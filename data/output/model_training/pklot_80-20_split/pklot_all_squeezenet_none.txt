Epoch 1/5
Batch [100/8699], Train Loss: 1.0187, Train Acc: 0.5209
Batch [200/8699], Train Loss: 0.9338, Train Acc: 0.5223
Batch [300/8699], Train Loss: 0.9284, Train Acc: 0.5328
Batch [400/8699], Train Loss: 0.8753, Train Acc: 0.5336
Batch [500/8699], Train Loss: 0.8411, Train Acc: 0.5541
Batch [600/8699], Train Loss: 0.7911, Train Acc: 0.5876
Batch [700/8699], Train Loss: 0.6975, Train Acc: 0.6403
Batch [800/8699], Train Loss: 0.6229, Train Acc: 0.6815
Batch [900/8699], Train Loss: 0.5650, Train Acc: 0.7129
Batch [1000/8699], Train Loss: 0.5167, Train Acc: 0.7394
Batch [1100/8699], Train Loss: 0.4765, Train Acc: 0.7611
Batch [1200/8699], Train Loss: 0.4429, Train Acc: 0.7793
Batch [1300/8699], Train Loss: 0.4139, Train Acc: 0.7945
Batch [1400/8699], Train Loss: 0.3896, Train Acc: 0.8076
Batch [1500/8699], Train Loss: 0.3672, Train Acc: 0.8195
Batch [1600/8699], Train Loss: 0.3482, Train Acc: 0.8295
Batch [1700/8699], Train Loss: 0.3325, Train Acc: 0.8381
Batch [1800/8699], Train Loss: 0.3178, Train Acc: 0.8460
Batch [1900/8699], Train Loss: 0.3046, Train Acc: 0.8531
Batch [2000/8699], Train Loss: 0.2920, Train Acc: 0.8597
Batch [2100/8699], Train Loss: 0.2802, Train Acc: 0.8658
Batch [2200/8699], Train Loss: 0.2688, Train Acc: 0.8714
Batch [2300/8699], Train Loss: 0.2593, Train Acc: 0.8762
Batch [2400/8699], Train Loss: 0.2509, Train Acc: 0.8807
Batch [2500/8699], Train Loss: 0.2425, Train Acc: 0.8850
Batch [2600/8699], Train Loss: 0.2346, Train Acc: 0.8890
Batch [2700/8699], Train Loss: 0.2277, Train Acc: 0.8926
Batch [2800/8699], Train Loss: 0.2215, Train Acc: 0.8959
Batch [2900/8699], Train Loss: 0.2152, Train Acc: 0.8991
Batch [3000/8699], Train Loss: 0.2092, Train Acc: 0.9021
Batch [3100/8699], Train Loss: 0.2037, Train Acc: 0.9049
Batch [3200/8699], Train Loss: 0.1985, Train Acc: 0.9076
Batch [3300/8699], Train Loss: 0.1933, Train Acc: 0.9102
Batch [3400/8699], Train Loss: 0.1887, Train Acc: 0.9125
Batch [3500/8699], Train Loss: 0.1847, Train Acc: 0.9146
Batch [3600/8699], Train Loss: 0.1807, Train Acc: 0.9166
Batch [3700/8699], Train Loss: 0.1768, Train Acc: 0.9186
Batch [3800/8699], Train Loss: 0.1731, Train Acc: 0.9204
Batch [3900/8699], Train Loss: 0.1693, Train Acc: 0.9223
Batch [4000/8699], Train Loss: 0.1659, Train Acc: 0.9240
Batch [4100/8699], Train Loss: 0.1625, Train Acc: 0.9257
Batch [4200/8699], Train Loss: 0.1595, Train Acc: 0.9272
Batch [4300/8699], Train Loss: 0.1564, Train Acc: 0.9287
Batch [4400/8699], Train Loss: 0.1538, Train Acc: 0.9301
Batch [4500/8699], Train Loss: 0.1511, Train Acc: 0.9315
Batch [4600/8699], Train Loss: 0.1485, Train Acc: 0.9328
Batch [4700/8699], Train Loss: 0.1458, Train Acc: 0.9341
Batch [4800/8699], Train Loss: 0.1439, Train Acc: 0.9352
Batch [4900/8699], Train Loss: 0.1416, Train Acc: 0.9363
Batch [5000/8699], Train Loss: 0.1395, Train Acc: 0.9374
Batch [5100/8699], Train Loss: 0.1374, Train Acc: 0.9383
Batch [5200/8699], Train Loss: 0.1352, Train Acc: 0.9394
Batch [5300/8699], Train Loss: 0.1332, Train Acc: 0.9404
Batch [5400/8699], Train Loss: 0.1312, Train Acc: 0.9414
Batch [5500/8699], Train Loss: 0.1293, Train Acc: 0.9423
Batch [5600/8699], Train Loss: 0.1273, Train Acc: 0.9432
Batch [5700/8699], Train Loss: 0.1256, Train Acc: 0.9441
Batch [5800/8699], Train Loss: 0.1238, Train Acc: 0.9449
Batch [5900/8699], Train Loss: 0.1222, Train Acc: 0.9457
Batch [6000/8699], Train Loss: 0.1209, Train Acc: 0.9464
Batch [6100/8699], Train Loss: 0.1193, Train Acc: 0.9471
Batch [6200/8699], Train Loss: 0.1180, Train Acc: 0.9478
Batch [6300/8699], Train Loss: 0.1164, Train Acc: 0.9486
Batch [6400/8699], Train Loss: 0.1154, Train Acc: 0.9492
Batch [6500/8699], Train Loss: 0.1142, Train Acc: 0.9498
Batch [6600/8699], Train Loss: 0.1131, Train Acc: 0.9504
Batch [6700/8699], Train Loss: 0.1119, Train Acc: 0.9510
Batch [6800/8699], Train Loss: 0.1106, Train Acc: 0.9516
Batch [6900/8699], Train Loss: 0.1094, Train Acc: 0.9522
Batch [7000/8699], Train Loss: 0.1082, Train Acc: 0.9528
Batch [7100/8699], Train Loss: 0.1071, Train Acc: 0.9533
Batch [7200/8699], Train Loss: 0.1061, Train Acc: 0.9538
Batch [7300/8699], Train Loss: 0.1050, Train Acc: 0.9544
Batch [7400/8699], Train Loss: 0.1039, Train Acc: 0.9549
Batch [7500/8699], Train Loss: 0.1029, Train Acc: 0.9554
Batch [7600/8699], Train Loss: 0.1019, Train Acc: 0.9559
Batch [7700/8699], Train Loss: 0.1008, Train Acc: 0.9564
Batch [7800/8699], Train Loss: 0.0999, Train Acc: 0.9568
Batch [7900/8699], Train Loss: 0.0989, Train Acc: 0.9573
Batch [8000/8699], Train Loss: 0.0980, Train Acc: 0.9578
Batch [8100/8699], Train Loss: 0.0971, Train Acc: 0.9582
Batch [8200/8699], Train Loss: 0.0961, Train Acc: 0.9587
Batch [8300/8699], Train Loss: 0.0952, Train Acc: 0.9591
Batch [8400/8699], Train Loss: 0.0943, Train Acc: 0.9595
Batch [8500/8699], Train Loss: 0.0935, Train Acc: 0.9599
Batch [8600/8699], Train Loss: 0.0926, Train Acc: 0.9603
Train Loss: 0.0917, Train Acc: 0.9607
Test Accuracy: 0.9943
Confusion Matrix:
[[70876   600]
 [  193 67502]]
Saved the new best model to ../data/models/80_20_split/pklot_all_squeezenet_None.pth
Epoch time: 21.8387 minutes and 50.3192 seconds
Epoch 2/5
Batch [100/8699], Train Loss: 0.0353, Train Acc: 0.9916
Batch [200/8699], Train Loss: 0.0291, Train Acc: 0.9923
Batch [300/8699], Train Loss: 0.0286, Train Acc: 0.9929
Batch [400/8699], Train Loss: 0.0269, Train Acc: 0.9931
Batch [500/8699], Train Loss: 0.0429, Train Acc: 0.9907
Batch [600/8699], Train Loss: 0.0426, Train Acc: 0.9902
Batch [700/8699], Train Loss: 0.0420, Train Acc: 0.9901
Batch [800/8699], Train Loss: 0.0398, Train Acc: 0.9905
Batch [900/8699], Train Loss: 0.0389, Train Acc: 0.9905
Batch [1000/8699], Train Loss: 0.0378, Train Acc: 0.9905
Batch [1100/8699], Train Loss: 0.0367, Train Acc: 0.9909
Batch [1200/8699], Train Loss: 0.0349, Train Acc: 0.9912
Batch [1300/8699], Train Loss: 0.0342, Train Acc: 0.9913
Batch [1400/8699], Train Loss: 0.0333, Train Acc: 0.9914
Batch [1500/8699], Train Loss: 0.0327, Train Acc: 0.9916
Batch [1600/8699], Train Loss: 0.0322, Train Acc: 0.9918
Batch [1700/8699], Train Loss: 0.0315, Train Acc: 0.9919
Batch [1800/8699], Train Loss: 0.0308, Train Acc: 0.9921
Batch [1900/8699], Train Loss: 0.0301, Train Acc: 0.9924
Batch [2000/8699], Train Loss: 0.0294, Train Acc: 0.9925
Batch [2100/8699], Train Loss: 0.0290, Train Acc: 0.9926
Batch [2200/8699], Train Loss: 0.0287, Train Acc: 0.9927
Batch [2300/8699], Train Loss: 0.0283, Train Acc: 0.9928
Batch [2400/8699], Train Loss: 0.0281, Train Acc: 0.9928
Batch [2500/8699], Train Loss: 0.0280, Train Acc: 0.9929
Batch [2600/8699], Train Loss: 0.0276, Train Acc: 0.9930
Batch [2700/8699], Train Loss: 0.0275, Train Acc: 0.9930
Batch [2800/8699], Train Loss: 0.0271, Train Acc: 0.9931
Batch [2900/8699], Train Loss: 0.0272, Train Acc: 0.9930
Batch [3000/8699], Train Loss: 0.0268, Train Acc: 0.9931
Batch [3100/8699], Train Loss: 0.0264, Train Acc: 0.9932
Batch [3200/8699], Train Loss: 0.0265, Train Acc: 0.9932
Batch [3300/8699], Train Loss: 0.0263, Train Acc: 0.9933
Batch [3400/8699], Train Loss: 0.0258, Train Acc: 0.9934
Batch [3500/8699], Train Loss: 0.0255, Train Acc: 0.9935
Batch [3600/8699], Train Loss: 0.0253, Train Acc: 0.9935
Batch [3700/8699], Train Loss: 0.0255, Train Acc: 0.9935
Batch [3800/8699], Train Loss: 0.0255, Train Acc: 0.9934
Batch [3900/8699], Train Loss: 0.0254, Train Acc: 0.9934
Batch [4000/8699], Train Loss: 0.0253, Train Acc: 0.9935
Batch [4100/8699], Train Loss: 0.0254, Train Acc: 0.9935
Batch [4200/8699], Train Loss: 0.0253, Train Acc: 0.9935
Batch [4300/8699], Train Loss: 0.0250, Train Acc: 0.9935
Batch [4400/8699], Train Loss: 0.0250, Train Acc: 0.9935
Batch [4500/8699], Train Loss: 0.0249, Train Acc: 0.9935
Batch [4600/8699], Train Loss: 0.0248, Train Acc: 0.9935
Batch [4700/8699], Train Loss: 0.0246, Train Acc: 0.9936
Batch [4800/8699], Train Loss: 0.0247, Train Acc: 0.9935
Batch [4900/8699], Train Loss: 0.0246, Train Acc: 0.9936
Batch [5000/8699], Train Loss: 0.0244, Train Acc: 0.9936
Batch [5100/8699], Train Loss: 0.0243, Train Acc: 0.9936
Batch [5200/8699], Train Loss: 0.0242, Train Acc: 0.9937
Batch [5300/8699], Train Loss: 0.0240, Train Acc: 0.9937
Batch [5400/8699], Train Loss: 0.0241, Train Acc: 0.9937
Batch [5500/8699], Train Loss: 0.0239, Train Acc: 0.9937
Batch [5600/8699], Train Loss: 0.0237, Train Acc: 0.9938
Batch [5700/8699], Train Loss: 0.0236, Train Acc: 0.9938
Batch [5800/8699], Train Loss: 0.0234, Train Acc: 0.9939
Batch [5900/8699], Train Loss: 0.0232, Train Acc: 0.9939
Batch [6000/8699], Train Loss: 0.0231, Train Acc: 0.9939
Batch [6100/8699], Train Loss: 0.0231, Train Acc: 0.9939
Batch [6200/8699], Train Loss: 0.0230, Train Acc: 0.9940
Batch [6300/8699], Train Loss: 0.0229, Train Acc: 0.9940
Batch [6400/8699], Train Loss: 0.0228, Train Acc: 0.9940
Batch [6500/8699], Train Loss: 0.0227, Train Acc: 0.9940
Batch [6600/8699], Train Loss: 0.0226, Train Acc: 0.9940
Batch [6700/8699], Train Loss: 0.0225, Train Acc: 0.9941
Batch [6800/8699], Train Loss: 0.0225, Train Acc: 0.9941
Batch [6900/8699], Train Loss: 0.0225, Train Acc: 0.9940
Batch [7000/8699], Train Loss: 0.0226, Train Acc: 0.9940
Batch [7100/8699], Train Loss: 0.0225, Train Acc: 0.9940
Batch [7200/8699], Train Loss: 0.0224, Train Acc: 0.9941
Batch [7300/8699], Train Loss: 0.0224, Train Acc: 0.9941
Batch [7400/8699], Train Loss: 0.0223, Train Acc: 0.9941
Batch [7500/8699], Train Loss: 0.0222, Train Acc: 0.9941
Batch [7600/8699], Train Loss: 0.0221, Train Acc: 0.9941
Batch [7700/8699], Train Loss: 0.0221, Train Acc: 0.9942
Batch [7800/8699], Train Loss: 0.0221, Train Acc: 0.9941
Batch [7900/8699], Train Loss: 0.0220, Train Acc: 0.9942
Batch [8000/8699], Train Loss: 0.0220, Train Acc: 0.9942
Batch [8100/8699], Train Loss: 0.0219, Train Acc: 0.9942
Batch [8200/8699], Train Loss: 0.0218, Train Acc: 0.9942
Batch [8300/8699], Train Loss: 0.0218, Train Acc: 0.9943
Batch [8400/8699], Train Loss: 0.0217, Train Acc: 0.9943
Batch [8500/8699], Train Loss: 0.0217, Train Acc: 0.9943
Batch [8600/8699], Train Loss: 0.0216, Train Acc: 0.9943
Train Loss: 0.0215, Train Acc: 0.9943
Test Accuracy: 0.9970
Confusion Matrix:
[[71315   161]
 [  259 67436]]
Saved the new best model to ../data/models/80_20_split/pklot_all_squeezenet_None.pth
Epoch time: 44.4870 minutes and 29.2179 seconds
Epoch 3/5
Batch [100/8699], Train Loss: 0.0141, Train Acc: 0.9966
Batch [200/8699], Train Loss: 0.0121, Train Acc: 0.9970
Batch [300/8699], Train Loss: 0.0126, Train Acc: 0.9967
Batch [400/8699], Train Loss: 0.0126, Train Acc: 0.9970
Batch [500/8699], Train Loss: 0.0126, Train Acc: 0.9970
Batch [600/8699], Train Loss: 0.0123, Train Acc: 0.9970
Batch [700/8699], Train Loss: 0.0124, Train Acc: 0.9970
Batch [800/8699], Train Loss: 0.0134, Train Acc: 0.9968
Batch [900/8699], Train Loss: 0.0146, Train Acc: 0.9965
Batch [1000/8699], Train Loss: 0.0152, Train Acc: 0.9963
Batch [1100/8699], Train Loss: 0.0151, Train Acc: 0.9963
Batch [1200/8699], Train Loss: 0.0153, Train Acc: 0.9962
Batch [1300/8699], Train Loss: 0.0149, Train Acc: 0.9964
Batch [1400/8699], Train Loss: 0.0147, Train Acc: 0.9964
Batch [1500/8699], Train Loss: 0.0147, Train Acc: 0.9964
Batch [1600/8699], Train Loss: 0.0149, Train Acc: 0.9964
Batch [1700/8699], Train Loss: 0.0149, Train Acc: 0.9964
Batch [1800/8699], Train Loss: 0.0147, Train Acc: 0.9965
Batch [1900/8699], Train Loss: 0.0144, Train Acc: 0.9966
Batch [2000/8699], Train Loss: 0.0144, Train Acc: 0.9966
Batch [2100/8699], Train Loss: 0.0140, Train Acc: 0.9967
Batch [2200/8699], Train Loss: 0.0148, Train Acc: 0.9965
Batch [2300/8699], Train Loss: 0.0149, Train Acc: 0.9964
Batch [2400/8699], Train Loss: 0.0149, Train Acc: 0.9964
Batch [2500/8699], Train Loss: 0.0146, Train Acc: 0.9964
Batch [2600/8699], Train Loss: 0.0145, Train Acc: 0.9964
Batch [2700/8699], Train Loss: 0.0144, Train Acc: 0.9965
Batch [2800/8699], Train Loss: 0.0143, Train Acc: 0.9965
Batch [2900/8699], Train Loss: 0.0145, Train Acc: 0.9965
Batch [3000/8699], Train Loss: 0.0145, Train Acc: 0.9965
Batch [3100/8699], Train Loss: 0.0145, Train Acc: 0.9964
Batch [3200/8699], Train Loss: 0.0145, Train Acc: 0.9964
Batch [3300/8699], Train Loss: 0.0144, Train Acc: 0.9965
Batch [3400/8699], Train Loss: 0.0144, Train Acc: 0.9965
Batch [3500/8699], Train Loss: 0.0146, Train Acc: 0.9965
Batch [3600/8699], Train Loss: 0.0144, Train Acc: 0.9965
Batch [3700/8699], Train Loss: 0.0144, Train Acc: 0.9965
Batch [3800/8699], Train Loss: 0.0145, Train Acc: 0.9965
Batch [3900/8699], Train Loss: 0.0146, Train Acc: 0.9964
Batch [4000/8699], Train Loss: 0.0145, Train Acc: 0.9965
Batch [4100/8699], Train Loss: 0.0146, Train Acc: 0.9964
Batch [4200/8699], Train Loss: 0.0147, Train Acc: 0.9964
Batch [4300/8699], Train Loss: 0.0146, Train Acc: 0.9964
Batch [4400/8699], Train Loss: 0.0145, Train Acc: 0.9964
Batch [4500/8699], Train Loss: 0.0145, Train Acc: 0.9964
Batch [4600/8699], Train Loss: 0.0146, Train Acc: 0.9964
Batch [4700/8699], Train Loss: 0.0146, Train Acc: 0.9964
Batch [4800/8699], Train Loss: 0.0147, Train Acc: 0.9964
Batch [4900/8699], Train Loss: 0.0146, Train Acc: 0.9964
Batch [5000/8699], Train Loss: 0.0146, Train Acc: 0.9964
Batch [5100/8699], Train Loss: 0.0146, Train Acc: 0.9964
Batch [5200/8699], Train Loss: 0.0144, Train Acc: 0.9964
Batch [5300/8699], Train Loss: 0.0144, Train Acc: 0.9964
Batch [5400/8699], Train Loss: 0.0144, Train Acc: 0.9964
Batch [5500/8699], Train Loss: 0.0145, Train Acc: 0.9964
Batch [5600/8699], Train Loss: 0.0144, Train Acc: 0.9964
Batch [5700/8699], Train Loss: 0.0144, Train Acc: 0.9964
Batch [5800/8699], Train Loss: 0.0143, Train Acc: 0.9964
Batch [5900/8699], Train Loss: 0.0143, Train Acc: 0.9964
Batch [6000/8699], Train Loss: 0.0142, Train Acc: 0.9964
Batch [6100/8699], Train Loss: 0.0142, Train Acc: 0.9965
Batch [6200/8699], Train Loss: 0.0142, Train Acc: 0.9964
Batch [6300/8699], Train Loss: 0.0142, Train Acc: 0.9964
Batch [6400/8699], Train Loss: 0.0142, Train Acc: 0.9964
Batch [6500/8699], Train Loss: 0.0142, Train Acc: 0.9964
Batch [6600/8699], Train Loss: 0.0141, Train Acc: 0.9964
Batch [6700/8699], Train Loss: 0.0141, Train Acc: 0.9964
Batch [6800/8699], Train Loss: 0.0141, Train Acc: 0.9964
Batch [6900/8699], Train Loss: 0.0143, Train Acc: 0.9964
Batch [7000/8699], Train Loss: 0.0143, Train Acc: 0.9964
Batch [7100/8699], Train Loss: 0.0142, Train Acc: 0.9964
Batch [7200/8699], Train Loss: 0.0142, Train Acc: 0.9964
Batch [7300/8699], Train Loss: 0.0142, Train Acc: 0.9964
Batch [7400/8699], Train Loss: 0.0143, Train Acc: 0.9964
Batch [7500/8699], Train Loss: 0.0142, Train Acc: 0.9964
Batch [7600/8699], Train Loss: 0.0142, Train Acc: 0.9964
Batch [7700/8699], Train Loss: 0.0142, Train Acc: 0.9964
Batch [7800/8699], Train Loss: 0.0142, Train Acc: 0.9964
Batch [7900/8699], Train Loss: 0.0142, Train Acc: 0.9964
Batch [8000/8699], Train Loss: 0.0142, Train Acc: 0.9964
Batch [8100/8699], Train Loss: 0.0141, Train Acc: 0.9964
Batch [8200/8699], Train Loss: 0.0141, Train Acc: 0.9965
Batch [8300/8699], Train Loss: 0.0141, Train Acc: 0.9965
Batch [8400/8699], Train Loss: 0.0140, Train Acc: 0.9965
Batch [8500/8699], Train Loss: 0.0140, Train Acc: 0.9965
Batch [8600/8699], Train Loss: 0.0141, Train Acc: 0.9965
Train Loss: 0.0141, Train Acc: 0.9965
Test Accuracy: 0.9976
Confusion Matrix:
[[71314   162]
 [  168 67527]]
Saved the new best model to ../data/models/80_20_split/pklot_all_squeezenet_None.pth
Epoch time: 64.5121 minutes and 30.7247 seconds
Epoch 4/5
Batch [100/8699], Train Loss: 0.0142, Train Acc: 0.9972
Batch [200/8699], Train Loss: 0.0124, Train Acc: 0.9973
Batch [300/8699], Train Loss: 0.0114, Train Acc: 0.9975
Batch [400/8699], Train Loss: 0.0113, Train Acc: 0.9977
Batch [500/8699], Train Loss: 0.0102, Train Acc: 0.9978
Batch [600/8699], Train Loss: 0.0111, Train Acc: 0.9974
Batch [700/8699], Train Loss: 0.0110, Train Acc: 0.9975
Batch [800/8699], Train Loss: 0.0108, Train Acc: 0.9975
Batch [900/8699], Train Loss: 0.0104, Train Acc: 0.9976
Batch [1000/8699], Train Loss: 0.0111, Train Acc: 0.9974
Batch [1100/8699], Train Loss: 0.0115, Train Acc: 0.9972
Batch [1200/8699], Train Loss: 0.0119, Train Acc: 0.9971
Batch [1300/8699], Train Loss: 0.0120, Train Acc: 0.9971
Batch [1400/8699], Train Loss: 0.0123, Train Acc: 0.9971
Batch [1500/8699], Train Loss: 0.0122, Train Acc: 0.9971
Batch [1600/8699], Train Loss: 0.0128, Train Acc: 0.9970
Batch [1700/8699], Train Loss: 0.0130, Train Acc: 0.9968
Batch [1800/8699], Train Loss: 0.0131, Train Acc: 0.9968
Batch [1900/8699], Train Loss: 0.0129, Train Acc: 0.9968
Batch [2000/8699], Train Loss: 0.0129, Train Acc: 0.9969
Batch [2100/8699], Train Loss: 0.0130, Train Acc: 0.9969
Batch [2200/8699], Train Loss: 0.0127, Train Acc: 0.9970
Batch [2300/8699], Train Loss: 0.0126, Train Acc: 0.9970
Batch [2400/8699], Train Loss: 0.0124, Train Acc: 0.9970
Batch [2500/8699], Train Loss: 0.0125, Train Acc: 0.9969
Batch [2600/8699], Train Loss: 0.0124, Train Acc: 0.9970
Batch [2700/8699], Train Loss: 0.0126, Train Acc: 0.9969
Batch [2800/8699], Train Loss: 0.0126, Train Acc: 0.9970
Batch [2900/8699], Train Loss: 0.0124, Train Acc: 0.9970
Batch [3000/8699], Train Loss: 0.0122, Train Acc: 0.9971
Batch [3100/8699], Train Loss: 0.0124, Train Acc: 0.9970
Batch [3200/8699], Train Loss: 0.0123, Train Acc: 0.9971
Batch [3300/8699], Train Loss: 0.0121, Train Acc: 0.9971
Batch [3400/8699], Train Loss: 0.0121, Train Acc: 0.9971
Batch [3500/8699], Train Loss: 0.0119, Train Acc: 0.9972
Batch [3600/8699], Train Loss: 0.0118, Train Acc: 0.9972
Batch [3700/8699], Train Loss: 0.0119, Train Acc: 0.9972
Batch [3800/8699], Train Loss: 0.0118, Train Acc: 0.9972
Batch [3900/8699], Train Loss: 0.0119, Train Acc: 0.9972
Batch [4000/8699], Train Loss: 0.0119, Train Acc: 0.9972
Batch [4100/8699], Train Loss: 0.0118, Train Acc: 0.9972
Batch [4200/8699], Train Loss: 0.0118, Train Acc: 0.9972
Batch [4300/8699], Train Loss: 0.0118, Train Acc: 0.9972
Batch [4400/8699], Train Loss: 0.0117, Train Acc: 0.9972
Batch [4500/8699], Train Loss: 0.0117, Train Acc: 0.9972
Batch [4600/8699], Train Loss: 0.0117, Train Acc: 0.9972
Batch [4700/8699], Train Loss: 0.0115, Train Acc: 0.9972
Batch [4800/8699], Train Loss: 0.0116, Train Acc: 0.9972
Batch [4900/8699], Train Loss: 0.0116, Train Acc: 0.9972
Batch [5000/8699], Train Loss: 0.0116, Train Acc: 0.9972
Batch [5100/8699], Train Loss: 0.0116, Train Acc: 0.9972
Batch [5200/8699], Train Loss: 0.0117, Train Acc: 0.9973
Batch [5300/8699], Train Loss: 0.0116, Train Acc: 0.9973
Batch [5400/8699], Train Loss: 0.0116, Train Acc: 0.9973
Batch [5500/8699], Train Loss: 0.0118, Train Acc: 0.9972
Batch [5600/8699], Train Loss: 0.0118, Train Acc: 0.9972
Batch [5700/8699], Train Loss: 0.0118, Train Acc: 0.9972
Batch [5800/8699], Train Loss: 0.0117, Train Acc: 0.9972
Batch [5900/8699], Train Loss: 0.0116, Train Acc: 0.9972
Batch [6000/8699], Train Loss: 0.0116, Train Acc: 0.9972
Batch [6100/8699], Train Loss: 0.0115, Train Acc: 0.9972
Batch [6200/8699], Train Loss: 0.0115, Train Acc: 0.9972
Batch [6300/8699], Train Loss: 0.0115, Train Acc: 0.9972
Batch [6400/8699], Train Loss: 0.0115, Train Acc: 0.9973
Batch [6500/8699], Train Loss: 0.0114, Train Acc: 0.9973
Batch [6600/8699], Train Loss: 0.0114, Train Acc: 0.9973
Batch [6700/8699], Train Loss: 0.0115, Train Acc: 0.9973
Batch [6800/8699], Train Loss: 0.0114, Train Acc: 0.9973
Batch [6900/8699], Train Loss: 0.0115, Train Acc: 0.9973
Batch [7000/8699], Train Loss: 0.0115, Train Acc: 0.9973
Batch [7100/8699], Train Loss: 0.0115, Train Acc: 0.9973
Batch [7200/8699], Train Loss: 0.0114, Train Acc: 0.9973
Batch [7300/8699], Train Loss: 0.0114, Train Acc: 0.9973
Batch [7400/8699], Train Loss: 0.0114, Train Acc: 0.9973
Batch [7500/8699], Train Loss: 0.0113, Train Acc: 0.9973
Batch [7600/8699], Train Loss: 0.0113, Train Acc: 0.9973
Batch [7700/8699], Train Loss: 0.0114, Train Acc: 0.9973
Batch [7800/8699], Train Loss: 0.0114, Train Acc: 0.9973
Batch [7900/8699], Train Loss: 0.0113, Train Acc: 0.9973
Batch [8000/8699], Train Loss: 0.0112, Train Acc: 0.9973
Batch [8100/8699], Train Loss: 0.0113, Train Acc: 0.9973
Batch [8200/8699], Train Loss: 0.0114, Train Acc: 0.9973
Batch [8300/8699], Train Loss: 0.0114, Train Acc: 0.9973
Batch [8400/8699], Train Loss: 0.0114, Train Acc: 0.9973
Batch [8500/8699], Train Loss: 0.0113, Train Acc: 0.9973
Batch [8600/8699], Train Loss: 0.0114, Train Acc: 0.9973
Train Loss: 0.0114, Train Acc: 0.9973
Test Accuracy: 0.9983
Confusion Matrix:
[[71379    97]
 [  144 67551]]
Saved the new best model to ../data/models/80_20_split/pklot_all_squeezenet_None.pth
Epoch time: 84.5019 minutes and 30.1154 seconds
Epoch 5/5
Batch [100/8699], Train Loss: 0.0076, Train Acc: 0.9978
Batch [200/8699], Train Loss: 0.0084, Train Acc: 0.9975
Batch [300/8699], Train Loss: 0.0107, Train Acc: 0.9973
Batch [400/8699], Train Loss: 0.0101, Train Acc: 0.9977
Batch [500/8699], Train Loss: 0.0097, Train Acc: 0.9979
Batch [600/8699], Train Loss: 0.0095, Train Acc: 0.9979
Batch [700/8699], Train Loss: 0.0093, Train Acc: 0.9980
Batch [800/8699], Train Loss: 0.0098, Train Acc: 0.9978
Batch [900/8699], Train Loss: 0.0095, Train Acc: 0.9978
Batch [1000/8699], Train Loss: 0.0097, Train Acc: 0.9977
Batch [1100/8699], Train Loss: 0.0101, Train Acc: 0.9977
Batch [1200/8699], Train Loss: 0.0102, Train Acc: 0.9977
Batch [1300/8699], Train Loss: 0.0101, Train Acc: 0.9977
Batch [1400/8699], Train Loss: 0.0099, Train Acc: 0.9978
Batch [1500/8699], Train Loss: 0.0093, Train Acc: 0.9979
Batch [1600/8699], Train Loss: 0.0097, Train Acc: 0.9979
Batch [1700/8699], Train Loss: 0.0092, Train Acc: 0.9980
Batch [1800/8699], Train Loss: 0.0094, Train Acc: 0.9979
Batch [1900/8699], Train Loss: 0.0096, Train Acc: 0.9979
Batch [2000/8699], Train Loss: 0.0097, Train Acc: 0.9978
Batch [2100/8699], Train Loss: 0.0096, Train Acc: 0.9979
Batch [2200/8699], Train Loss: 0.0097, Train Acc: 0.9979
Batch [2300/8699], Train Loss: 0.0097, Train Acc: 0.9979
Batch [2400/8699], Train Loss: 0.0100, Train Acc: 0.9978
Batch [2500/8699], Train Loss: 0.0100, Train Acc: 0.9978
Batch [2600/8699], Train Loss: 0.0102, Train Acc: 0.9978
Batch [2700/8699], Train Loss: 0.0101, Train Acc: 0.9978
Batch [2800/8699], Train Loss: 0.0100, Train Acc: 0.9978
Batch [2900/8699], Train Loss: 0.0101, Train Acc: 0.9978
Batch [3000/8699], Train Loss: 0.0101, Train Acc: 0.9977
Batch [3100/8699], Train Loss: 0.0100, Train Acc: 0.9977
Batch [3200/8699], Train Loss: 0.0100, Train Acc: 0.9978
Batch [3300/8699], Train Loss: 0.0099, Train Acc: 0.9978
Batch [3400/8699], Train Loss: 0.0099, Train Acc: 0.9978
Batch [3500/8699], Train Loss: 0.0099, Train Acc: 0.9978
Batch [3600/8699], Train Loss: 0.0100, Train Acc: 0.9978
Batch [3700/8699], Train Loss: 0.0099, Train Acc: 0.9978
Batch [3800/8699], Train Loss: 0.0098, Train Acc: 0.9978
Batch [3900/8699], Train Loss: 0.0097, Train Acc: 0.9978
Batch [4000/8699], Train Loss: 0.0095, Train Acc: 0.9979
Batch [4100/8699], Train Loss: 0.0095, Train Acc: 0.9979
Batch [4200/8699], Train Loss: 0.0096, Train Acc: 0.9978
Batch [4300/8699], Train Loss: 0.0096, Train Acc: 0.9979
Batch [4400/8699], Train Loss: 0.0095, Train Acc: 0.9979
Batch [4500/8699], Train Loss: 0.0096, Train Acc: 0.9979
Batch [4600/8699], Train Loss: 0.0096, Train Acc: 0.9979
Batch [4700/8699], Train Loss: 0.0096, Train Acc: 0.9979
Batch [4800/8699], Train Loss: 0.0095, Train Acc: 0.9979
Batch [4900/8699], Train Loss: 0.0096, Train Acc: 0.9979
Batch [5000/8699], Train Loss: 0.0095, Train Acc: 0.9979
Batch [5100/8699], Train Loss: 0.0095, Train Acc: 0.9979
Batch [5200/8699], Train Loss: 0.0095, Train Acc: 0.9979
Batch [5300/8699], Train Loss: 0.0096, Train Acc: 0.9979
Batch [5400/8699], Train Loss: 0.0099, Train Acc: 0.9978
Batch [5500/8699], Train Loss: 0.0099, Train Acc: 0.9978
Batch [5600/8699], Train Loss: 0.0098, Train Acc: 0.9978
Batch [5700/8699], Train Loss: 0.0098, Train Acc: 0.9978
Batch [5800/8699], Train Loss: 0.0099, Train Acc: 0.9978
Batch [5900/8699], Train Loss: 0.0098, Train Acc: 0.9978
Batch [6000/8699], Train Loss: 0.0098, Train Acc: 0.9978
Batch [6100/8699], Train Loss: 0.0099, Train Acc: 0.9978
Batch [6200/8699], Train Loss: 0.0099, Train Acc: 0.9978
Batch [6300/8699], Train Loss: 0.0099, Train Acc: 0.9978
Batch [6400/8699], Train Loss: 0.0098, Train Acc: 0.9979
Batch [6500/8699], Train Loss: 0.0098, Train Acc: 0.9978
Batch [6600/8699], Train Loss: 0.0098, Train Acc: 0.9979
Batch [6700/8699], Train Loss: 0.0098, Train Acc: 0.9978
Batch [6800/8699], Train Loss: 0.0098, Train Acc: 0.9978
Batch [6900/8699], Train Loss: 0.0098, Train Acc: 0.9978
Batch [7000/8699], Train Loss: 0.0098, Train Acc: 0.9978
Batch [7100/8699], Train Loss: 0.0098, Train Acc: 0.9978
Batch [7200/8699], Train Loss: 0.0097, Train Acc: 0.9978
Batch [7300/8699], Train Loss: 0.0097, Train Acc: 0.9978
Batch [7400/8699], Train Loss: 0.0097, Train Acc: 0.9978
Batch [7500/8699], Train Loss: 0.0097, Train Acc: 0.9979
Batch [7600/8699], Train Loss: 0.0097, Train Acc: 0.9979
Batch [7700/8699], Train Loss: 0.0097, Train Acc: 0.9978
Batch [7800/8699], Train Loss: 0.0097, Train Acc: 0.9978
Batch [7900/8699], Train Loss: 0.0096, Train Acc: 0.9978
Batch [8000/8699], Train Loss: 0.0096, Train Acc: 0.9978
Batch [8100/8699], Train Loss: 0.0096, Train Acc: 0.9978
Batch [8200/8699], Train Loss: 0.0096, Train Acc: 0.9979
Batch [8300/8699], Train Loss: 0.0096, Train Acc: 0.9979
Batch [8400/8699], Train Loss: 0.0095, Train Acc: 0.9979
Batch [8500/8699], Train Loss: 0.0096, Train Acc: 0.9978
Batch [8600/8699], Train Loss: 0.0097, Train Acc: 0.9978
Train Loss: 0.0097, Train Acc: 0.9978
Test Accuracy: 0.9985
Confusion Matrix:
[[71374   102]
 [  112 67583]]
Saved the new best model to ../data/models/80_20_split/pklot_all_squeezenet_None.pth
Epoch time: 104.5089 minutes and 30.5345 seconds
Best Train Acc: 0.9978
Total training time: 104.50894107421239 minutes and 30.53646445274353 seconds
