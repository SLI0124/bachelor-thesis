Epoch 1/5
Batch [100/8699], Train Loss: 1.0668, Train Acc: 0.5147
Batch [200/8699], Train Loss: 0.9051, Train Acc: 0.5112
Batch [300/8699], Train Loss: 0.7730, Train Acc: 0.5832
Batch [400/8699], Train Loss: 0.6186, Train Acc: 0.6735
Batch [500/8699], Train Loss: 0.5152, Train Acc: 0.7324
Batch [600/8699], Train Loss: 0.4413, Train Acc: 0.7734
Batch [700/8699], Train Loss: 0.3861, Train Acc: 0.8030
Batch [800/8699], Train Loss: 0.3445, Train Acc: 0.8254
Batch [900/8699], Train Loss: 0.3108, Train Acc: 0.8435
Batch [1000/8699], Train Loss: 0.2856, Train Acc: 0.8573
Batch [1100/8699], Train Loss: 0.2673, Train Acc: 0.8678
Batch [1200/8699], Train Loss: 0.2492, Train Acc: 0.8776
Batch [1300/8699], Train Loss: 0.2335, Train Acc: 0.8859
Batch [1400/8699], Train Loss: 0.2200, Train Acc: 0.8932
Batch [1500/8699], Train Loss: 0.2084, Train Acc: 0.8993
Batch [1600/8699], Train Loss: 0.1986, Train Acc: 0.9046
Batch [1700/8699], Train Loss: 0.1894, Train Acc: 0.9094
Batch [1800/8699], Train Loss: 0.1812, Train Acc: 0.9137
Batch [1900/8699], Train Loss: 0.1734, Train Acc: 0.9177
Batch [2000/8699], Train Loss: 0.1669, Train Acc: 0.9212
Batch [2100/8699], Train Loss: 0.1608, Train Acc: 0.9244
Batch [2200/8699], Train Loss: 0.1549, Train Acc: 0.9274
Batch [2300/8699], Train Loss: 0.1495, Train Acc: 0.9302
Batch [2400/8699], Train Loss: 0.1447, Train Acc: 0.9327
Batch [2500/8699], Train Loss: 0.1399, Train Acc: 0.9351
Batch [2600/8699], Train Loss: 0.1361, Train Acc: 0.9371
Batch [2700/8699], Train Loss: 0.1324, Train Acc: 0.9390
Batch [2800/8699], Train Loss: 0.1286, Train Acc: 0.9410
Batch [2900/8699], Train Loss: 0.1251, Train Acc: 0.9427
Batch [3000/8699], Train Loss: 0.1219, Train Acc: 0.9443
Batch [3100/8699], Train Loss: 0.1188, Train Acc: 0.9459
Batch [3200/8699], Train Loss: 0.1161, Train Acc: 0.9473
Batch [3300/8699], Train Loss: 0.1134, Train Acc: 0.9486
Batch [3400/8699], Train Loss: 0.1111, Train Acc: 0.9498
Batch [3500/8699], Train Loss: 0.1090, Train Acc: 0.9509
Batch [3600/8699], Train Loss: 0.1068, Train Acc: 0.9520
Batch [3700/8699], Train Loss: 0.1046, Train Acc: 0.9531
Batch [3800/8699], Train Loss: 0.1026, Train Acc: 0.9542
Batch [3900/8699], Train Loss: 0.1007, Train Acc: 0.9552
Batch [4000/8699], Train Loss: 0.0988, Train Acc: 0.9561
Batch [4100/8699], Train Loss: 0.0972, Train Acc: 0.9570
Batch [4200/8699], Train Loss: 0.0956, Train Acc: 0.9578
Batch [4300/8699], Train Loss: 0.0939, Train Acc: 0.9586
Batch [4400/8699], Train Loss: 0.0925, Train Acc: 0.9593
Batch [4500/8699], Train Loss: 0.0909, Train Acc: 0.9600
Batch [4600/8699], Train Loss: 0.0901, Train Acc: 0.9606
Batch [4700/8699], Train Loss: 0.0886, Train Acc: 0.9613
Batch [4800/8699], Train Loss: 0.0873, Train Acc: 0.9620
Batch [4900/8699], Train Loss: 0.0860, Train Acc: 0.9626
Batch [5000/8699], Train Loss: 0.0853, Train Acc: 0.9631
Batch [5100/8699], Train Loss: 0.0843, Train Acc: 0.9636
Batch [5200/8699], Train Loss: 0.0831, Train Acc: 0.9642
Batch [5300/8699], Train Loss: 0.0820, Train Acc: 0.9647
Batch [5400/8699], Train Loss: 0.0809, Train Acc: 0.9653
Batch [5500/8699], Train Loss: 0.0799, Train Acc: 0.9658
Batch [5600/8699], Train Loss: 0.0788, Train Acc: 0.9663
Batch [5700/8699], Train Loss: 0.0779, Train Acc: 0.9667
Batch [5800/8699], Train Loss: 0.0769, Train Acc: 0.9672
Batch [5900/8699], Train Loss: 0.0760, Train Acc: 0.9677
Batch [6000/8699], Train Loss: 0.0751, Train Acc: 0.9681
Batch [6100/8699], Train Loss: 0.0742, Train Acc: 0.9686
Batch [6200/8699], Train Loss: 0.0734, Train Acc: 0.9690
Batch [6300/8699], Train Loss: 0.0725, Train Acc: 0.9694
Batch [6400/8699], Train Loss: 0.0718, Train Acc: 0.9697
Batch [6500/8699], Train Loss: 0.0711, Train Acc: 0.9701
Batch [6600/8699], Train Loss: 0.0703, Train Acc: 0.9704
Batch [6700/8699], Train Loss: 0.0698, Train Acc: 0.9708
Batch [6800/8699], Train Loss: 0.0690, Train Acc: 0.9711
Batch [6900/8699], Train Loss: 0.0684, Train Acc: 0.9714
Batch [7000/8699], Train Loss: 0.0678, Train Acc: 0.9717
Batch [7100/8699], Train Loss: 0.0672, Train Acc: 0.9720
Batch [7200/8699], Train Loss: 0.0665, Train Acc: 0.9723
Batch [7300/8699], Train Loss: 0.0659, Train Acc: 0.9726
Batch [7400/8699], Train Loss: 0.0654, Train Acc: 0.9729
Batch [7500/8699], Train Loss: 0.0650, Train Acc: 0.9731
Batch [7600/8699], Train Loss: 0.0644, Train Acc: 0.9734
Batch [7700/8699], Train Loss: 0.0639, Train Acc: 0.9737
Batch [7800/8699], Train Loss: 0.0633, Train Acc: 0.9739
Batch [7900/8699], Train Loss: 0.0629, Train Acc: 0.9742
Batch [8000/8699], Train Loss: 0.0624, Train Acc: 0.9744
Batch [8100/8699], Train Loss: 0.0619, Train Acc: 0.9747
Batch [8200/8699], Train Loss: 0.0613, Train Acc: 0.9749
Batch [8300/8699], Train Loss: 0.0608, Train Acc: 0.9751
Batch [8400/8699], Train Loss: 0.0604, Train Acc: 0.9754
Batch [8500/8699], Train Loss: 0.0599, Train Acc: 0.9756
Batch [8600/8699], Train Loss: 0.0595, Train Acc: 0.9758
Train Loss: 0.0590, Train Acc: 0.9760
Test Accuracy: 0.9893
Confusion Matrix:
[[70529  1420]
 [   68 67154]]
Saved the new best model to ../data/models/80_20_split/pklot_all_squeezenet.pth
Epoch time: 21.9204 minutes and 55.2225 seconds
Epoch 2/5
Batch [100/8699], Train Loss: 0.0238, Train Acc: 0.9933
Batch [200/8699], Train Loss: 0.0203, Train Acc: 0.9942
Batch [300/8699], Train Loss: 0.0210, Train Acc: 0.9939
Batch [400/8699], Train Loss: 0.0225, Train Acc: 0.9938
Batch [500/8699], Train Loss: 0.0211, Train Acc: 0.9938
Batch [600/8699], Train Loss: 0.0220, Train Acc: 0.9936
Batch [700/8699], Train Loss: 0.0207, Train Acc: 0.9938
Batch [800/8699], Train Loss: 0.0212, Train Acc: 0.9938
Batch [900/8699], Train Loss: 0.0207, Train Acc: 0.9939
Batch [1000/8699], Train Loss: 0.0204, Train Acc: 0.9941
Batch [1100/8699], Train Loss: 0.0205, Train Acc: 0.9941
Batch [1200/8699], Train Loss: 0.0202, Train Acc: 0.9941
Batch [1300/8699], Train Loss: 0.0200, Train Acc: 0.9941
Batch [1400/8699], Train Loss: 0.0199, Train Acc: 0.9942
Batch [1500/8699], Train Loss: 0.0197, Train Acc: 0.9943
Batch [1600/8699], Train Loss: 0.0197, Train Acc: 0.9943
Batch [1700/8699], Train Loss: 0.0201, Train Acc: 0.9942
Batch [1800/8699], Train Loss: 0.0200, Train Acc: 0.9943
Batch [1900/8699], Train Loss: 0.0201, Train Acc: 0.9943
Batch [2000/8699], Train Loss: 0.0199, Train Acc: 0.9944
Batch [2100/8699], Train Loss: 0.0196, Train Acc: 0.9944
Batch [2200/8699], Train Loss: 0.0193, Train Acc: 0.9946
Batch [2300/8699], Train Loss: 0.0190, Train Acc: 0.9947
Batch [2400/8699], Train Loss: 0.0188, Train Acc: 0.9947
Batch [2500/8699], Train Loss: 0.0189, Train Acc: 0.9948
Batch [2600/8699], Train Loss: 0.0189, Train Acc: 0.9948
Batch [2700/8699], Train Loss: 0.0188, Train Acc: 0.9948
Batch [2800/8699], Train Loss: 0.0188, Train Acc: 0.9948
Batch [2900/8699], Train Loss: 0.0187, Train Acc: 0.9948
Batch [3000/8699], Train Loss: 0.0188, Train Acc: 0.9948
Batch [3100/8699], Train Loss: 0.0187, Train Acc: 0.9948
Batch [3200/8699], Train Loss: 0.0187, Train Acc: 0.9948
Batch [3300/8699], Train Loss: 0.0186, Train Acc: 0.9949
Batch [3400/8699], Train Loss: 0.0188, Train Acc: 0.9948
Batch [3500/8699], Train Loss: 0.0188, Train Acc: 0.9948
Batch [3600/8699], Train Loss: 0.0189, Train Acc: 0.9948
Batch [3700/8699], Train Loss: 0.0188, Train Acc: 0.9948
Batch [3800/8699], Train Loss: 0.0187, Train Acc: 0.9948
Batch [3900/8699], Train Loss: 0.0185, Train Acc: 0.9949
Batch [4000/8699], Train Loss: 0.0185, Train Acc: 0.9949
Batch [4100/8699], Train Loss: 0.0185, Train Acc: 0.9949
Batch [4200/8699], Train Loss: 0.0184, Train Acc: 0.9949
Batch [4300/8699], Train Loss: 0.0184, Train Acc: 0.9949
Batch [4400/8699], Train Loss: 0.0184, Train Acc: 0.9949
Batch [4500/8699], Train Loss: 0.0185, Train Acc: 0.9949
Batch [4600/8699], Train Loss: 0.0184, Train Acc: 0.9949
Batch [4700/8699], Train Loss: 0.0185, Train Acc: 0.9949
Batch [4800/8699], Train Loss: 0.0184, Train Acc: 0.9950
Batch [4900/8699], Train Loss: 0.0185, Train Acc: 0.9950
Batch [5000/8699], Train Loss: 0.0185, Train Acc: 0.9950
Batch [5100/8699], Train Loss: 0.0185, Train Acc: 0.9950
Batch [5200/8699], Train Loss: 0.0184, Train Acc: 0.9950
Batch [5300/8699], Train Loss: 0.0184, Train Acc: 0.9950
Batch [5400/8699], Train Loss: 0.0183, Train Acc: 0.9950
Batch [5500/8699], Train Loss: 0.0183, Train Acc: 0.9950
Batch [5600/8699], Train Loss: 0.0182, Train Acc: 0.9950
Batch [5700/8699], Train Loss: 0.0181, Train Acc: 0.9950
Batch [5800/8699], Train Loss: 0.0181, Train Acc: 0.9950
Batch [5900/8699], Train Loss: 0.0179, Train Acc: 0.9951
Batch [6000/8699], Train Loss: 0.0179, Train Acc: 0.9950
Batch [6100/8699], Train Loss: 0.0178, Train Acc: 0.9951
Batch [6200/8699], Train Loss: 0.0178, Train Acc: 0.9951
Batch [6300/8699], Train Loss: 0.0178, Train Acc: 0.9951
Batch [6400/8699], Train Loss: 0.0178, Train Acc: 0.9951
Batch [6500/8699], Train Loss: 0.0178, Train Acc: 0.9951
Batch [6600/8699], Train Loss: 0.0178, Train Acc: 0.9951
Batch [6700/8699], Train Loss: 0.0179, Train Acc: 0.9951
Batch [6800/8699], Train Loss: 0.0178, Train Acc: 0.9951
Batch [6900/8699], Train Loss: 0.0178, Train Acc: 0.9951
Batch [7000/8699], Train Loss: 0.0177, Train Acc: 0.9951
Batch [7100/8699], Train Loss: 0.0177, Train Acc: 0.9952
Batch [7200/8699], Train Loss: 0.0177, Train Acc: 0.9952
Batch [7300/8699], Train Loss: 0.0177, Train Acc: 0.9951
Batch [7400/8699], Train Loss: 0.0176, Train Acc: 0.9952
Batch [7500/8699], Train Loss: 0.0175, Train Acc: 0.9952
Batch [7600/8699], Train Loss: 0.0176, Train Acc: 0.9952
Batch [7700/8699], Train Loss: 0.0175, Train Acc: 0.9952
Batch [7800/8699], Train Loss: 0.0174, Train Acc: 0.9952
Batch [7900/8699], Train Loss: 0.0174, Train Acc: 0.9952
Batch [8000/8699], Train Loss: 0.0173, Train Acc: 0.9952
Batch [8100/8699], Train Loss: 0.0173, Train Acc: 0.9953
Batch [8200/8699], Train Loss: 0.0172, Train Acc: 0.9953
Batch [8300/8699], Train Loss: 0.0171, Train Acc: 0.9953
Batch [8400/8699], Train Loss: 0.0171, Train Acc: 0.9953
Batch [8500/8699], Train Loss: 0.0172, Train Acc: 0.9953
Batch [8600/8699], Train Loss: 0.0171, Train Acc: 0.9953
Train Loss: 0.0171, Train Acc: 0.9953
Test Accuracy: 0.9961
Confusion Matrix:
[[71858    91]
 [  458 66764]]
Saved the new best model to ../data/models/80_20_split/pklot_all_squeezenet.pth
Epoch time: 22.0284 minutes and 1.7011 seconds
Epoch 3/5
Batch [100/8699], Train Loss: 0.0155, Train Acc: 0.9958
Batch [200/8699], Train Loss: 0.0162, Train Acc: 0.9962
Batch [300/8699], Train Loss: 0.0155, Train Acc: 0.9961
Batch [400/8699], Train Loss: 0.0147, Train Acc: 0.9962
Batch [500/8699], Train Loss: 0.0157, Train Acc: 0.9959
Batch [600/8699], Train Loss: 0.0143, Train Acc: 0.9963
Batch [700/8699], Train Loss: 0.0148, Train Acc: 0.9961
Batch [800/8699], Train Loss: 0.0157, Train Acc: 0.9959
Batch [900/8699], Train Loss: 0.0153, Train Acc: 0.9960
Batch [1000/8699], Train Loss: 0.0149, Train Acc: 0.9961
Batch [1100/8699], Train Loss: 0.0147, Train Acc: 0.9962
Batch [1200/8699], Train Loss: 0.0145, Train Acc: 0.9962
Batch [1300/8699], Train Loss: 0.0143, Train Acc: 0.9962
Batch [1400/8699], Train Loss: 0.0144, Train Acc: 0.9963
Batch [1500/8699], Train Loss: 0.0144, Train Acc: 0.9963
Batch [1600/8699], Train Loss: 0.0146, Train Acc: 0.9962
Batch [1700/8699], Train Loss: 0.0146, Train Acc: 0.9962
Batch [1800/8699], Train Loss: 0.0147, Train Acc: 0.9962
Batch [1900/8699], Train Loss: 0.0146, Train Acc: 0.9962
Batch [2000/8699], Train Loss: 0.0146, Train Acc: 0.9962
Batch [2100/8699], Train Loss: 0.0144, Train Acc: 0.9962
Batch [2200/8699], Train Loss: 0.0143, Train Acc: 0.9963
Batch [2300/8699], Train Loss: 0.0141, Train Acc: 0.9963
Batch [2400/8699], Train Loss: 0.0140, Train Acc: 0.9963
Batch [2500/8699], Train Loss: 0.0140, Train Acc: 0.9964
Batch [2600/8699], Train Loss: 0.0141, Train Acc: 0.9963
Batch [2700/8699], Train Loss: 0.0140, Train Acc: 0.9963
Batch [2800/8699], Train Loss: 0.0138, Train Acc: 0.9963
Batch [2900/8699], Train Loss: 0.0138, Train Acc: 0.9963
Batch [3000/8699], Train Loss: 0.0140, Train Acc: 0.9963
Batch [3100/8699], Train Loss: 0.0139, Train Acc: 0.9963
Batch [3200/8699], Train Loss: 0.0140, Train Acc: 0.9963
Batch [3300/8699], Train Loss: 0.0139, Train Acc: 0.9963
Batch [3400/8699], Train Loss: 0.0139, Train Acc: 0.9964
Batch [3500/8699], Train Loss: 0.0139, Train Acc: 0.9964
Batch [3600/8699], Train Loss: 0.0138, Train Acc: 0.9965
Batch [3700/8699], Train Loss: 0.0138, Train Acc: 0.9965
Batch [3800/8699], Train Loss: 0.0137, Train Acc: 0.9965
Batch [3900/8699], Train Loss: 0.0135, Train Acc: 0.9965
Batch [4000/8699], Train Loss: 0.0137, Train Acc: 0.9965
Batch [4100/8699], Train Loss: 0.0138, Train Acc: 0.9964
Batch [4200/8699], Train Loss: 0.0138, Train Acc: 0.9964
Batch [4300/8699], Train Loss: 0.0138, Train Acc: 0.9964
Batch [4400/8699], Train Loss: 0.0138, Train Acc: 0.9964
Batch [4500/8699], Train Loss: 0.0137, Train Acc: 0.9964
Batch [4600/8699], Train Loss: 0.0136, Train Acc: 0.9965
Batch [4700/8699], Train Loss: 0.0136, Train Acc: 0.9965
Batch [4800/8699], Train Loss: 0.0136, Train Acc: 0.9965
Batch [4900/8699], Train Loss: 0.0136, Train Acc: 0.9965
Batch [5000/8699], Train Loss: 0.0135, Train Acc: 0.9965
Batch [5100/8699], Train Loss: 0.0136, Train Acc: 0.9965
Batch [5200/8699], Train Loss: 0.0135, Train Acc: 0.9965
Batch [5300/8699], Train Loss: 0.0135, Train Acc: 0.9965
Batch [5400/8699], Train Loss: 0.0134, Train Acc: 0.9965
Batch [5500/8699], Train Loss: 0.0134, Train Acc: 0.9966
Batch [5600/8699], Train Loss: 0.0134, Train Acc: 0.9965
Batch [5700/8699], Train Loss: 0.0135, Train Acc: 0.9965
Batch [5800/8699], Train Loss: 0.0135, Train Acc: 0.9965
Batch [5900/8699], Train Loss: 0.0135, Train Acc: 0.9965
Batch [6000/8699], Train Loss: 0.0134, Train Acc: 0.9965
Batch [6100/8699], Train Loss: 0.0134, Train Acc: 0.9965
Batch [6200/8699], Train Loss: 0.0133, Train Acc: 0.9966
Batch [6300/8699], Train Loss: 0.0132, Train Acc: 0.9966
Batch [6400/8699], Train Loss: 0.0133, Train Acc: 0.9966
Batch [6500/8699], Train Loss: 0.0132, Train Acc: 0.9966
Batch [6600/8699], Train Loss: 0.0133, Train Acc: 0.9966
Batch [6700/8699], Train Loss: 0.0134, Train Acc: 0.9966
Batch [6800/8699], Train Loss: 0.0133, Train Acc: 0.9966
Batch [6900/8699], Train Loss: 0.0133, Train Acc: 0.9966
Batch [7000/8699], Train Loss: 0.0133, Train Acc: 0.9966
Batch [7100/8699], Train Loss: 0.0133, Train Acc: 0.9966
Batch [7200/8699], Train Loss: 0.0132, Train Acc: 0.9966
Batch [7300/8699], Train Loss: 0.0132, Train Acc: 0.9966
Batch [7400/8699], Train Loss: 0.0131, Train Acc: 0.9966
Batch [7500/8699], Train Loss: 0.0132, Train Acc: 0.9966
Batch [7600/8699], Train Loss: 0.0131, Train Acc: 0.9966
Batch [7700/8699], Train Loss: 0.0131, Train Acc: 0.9966
Batch [7800/8699], Train Loss: 0.0132, Train Acc: 0.9966
Batch [7900/8699], Train Loss: 0.0132, Train Acc: 0.9966
Batch [8000/8699], Train Loss: 0.0132, Train Acc: 0.9966
Batch [8100/8699], Train Loss: 0.0132, Train Acc: 0.9966
Batch [8200/8699], Train Loss: 0.0133, Train Acc: 0.9966
Batch [8300/8699], Train Loss: 0.0133, Train Acc: 0.9966
Batch [8400/8699], Train Loss: 0.0132, Train Acc: 0.9966
Batch [8500/8699], Train Loss: 0.0132, Train Acc: 0.9966
Batch [8600/8699], Train Loss: 0.0132, Train Acc: 0.9966
Train Loss: 0.0132, Train Acc: 0.9967
Test Accuracy: 0.9943
Confusion Matrix:
[[71878    71]
 [  716 66506]]
Saved the new best model to ../data/models/80_20_split/pklot_all_squeezenet.pth
Epoch time: 25.0582 minutes and 3.4922 seconds
Epoch 4/5
Batch [100/8699], Train Loss: 0.0140, Train Acc: 0.9956
Batch [200/8699], Train Loss: 0.0112, Train Acc: 0.9963
Batch [300/8699], Train Loss: 0.0119, Train Acc: 0.9965
Batch [400/8699], Train Loss: 0.0107, Train Acc: 0.9968
Batch [500/8699], Train Loss: 0.0102, Train Acc: 0.9968
Batch [600/8699], Train Loss: 0.0109, Train Acc: 0.9966
Batch [700/8699], Train Loss: 0.0116, Train Acc: 0.9967
Batch [800/8699], Train Loss: 0.0125, Train Acc: 0.9966
Batch [900/8699], Train Loss: 0.0123, Train Acc: 0.9966
Batch [1000/8699], Train Loss: 0.0122, Train Acc: 0.9967
Batch [1100/8699], Train Loss: 0.0120, Train Acc: 0.9967
Batch [1200/8699], Train Loss: 0.0119, Train Acc: 0.9968
Batch [1300/8699], Train Loss: 0.0128, Train Acc: 0.9967
Batch [1400/8699], Train Loss: 0.0125, Train Acc: 0.9968
Batch [1500/8699], Train Loss: 0.0127, Train Acc: 0.9968
Batch [1600/8699], Train Loss: 0.0126, Train Acc: 0.9968
Batch [1700/8699], Train Loss: 0.0124, Train Acc: 0.9968
Batch [1800/8699], Train Loss: 0.0122, Train Acc: 0.9968
Batch [1900/8699], Train Loss: 0.0121, Train Acc: 0.9969
Batch [2000/8699], Train Loss: 0.0122, Train Acc: 0.9969
Batch [2100/8699], Train Loss: 0.0122, Train Acc: 0.9968
Batch [2200/8699], Train Loss: 0.0120, Train Acc: 0.9969
Batch [2300/8699], Train Loss: 0.0119, Train Acc: 0.9969
Batch [2400/8699], Train Loss: 0.0120, Train Acc: 0.9968
Batch [2500/8699], Train Loss: 0.0120, Train Acc: 0.9969
Batch [2600/8699], Train Loss: 0.0117, Train Acc: 0.9969
Batch [2700/8699], Train Loss: 0.0117, Train Acc: 0.9969
Batch [2800/8699], Train Loss: 0.0117, Train Acc: 0.9969
Batch [2900/8699], Train Loss: 0.0116, Train Acc: 0.9970
Batch [3000/8699], Train Loss: 0.0116, Train Acc: 0.9970
Batch [3100/8699], Train Loss: 0.0115, Train Acc: 0.9970
Batch [3200/8699], Train Loss: 0.0118, Train Acc: 0.9969
Batch [3300/8699], Train Loss: 0.0120, Train Acc: 0.9969
Batch [3400/8699], Train Loss: 0.0119, Train Acc: 0.9969
Batch [3500/8699], Train Loss: 0.0119, Train Acc: 0.9969
Batch [3600/8699], Train Loss: 0.0119, Train Acc: 0.9969
Batch [3700/8699], Train Loss: 0.0119, Train Acc: 0.9969
Batch [3800/8699], Train Loss: 0.0120, Train Acc: 0.9969
Batch [3900/8699], Train Loss: 0.0120, Train Acc: 0.9969
Batch [4000/8699], Train Loss: 0.0119, Train Acc: 0.9969
Batch [4100/8699], Train Loss: 0.0119, Train Acc: 0.9969
Batch [4200/8699], Train Loss: 0.0119, Train Acc: 0.9969
Batch [4300/8699], Train Loss: 0.0119, Train Acc: 0.9969
Batch [4400/8699], Train Loss: 0.0119, Train Acc: 0.9969
Batch [4500/8699], Train Loss: 0.0118, Train Acc: 0.9970
Batch [4600/8699], Train Loss: 0.0119, Train Acc: 0.9969
Batch [4700/8699], Train Loss: 0.0118, Train Acc: 0.9970
Batch [4800/8699], Train Loss: 0.0118, Train Acc: 0.9970
Batch [4900/8699], Train Loss: 0.0118, Train Acc: 0.9970
Batch [5000/8699], Train Loss: 0.0118, Train Acc: 0.9970
Batch [5100/8699], Train Loss: 0.0118, Train Acc: 0.9970
Batch [5200/8699], Train Loss: 0.0118, Train Acc: 0.9970
Batch [5300/8699], Train Loss: 0.0117, Train Acc: 0.9970
Batch [5400/8699], Train Loss: 0.0118, Train Acc: 0.9970
Batch [5500/8699], Train Loss: 0.0117, Train Acc: 0.9971
Batch [5600/8699], Train Loss: 0.0117, Train Acc: 0.9971
Batch [5700/8699], Train Loss: 0.0117, Train Acc: 0.9971
Batch [5800/8699], Train Loss: 0.0117, Train Acc: 0.9971
Batch [5900/8699], Train Loss: 0.0117, Train Acc: 0.9971
Batch [6000/8699], Train Loss: 0.0118, Train Acc: 0.9970
Batch [6100/8699], Train Loss: 0.0117, Train Acc: 0.9970
Batch [6200/8699], Train Loss: 0.0117, Train Acc: 0.9970
Batch [6300/8699], Train Loss: 0.0118, Train Acc: 0.9970
Batch [6400/8699], Train Loss: 0.0118, Train Acc: 0.9970
Batch [6500/8699], Train Loss: 0.0118, Train Acc: 0.9970
Batch [6600/8699], Train Loss: 0.0118, Train Acc: 0.9970
Batch [6700/8699], Train Loss: 0.0118, Train Acc: 0.9971
Batch [6800/8699], Train Loss: 0.0118, Train Acc: 0.9971
Batch [6900/8699], Train Loss: 0.0118, Train Acc: 0.9971
Batch [7000/8699], Train Loss: 0.0118, Train Acc: 0.9971
Batch [7100/8699], Train Loss: 0.0117, Train Acc: 0.9971
Batch [7200/8699], Train Loss: 0.0117, Train Acc: 0.9971
Batch [7300/8699], Train Loss: 0.0117, Train Acc: 0.9971
Batch [7400/8699], Train Loss: 0.0116, Train Acc: 0.9971
Batch [7500/8699], Train Loss: 0.0117, Train Acc: 0.9971
Batch [7600/8699], Train Loss: 0.0116, Train Acc: 0.9971
Batch [7700/8699], Train Loss: 0.0116, Train Acc: 0.9971
Batch [7800/8699], Train Loss: 0.0115, Train Acc: 0.9971
Batch [7900/8699], Train Loss: 0.0116, Train Acc: 0.9971
Batch [8000/8699], Train Loss: 0.0115, Train Acc: 0.9971
Batch [8100/8699], Train Loss: 0.0115, Train Acc: 0.9971
Batch [8200/8699], Train Loss: 0.0115, Train Acc: 0.9971
Batch [8300/8699], Train Loss: 0.0115, Train Acc: 0.9971
Batch [8400/8699], Train Loss: 0.0115, Train Acc: 0.9971
Batch [8500/8699], Train Loss: 0.0115, Train Acc: 0.9971
Batch [8600/8699], Train Loss: 0.0115, Train Acc: 0.9971
Train Loss: 0.0115, Train Acc: 0.9972
Test Accuracy: 0.9983
Confusion Matrix:
[[71837   112]
 [  127 67095]]
Saved the new best model to ../data/models/80_20_split/pklot_all_squeezenet.pth
Epoch time: 26.5830 minutes and 34.9799 seconds
Epoch 5/5
Batch [100/8699], Train Loss: 0.0070, Train Acc: 0.9988
Batch [200/8699], Train Loss: 0.0112, Train Acc: 0.9978
Batch [300/8699], Train Loss: 0.0110, Train Acc: 0.9974
Batch [400/8699], Train Loss: 0.0107, Train Acc: 0.9976
Batch [500/8699], Train Loss: 0.0100, Train Acc: 0.9978
Batch [600/8699], Train Loss: 0.0101, Train Acc: 0.9977
Batch [700/8699], Train Loss: 0.0096, Train Acc: 0.9977
Batch [800/8699], Train Loss: 0.0104, Train Acc: 0.9976
Batch [900/8699], Train Loss: 0.0104, Train Acc: 0.9976
Batch [1000/8699], Train Loss: 0.0109, Train Acc: 0.9975
Batch [1100/8699], Train Loss: 0.0107, Train Acc: 0.9975
Batch [1200/8699], Train Loss: 0.0109, Train Acc: 0.9975
Batch [1300/8699], Train Loss: 0.0109, Train Acc: 0.9974
Batch [1400/8699], Train Loss: 0.0108, Train Acc: 0.9975
Batch [1500/8699], Train Loss: 0.0107, Train Acc: 0.9975
Batch [1600/8699], Train Loss: 0.0107, Train Acc: 0.9975
Batch [1700/8699], Train Loss: 0.0105, Train Acc: 0.9975
Batch [1800/8699], Train Loss: 0.0106, Train Acc: 0.9976
Batch [1900/8699], Train Loss: 0.0104, Train Acc: 0.9976
Batch [2000/8699], Train Loss: 0.0103, Train Acc: 0.9976
Batch [2100/8699], Train Loss: 0.0102, Train Acc: 0.9976
Batch [2200/8699], Train Loss: 0.0101, Train Acc: 0.9976
Batch [2300/8699], Train Loss: 0.0100, Train Acc: 0.9976
Batch [2400/8699], Train Loss: 0.0101, Train Acc: 0.9976
Batch [2500/8699], Train Loss: 0.0103, Train Acc: 0.9976
Batch [2600/8699], Train Loss: 0.0100, Train Acc: 0.9976
Batch [2700/8699], Train Loss: 0.0101, Train Acc: 0.9976
Batch [2800/8699], Train Loss: 0.0100, Train Acc: 0.9976
Batch [2900/8699], Train Loss: 0.0100, Train Acc: 0.9976
Batch [3000/8699], Train Loss: 0.0100, Train Acc: 0.9976
Batch [3100/8699], Train Loss: 0.0101, Train Acc: 0.9976
Batch [3200/8699], Train Loss: 0.0099, Train Acc: 0.9976
Batch [3300/8699], Train Loss: 0.0100, Train Acc: 0.9976
Batch [3400/8699], Train Loss: 0.0101, Train Acc: 0.9976
Batch [3500/8699], Train Loss: 0.0102, Train Acc: 0.9976
Batch [3600/8699], Train Loss: 0.0102, Train Acc: 0.9976
Batch [3700/8699], Train Loss: 0.0102, Train Acc: 0.9976
Batch [3800/8699], Train Loss: 0.0102, Train Acc: 0.9976
Batch [3900/8699], Train Loss: 0.0104, Train Acc: 0.9976
Batch [4000/8699], Train Loss: 0.0104, Train Acc: 0.9975
Batch [4100/8699], Train Loss: 0.0105, Train Acc: 0.9975
Batch [4200/8699], Train Loss: 0.0105, Train Acc: 0.9975
Batch [4300/8699], Train Loss: 0.0105, Train Acc: 0.9975
Batch [4400/8699], Train Loss: 0.0107, Train Acc: 0.9975
Batch [4500/8699], Train Loss: 0.0107, Train Acc: 0.9975
Batch [4600/8699], Train Loss: 0.0106, Train Acc: 0.9975
Batch [4700/8699], Train Loss: 0.0105, Train Acc: 0.9975
Batch [4800/8699], Train Loss: 0.0106, Train Acc: 0.9975
Batch [4900/8699], Train Loss: 0.0105, Train Acc: 0.9975
Batch [5000/8699], Train Loss: 0.0106, Train Acc: 0.9975
Batch [5100/8699], Train Loss: 0.0105, Train Acc: 0.9975
Batch [5200/8699], Train Loss: 0.0105, Train Acc: 0.9975
Batch [5300/8699], Train Loss: 0.0105, Train Acc: 0.9975
Batch [5400/8699], Train Loss: 0.0105, Train Acc: 0.9975
Batch [5500/8699], Train Loss: 0.0105, Train Acc: 0.9975
Batch [5600/8699], Train Loss: 0.0106, Train Acc: 0.9975
Batch [5700/8699], Train Loss: 0.0105, Train Acc: 0.9975
Batch [5800/8699], Train Loss: 0.0104, Train Acc: 0.9975
Batch [5900/8699], Train Loss: 0.0105, Train Acc: 0.9975
Batch [6000/8699], Train Loss: 0.0105, Train Acc: 0.9975
Batch [6100/8699], Train Loss: 0.0105, Train Acc: 0.9975
Batch [6200/8699], Train Loss: 0.0105, Train Acc: 0.9975
Batch [6300/8699], Train Loss: 0.0105, Train Acc: 0.9975
Batch [6400/8699], Train Loss: 0.0106, Train Acc: 0.9975
Batch [6500/8699], Train Loss: 0.0107, Train Acc: 0.9975
Batch [6600/8699], Train Loss: 0.0106, Train Acc: 0.9975
Batch [6700/8699], Train Loss: 0.0106, Train Acc: 0.9975
Batch [6800/8699], Train Loss: 0.0106, Train Acc: 0.9975
Batch [6900/8699], Train Loss: 0.0105, Train Acc: 0.9975
Batch [7000/8699], Train Loss: 0.0105, Train Acc: 0.9975
Batch [7100/8699], Train Loss: 0.0106, Train Acc: 0.9975
Batch [7200/8699], Train Loss: 0.0106, Train Acc: 0.9975
Batch [7300/8699], Train Loss: 0.0106, Train Acc: 0.9975
Batch [7400/8699], Train Loss: 0.0105, Train Acc: 0.9975
Batch [7500/8699], Train Loss: 0.0105, Train Acc: 0.9975
Batch [7600/8699], Train Loss: 0.0105, Train Acc: 0.9975
Batch [7700/8699], Train Loss: 0.0104, Train Acc: 0.9975
Batch [7800/8699], Train Loss: 0.0104, Train Acc: 0.9975
Batch [7900/8699], Train Loss: 0.0104, Train Acc: 0.9975
Batch [8000/8699], Train Loss: 0.0104, Train Acc: 0.9975
Batch [8100/8699], Train Loss: 0.0104, Train Acc: 0.9975
Batch [8200/8699], Train Loss: 0.0105, Train Acc: 0.9975
Batch [8300/8699], Train Loss: 0.0105, Train Acc: 0.9975
Batch [8400/8699], Train Loss: 0.0105, Train Acc: 0.9975
Batch [8500/8699], Train Loss: 0.0105, Train Acc: 0.9975
Batch [8600/8699], Train Loss: 0.0105, Train Acc: 0.9975
Train Loss: 0.0105, Train Acc: 0.9975
Test Accuracy: 0.9977
Confusion Matrix:
[[71750   199]
 [  126 67096]]
Saved the new best model to ../data/models/80_20_split/pklot_all_squeezenet.pth
Epoch time: 21.8750 minutes and 52.5029 seconds
Best Train Acc: 0.9975
Total training time: 117.46499240795771 minutes and 27.89954447746277 seconds
