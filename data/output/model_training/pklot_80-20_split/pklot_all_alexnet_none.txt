Epoch 1/5
Batch [100/8699], Train Loss: 1.5688, Train Acc: 0.7205
Batch [200/8699], Train Loss: 0.8396, Train Acc: 0.8432
Batch [300/8699], Train Loss: 0.5931, Train Acc: 0.8856
Batch [400/8699], Train Loss: 0.4646, Train Acc: 0.9081
Batch [500/8699], Train Loss: 0.3879, Train Acc: 0.9220
Batch [600/8699], Train Loss: 0.3366, Train Acc: 0.9310
Batch [700/8699], Train Loss: 0.3004, Train Acc: 0.9373
Batch [800/8699], Train Loss: 0.2722, Train Acc: 0.9425
Batch [900/8699], Train Loss: 0.2498, Train Acc: 0.9463
Batch [1000/8699], Train Loss: 0.2318, Train Acc: 0.9497
Batch [1100/8699], Train Loss: 0.2161, Train Acc: 0.9525
Batch [1200/8699], Train Loss: 0.2025, Train Acc: 0.9551
Batch [1300/8699], Train Loss: 0.1913, Train Acc: 0.9573
Batch [1400/8699], Train Loss: 0.1818, Train Acc: 0.9591
Batch [1500/8699], Train Loss: 0.1724, Train Acc: 0.9611
Batch [1600/8699], Train Loss: 0.1646, Train Acc: 0.9626
Batch [1700/8699], Train Loss: 0.1577, Train Acc: 0.9641
Batch [1800/8699], Train Loss: 0.1510, Train Acc: 0.9655
Batch [1900/8699], Train Loss: 0.1457, Train Acc: 0.9665
Batch [2000/8699], Train Loss: 0.1405, Train Acc: 0.9676
Batch [2100/8699], Train Loss: 0.1356, Train Acc: 0.9686
Batch [2200/8699], Train Loss: 0.1313, Train Acc: 0.9693
Batch [2300/8699], Train Loss: 0.1275, Train Acc: 0.9701
Batch [2400/8699], Train Loss: 0.1237, Train Acc: 0.9710
Batch [2500/8699], Train Loss: 0.1202, Train Acc: 0.9717
Batch [2600/8699], Train Loss: 0.1169, Train Acc: 0.9725
Batch [2700/8699], Train Loss: 0.1138, Train Acc: 0.9731
Batch [2800/8699], Train Loss: 0.1111, Train Acc: 0.9737
Batch [2900/8699], Train Loss: 0.1080, Train Acc: 0.9743
Batch [3000/8699], Train Loss: 0.1054, Train Acc: 0.9748
Batch [3100/8699], Train Loss: 0.1028, Train Acc: 0.9754
Batch [3200/8699], Train Loss: 0.1007, Train Acc: 0.9759
Batch [3300/8699], Train Loss: 0.0986, Train Acc: 0.9763
Batch [3400/8699], Train Loss: 0.0967, Train Acc: 0.9768
Batch [3500/8699], Train Loss: 0.0950, Train Acc: 0.9771
Batch [3600/8699], Train Loss: 0.0935, Train Acc: 0.9775
Batch [3700/8699], Train Loss: 0.0918, Train Acc: 0.9779
Batch [3800/8699], Train Loss: 0.0902, Train Acc: 0.9782
Batch [3900/8699], Train Loss: 0.0886, Train Acc: 0.9785
Batch [4000/8699], Train Loss: 0.0869, Train Acc: 0.9789
Batch [4100/8699], Train Loss: 0.0855, Train Acc: 0.9792
Batch [4200/8699], Train Loss: 0.0845, Train Acc: 0.9795
Batch [4300/8699], Train Loss: 0.0844, Train Acc: 0.9794
Batch [4400/8699], Train Loss: 0.0835, Train Acc: 0.9795
Batch [4500/8699], Train Loss: 0.0824, Train Acc: 0.9798
Batch [4600/8699], Train Loss: 0.0812, Train Acc: 0.9801
Batch [4700/8699], Train Loss: 0.0803, Train Acc: 0.9803
Batch [4800/8699], Train Loss: 0.0792, Train Acc: 0.9805
Batch [4900/8699], Train Loss: 0.0782, Train Acc: 0.9807
Batch [5000/8699], Train Loss: 0.0772, Train Acc: 0.9810
Batch [5100/8699], Train Loss: 0.0763, Train Acc: 0.9812
Batch [5200/8699], Train Loss: 0.0755, Train Acc: 0.9814
Batch [5300/8699], Train Loss: 0.0745, Train Acc: 0.9816
Batch [5400/8699], Train Loss: 0.0737, Train Acc: 0.9818
Batch [5500/8699], Train Loss: 0.0728, Train Acc: 0.9821
Batch [5600/8699], Train Loss: 0.0719, Train Acc: 0.9823
Batch [5700/8699], Train Loss: 0.0711, Train Acc: 0.9824
Batch [5800/8699], Train Loss: 0.0703, Train Acc: 0.9826
Batch [5900/8699], Train Loss: 0.0697, Train Acc: 0.9827
Batch [6000/8699], Train Loss: 0.0690, Train Acc: 0.9829
Batch [6100/8699], Train Loss: 0.0683, Train Acc: 0.9831
Batch [6200/8699], Train Loss: 0.0676, Train Acc: 0.9832
Batch [6300/8699], Train Loss: 0.0669, Train Acc: 0.9834
Batch [6400/8699], Train Loss: 0.0663, Train Acc: 0.9835
Batch [6500/8699], Train Loss: 0.0657, Train Acc: 0.9837
Batch [6600/8699], Train Loss: 0.0650, Train Acc: 0.9839
Batch [6700/8699], Train Loss: 0.0644, Train Acc: 0.9840
Batch [6800/8699], Train Loss: 0.0638, Train Acc: 0.9842
Batch [6900/8699], Train Loss: 0.0632, Train Acc: 0.9843
Batch [7000/8699], Train Loss: 0.0627, Train Acc: 0.9844
Batch [7100/8699], Train Loss: 0.0621, Train Acc: 0.9846
Batch [7200/8699], Train Loss: 0.0616, Train Acc: 0.9847
Batch [7300/8699], Train Loss: 0.0611, Train Acc: 0.9848
Batch [7400/8699], Train Loss: 0.0606, Train Acc: 0.9849
Batch [7500/8699], Train Loss: 0.0601, Train Acc: 0.9850
Batch [7600/8699], Train Loss: 0.0595, Train Acc: 0.9852
Batch [7700/8699], Train Loss: 0.0590, Train Acc: 0.9853
Batch [7800/8699], Train Loss: 0.0586, Train Acc: 0.9854
Batch [7900/8699], Train Loss: 0.0581, Train Acc: 0.9855
Batch [8000/8699], Train Loss: 0.0577, Train Acc: 0.9856
Batch [8100/8699], Train Loss: 0.0572, Train Acc: 0.9858
Batch [8200/8699], Train Loss: 0.0568, Train Acc: 0.9859
Batch [8300/8699], Train Loss: 0.0566, Train Acc: 0.9859
Batch [8400/8699], Train Loss: 0.0561, Train Acc: 0.9860
Batch [8500/8699], Train Loss: 0.0557, Train Acc: 0.9861
Batch [8600/8699], Train Loss: 0.0553, Train Acc: 0.9862
Train Loss: 0.0549, Train Acc: 0.9863
Test Accuracy: 0.9957
Confusion Matrix:
[[71100   465]
 [  132 67474]]
Saved the new best model to ../data/models/80_20_split/pklot_all_alexnet_None.pth
Epoch time: 13.8736 minutes and 52.4182 seconds
Epoch 2/5
Batch [100/8699], Train Loss: 0.0285, Train Acc: 0.9930
Batch [200/8699], Train Loss: 0.0239, Train Acc: 0.9941
Batch [300/8699], Train Loss: 0.0240, Train Acc: 0.9938
Batch [400/8699], Train Loss: 0.0221, Train Acc: 0.9943
Batch [500/8699], Train Loss: 0.0223, Train Acc: 0.9943
Batch [600/8699], Train Loss: 0.0239, Train Acc: 0.9941
Batch [700/8699], Train Loss: 0.0234, Train Acc: 0.9940
Batch [800/8699], Train Loss: 0.0232, Train Acc: 0.9941
Batch [900/8699], Train Loss: 0.0232, Train Acc: 0.9941
Batch [1000/8699], Train Loss: 0.0233, Train Acc: 0.9941
Batch [1100/8699], Train Loss: 0.0235, Train Acc: 0.9941
Batch [1200/8699], Train Loss: 0.0239, Train Acc: 0.9940
Batch [1300/8699], Train Loss: 0.0232, Train Acc: 0.9942
Batch [1400/8699], Train Loss: 0.0227, Train Acc: 0.9943
Batch [1500/8699], Train Loss: 0.0248, Train Acc: 0.9938
Batch [1600/8699], Train Loss: 0.0260, Train Acc: 0.9935
Batch [1700/8699], Train Loss: 0.0266, Train Acc: 0.9934
Batch [1800/8699], Train Loss: 0.0264, Train Acc: 0.9933
Batch [1900/8699], Train Loss: 0.0266, Train Acc: 0.9932
Batch [2000/8699], Train Loss: 0.0273, Train Acc: 0.9931
Batch [2100/8699], Train Loss: 0.0272, Train Acc: 0.9931
Batch [2200/8699], Train Loss: 0.0268, Train Acc: 0.9932
Batch [2300/8699], Train Loss: 0.0267, Train Acc: 0.9932
Batch [2400/8699], Train Loss: 0.0268, Train Acc: 0.9932
Batch [2500/8699], Train Loss: 0.0272, Train Acc: 0.9932
Batch [2600/8699], Train Loss: 0.0274, Train Acc: 0.9932
Batch [2700/8699], Train Loss: 0.0277, Train Acc: 0.9931
Batch [2800/8699], Train Loss: 0.0272, Train Acc: 0.9932
Batch [2900/8699], Train Loss: 0.0270, Train Acc: 0.9933
Batch [3000/8699], Train Loss: 0.0267, Train Acc: 0.9934
Batch [3100/8699], Train Loss: 0.0263, Train Acc: 0.9935
Batch [3200/8699], Train Loss: 0.0261, Train Acc: 0.9935
Batch [3300/8699], Train Loss: 0.0260, Train Acc: 0.9936
Batch [3400/8699], Train Loss: 0.0260, Train Acc: 0.9936
Batch [3500/8699], Train Loss: 0.0259, Train Acc: 0.9936
Batch [3600/8699], Train Loss: 0.0259, Train Acc: 0.9937
Batch [3700/8699], Train Loss: 0.0256, Train Acc: 0.9937
Batch [3800/8699], Train Loss: 0.0257, Train Acc: 0.9937
Batch [3900/8699], Train Loss: 0.0255, Train Acc: 0.9937
Batch [4000/8699], Train Loss: 0.0254, Train Acc: 0.9937
Batch [4100/8699], Train Loss: 0.0253, Train Acc: 0.9938
Batch [4200/8699], Train Loss: 0.0256, Train Acc: 0.9937
Batch [4300/8699], Train Loss: 0.0255, Train Acc: 0.9937
Batch [4400/8699], Train Loss: 0.0255, Train Acc: 0.9937
Batch [4500/8699], Train Loss: 0.0256, Train Acc: 0.9937
Batch [4600/8699], Train Loss: 0.0256, Train Acc: 0.9937
Batch [4700/8699], Train Loss: 0.0254, Train Acc: 0.9937
Batch [4800/8699], Train Loss: 0.0252, Train Acc: 0.9937
Batch [4900/8699], Train Loss: 0.0251, Train Acc: 0.9938
Batch [5000/8699], Train Loss: 0.0251, Train Acc: 0.9938
Batch [5100/8699], Train Loss: 0.0250, Train Acc: 0.9938
Batch [5200/8699], Train Loss: 0.0249, Train Acc: 0.9939
Batch [5300/8699], Train Loss: 0.0249, Train Acc: 0.9939
Batch [5400/8699], Train Loss: 0.0248, Train Acc: 0.9939
Batch [5500/8699], Train Loss: 0.0246, Train Acc: 0.9939
Batch [5600/8699], Train Loss: 0.0244, Train Acc: 0.9940
Batch [5700/8699], Train Loss: 0.0244, Train Acc: 0.9940
Batch [5800/8699], Train Loss: 0.0244, Train Acc: 0.9940
Batch [5900/8699], Train Loss: 0.0242, Train Acc: 0.9940
Batch [6000/8699], Train Loss: 0.0241, Train Acc: 0.9940
Batch [6100/8699], Train Loss: 0.0240, Train Acc: 0.9941
Batch [6200/8699], Train Loss: 0.0239, Train Acc: 0.9941
Batch [6300/8699], Train Loss: 0.0239, Train Acc: 0.9940
Batch [6400/8699], Train Loss: 0.0238, Train Acc: 0.9941
Batch [6500/8699], Train Loss: 0.0237, Train Acc: 0.9941
Batch [6600/8699], Train Loss: 0.0237, Train Acc: 0.9941
Batch [6700/8699], Train Loss: 0.0236, Train Acc: 0.9941
Batch [6800/8699], Train Loss: 0.0236, Train Acc: 0.9941
Batch [6900/8699], Train Loss: 0.0236, Train Acc: 0.9941
Batch [7000/8699], Train Loss: 0.0236, Train Acc: 0.9941
Batch [7100/8699], Train Loss: 0.0236, Train Acc: 0.9941
Batch [7200/8699], Train Loss: 0.0236, Train Acc: 0.9941
Batch [7300/8699], Train Loss: 0.0235, Train Acc: 0.9942
Batch [7400/8699], Train Loss: 0.0234, Train Acc: 0.9942
Batch [7500/8699], Train Loss: 0.0233, Train Acc: 0.9942
Batch [7600/8699], Train Loss: 0.0233, Train Acc: 0.9942
Batch [7700/8699], Train Loss: 0.0232, Train Acc: 0.9942
Batch [7800/8699], Train Loss: 0.0232, Train Acc: 0.9942
Batch [7900/8699], Train Loss: 0.0231, Train Acc: 0.9943
Batch [8000/8699], Train Loss: 0.0232, Train Acc: 0.9943
Batch [8100/8699], Train Loss: 0.0232, Train Acc: 0.9943
Batch [8200/8699], Train Loss: 0.0231, Train Acc: 0.9943
Batch [8300/8699], Train Loss: 0.0231, Train Acc: 0.9943
Batch [8400/8699], Train Loss: 0.0233, Train Acc: 0.9943
Batch [8500/8699], Train Loss: 0.0233, Train Acc: 0.9943
Batch [8600/8699], Train Loss: 0.0234, Train Acc: 0.9942
Train Loss: 0.0233, Train Acc: 0.9943
Test Accuracy: 0.9953
Confusion Matrix:
[[71032   533]
 [  116 67490]]
Saved the new best model to ../data/models/80_20_split/pklot_all_alexnet_None.pth
Epoch time: 24.7934 minutes and 47.6041 seconds
Epoch 3/5
Batch [100/8699], Train Loss: 0.0223, Train Acc: 0.9955
Batch [200/8699], Train Loss: 0.0200, Train Acc: 0.9957
Batch [300/8699], Train Loss: 0.0163, Train Acc: 0.9965
Batch [400/8699], Train Loss: 0.0193, Train Acc: 0.9961
Batch [500/8699], Train Loss: 0.0177, Train Acc: 0.9961
Batch [600/8699], Train Loss: 0.0207, Train Acc: 0.9956
Batch [700/8699], Train Loss: 0.0214, Train Acc: 0.9952
Batch [800/8699], Train Loss: 0.0203, Train Acc: 0.9954
Batch [900/8699], Train Loss: 0.0207, Train Acc: 0.9952
Batch [1000/8699], Train Loss: 0.0205, Train Acc: 0.9951
Batch [1100/8699], Train Loss: 0.0200, Train Acc: 0.9952
Batch [1200/8699], Train Loss: 0.0192, Train Acc: 0.9953
Batch [1300/8699], Train Loss: 0.0191, Train Acc: 0.9953
Batch [1400/8699], Train Loss: 0.0193, Train Acc: 0.9952
Batch [1500/8699], Train Loss: 0.0190, Train Acc: 0.9953
Batch [1600/8699], Train Loss: 0.0188, Train Acc: 0.9954
Batch [1700/8699], Train Loss: 0.0187, Train Acc: 0.9954
Batch [1800/8699], Train Loss: 0.0189, Train Acc: 0.9954
Batch [1900/8699], Train Loss: 0.0183, Train Acc: 0.9955
Batch [2000/8699], Train Loss: 0.0187, Train Acc: 0.9955
Batch [2100/8699], Train Loss: 0.0189, Train Acc: 0.9954
Batch [2200/8699], Train Loss: 0.0189, Train Acc: 0.9954
Batch [2300/8699], Train Loss: 0.0189, Train Acc: 0.9954
Batch [2400/8699], Train Loss: 0.0189, Train Acc: 0.9954
Batch [2500/8699], Train Loss: 0.0203, Train Acc: 0.9952
Batch [2600/8699], Train Loss: 0.0204, Train Acc: 0.9951
Batch [2700/8699], Train Loss: 0.0206, Train Acc: 0.9950
Batch [2800/8699], Train Loss: 0.0205, Train Acc: 0.9950
Batch [2900/8699], Train Loss: 0.0204, Train Acc: 0.9950
Batch [3000/8699], Train Loss: 0.0205, Train Acc: 0.9950
Batch [3100/8699], Train Loss: 0.0219, Train Acc: 0.9947
Batch [3200/8699], Train Loss: 0.0228, Train Acc: 0.9944
Batch [3300/8699], Train Loss: 0.0230, Train Acc: 0.9943
Batch [3400/8699], Train Loss: 0.0264, Train Acc: 0.9938
Batch [3500/8699], Train Loss: 0.0272, Train Acc: 0.9935
Batch [3600/8699], Train Loss: 0.0274, Train Acc: 0.9935
Batch [3700/8699], Train Loss: 0.0274, Train Acc: 0.9934
Batch [3800/8699], Train Loss: 0.0274, Train Acc: 0.9934
Batch [3900/8699], Train Loss: 0.0278, Train Acc: 0.9933
Batch [4000/8699], Train Loss: 0.0276, Train Acc: 0.9933
Batch [4100/8699], Train Loss: 0.0276, Train Acc: 0.9933
Batch [4200/8699], Train Loss: 0.0273, Train Acc: 0.9933
Batch [4300/8699], Train Loss: 0.0270, Train Acc: 0.9934
Batch [4400/8699], Train Loss: 0.0270, Train Acc: 0.9934
Batch [4500/8699], Train Loss: 0.0269, Train Acc: 0.9934
Batch [4600/8699], Train Loss: 0.0266, Train Acc: 0.9935
Batch [4700/8699], Train Loss: 0.0264, Train Acc: 0.9936
Batch [4800/8699], Train Loss: 0.0262, Train Acc: 0.9936
Batch [4900/8699], Train Loss: 0.0260, Train Acc: 0.9937
Batch [5000/8699], Train Loss: 0.0259, Train Acc: 0.9937
Batch [5100/8699], Train Loss: 0.0257, Train Acc: 0.9937
Batch [5200/8699], Train Loss: 0.0255, Train Acc: 0.9938
Batch [5300/8699], Train Loss: 0.0254, Train Acc: 0.9938
Batch [5400/8699], Train Loss: 0.0252, Train Acc: 0.9939
Batch [5500/8699], Train Loss: 0.0251, Train Acc: 0.9939
Batch [5600/8699], Train Loss: 0.0249, Train Acc: 0.9939
Batch [5700/8699], Train Loss: 0.0247, Train Acc: 0.9940
Batch [5800/8699], Train Loss: 0.0246, Train Acc: 0.9940
Batch [5900/8699], Train Loss: 0.0245, Train Acc: 0.9940
Batch [6000/8699], Train Loss: 0.0243, Train Acc: 0.9941
Batch [6100/8699], Train Loss: 0.0240, Train Acc: 0.9941
Batch [6200/8699], Train Loss: 0.0239, Train Acc: 0.9941
Batch [6300/8699], Train Loss: 0.0238, Train Acc: 0.9942
Batch [6400/8699], Train Loss: 0.0238, Train Acc: 0.9942
Batch [6500/8699], Train Loss: 0.0237, Train Acc: 0.9942
Batch [6600/8699], Train Loss: 0.0236, Train Acc: 0.9943
Batch [6700/8699], Train Loss: 0.0234, Train Acc: 0.9943
Batch [6800/8699], Train Loss: 0.0233, Train Acc: 0.9943
Batch [6900/8699], Train Loss: 0.0234, Train Acc: 0.9944
Batch [7000/8699], Train Loss: 0.0233, Train Acc: 0.9944
Batch [7100/8699], Train Loss: 0.0231, Train Acc: 0.9944
Batch [7200/8699], Train Loss: 0.0230, Train Acc: 0.9944
Batch [7300/8699], Train Loss: 0.0229, Train Acc: 0.9944
Batch [7400/8699], Train Loss: 0.0229, Train Acc: 0.9945
Batch [7500/8699], Train Loss: 0.0230, Train Acc: 0.9944
Batch [7600/8699], Train Loss: 0.0230, Train Acc: 0.9945
Batch [7700/8699], Train Loss: 0.0228, Train Acc: 0.9945
Batch [7800/8699], Train Loss: 0.0228, Train Acc: 0.9945
Batch [7900/8699], Train Loss: 0.0227, Train Acc: 0.9945
Batch [8000/8699], Train Loss: 0.0225, Train Acc: 0.9946
Batch [8100/8699], Train Loss: 0.0224, Train Acc: 0.9946
Batch [8200/8699], Train Loss: 0.0223, Train Acc: 0.9946
Batch [8300/8699], Train Loss: 0.0222, Train Acc: 0.9946
Batch [8400/8699], Train Loss: 0.0221, Train Acc: 0.9946
Batch [8500/8699], Train Loss: 0.0220, Train Acc: 0.9947
Batch [8600/8699], Train Loss: 0.0219, Train Acc: 0.9947
Train Loss: 0.0218, Train Acc: 0.9947
Test Accuracy: 0.9967
Confusion Matrix:
[[71350   215]
 [  238 67368]]
Saved the new best model to ../data/models/80_20_split/pklot_all_alexnet_None.pth
Epoch time: 33.7413 minutes and 44.4805 seconds
Epoch 4/5
Batch [100/8699], Train Loss: 0.0215, Train Acc: 0.9950
Batch [200/8699], Train Loss: 0.0187, Train Acc: 0.9956
Batch [300/8699], Train Loss: 0.0171, Train Acc: 0.9960
Batch [400/8699], Train Loss: 0.0170, Train Acc: 0.9961
Batch [500/8699], Train Loss: 0.0172, Train Acc: 0.9959
Batch [600/8699], Train Loss: 0.0173, Train Acc: 0.9959
Batch [700/8699], Train Loss: 0.0172, Train Acc: 0.9959
Batch [800/8699], Train Loss: 0.0177, Train Acc: 0.9959
Batch [900/8699], Train Loss: 0.0173, Train Acc: 0.9960
Batch [1000/8699], Train Loss: 0.0173, Train Acc: 0.9958
Batch [1100/8699], Train Loss: 0.0184, Train Acc: 0.9955
Batch [1200/8699], Train Loss: 0.0181, Train Acc: 0.9956
Batch [1300/8699], Train Loss: 0.0176, Train Acc: 0.9956
Batch [1400/8699], Train Loss: 0.0175, Train Acc: 0.9957
Batch [1500/8699], Train Loss: 0.0174, Train Acc: 0.9958
Batch [1600/8699], Train Loss: 0.0177, Train Acc: 0.9956
Batch [1700/8699], Train Loss: 0.0180, Train Acc: 0.9956
Batch [1800/8699], Train Loss: 0.0183, Train Acc: 0.9956
Batch [1900/8699], Train Loss: 0.0181, Train Acc: 0.9956
Batch [2000/8699], Train Loss: 0.0181, Train Acc: 0.9955
Batch [2100/8699], Train Loss: 0.0179, Train Acc: 0.9956
Batch [2200/8699], Train Loss: 0.0178, Train Acc: 0.9956
Batch [2300/8699], Train Loss: 0.0175, Train Acc: 0.9957
Batch [2400/8699], Train Loss: 0.0174, Train Acc: 0.9957
Batch [2500/8699], Train Loss: 0.0175, Train Acc: 0.9957
Batch [2600/8699], Train Loss: 0.0175, Train Acc: 0.9957
Batch [2700/8699], Train Loss: 0.0181, Train Acc: 0.9956
Batch [2800/8699], Train Loss: 0.0178, Train Acc: 0.9956
Batch [2900/8699], Train Loss: 0.0176, Train Acc: 0.9957
Batch [3000/8699], Train Loss: 0.0176, Train Acc: 0.9957
Batch [3100/8699], Train Loss: 0.0191, Train Acc: 0.9953
Batch [3200/8699], Train Loss: 0.0193, Train Acc: 0.9952
Batch [3300/8699], Train Loss: 0.0193, Train Acc: 0.9952
Batch [3400/8699], Train Loss: 0.0193, Train Acc: 0.9952
Batch [3500/8699], Train Loss: 0.0200, Train Acc: 0.9950
Batch [3600/8699], Train Loss: 0.0204, Train Acc: 0.9949
Batch [3700/8699], Train Loss: 0.0204, Train Acc: 0.9949
Batch [3800/8699], Train Loss: 0.0208, Train Acc: 0.9948
Batch [3900/8699], Train Loss: 0.0207, Train Acc: 0.9948
Batch [4000/8699], Train Loss: 0.0206, Train Acc: 0.9948
Batch [4100/8699], Train Loss: 0.0205, Train Acc: 0.9949
Batch [4200/8699], Train Loss: 0.0204, Train Acc: 0.9949
Batch [4300/8699], Train Loss: 0.0205, Train Acc: 0.9949
Batch [4400/8699], Train Loss: 0.0209, Train Acc: 0.9948
Batch [4500/8699], Train Loss: 0.0208, Train Acc: 0.9948
Batch [4600/8699], Train Loss: 0.0208, Train Acc: 0.9948
Batch [4700/8699], Train Loss: 0.0207, Train Acc: 0.9948
Batch [4800/8699], Train Loss: 0.0207, Train Acc: 0.9948
Batch [4900/8699], Train Loss: 0.0209, Train Acc: 0.9948
Batch [5000/8699], Train Loss: 0.0209, Train Acc: 0.9948
Batch [5100/8699], Train Loss: 0.0210, Train Acc: 0.9948
Batch [5200/8699], Train Loss: 0.0212, Train Acc: 0.9948
Batch [5300/8699], Train Loss: 0.0211, Train Acc: 0.9948
Batch [5400/8699], Train Loss: 0.0214, Train Acc: 0.9947
Batch [5500/8699], Train Loss: 0.0216, Train Acc: 0.9947
Batch [5600/8699], Train Loss: 0.0217, Train Acc: 0.9947
Batch [5700/8699], Train Loss: 0.0215, Train Acc: 0.9947
Batch [5800/8699], Train Loss: 0.0214, Train Acc: 0.9947
Batch [5900/8699], Train Loss: 0.0213, Train Acc: 0.9947
Batch [6000/8699], Train Loss: 0.0211, Train Acc: 0.9948
Batch [6100/8699], Train Loss: 0.0210, Train Acc: 0.9948
Batch [6200/8699], Train Loss: 0.0209, Train Acc: 0.9949
Batch [6300/8699], Train Loss: 0.0208, Train Acc: 0.9949
Batch [6400/8699], Train Loss: 0.0207, Train Acc: 0.9949
Batch [6500/8699], Train Loss: 0.0206, Train Acc: 0.9949
Batch [6600/8699], Train Loss: 0.0205, Train Acc: 0.9950
Batch [6700/8699], Train Loss: 0.0203, Train Acc: 0.9950
Batch [6800/8699], Train Loss: 0.0202, Train Acc: 0.9950
Batch [6900/8699], Train Loss: 0.0202, Train Acc: 0.9950
Batch [7000/8699], Train Loss: 0.0201, Train Acc: 0.9951
Batch [7100/8699], Train Loss: 0.0200, Train Acc: 0.9951
Batch [7200/8699], Train Loss: 0.0202, Train Acc: 0.9950
Batch [7300/8699], Train Loss: 0.0203, Train Acc: 0.9950
Batch [7400/8699], Train Loss: 0.0202, Train Acc: 0.9950
Batch [7500/8699], Train Loss: 0.0201, Train Acc: 0.9951
Batch [7600/8699], Train Loss: 0.0202, Train Acc: 0.9951
Batch [7700/8699], Train Loss: 0.0202, Train Acc: 0.9951
Batch [7800/8699], Train Loss: 0.0201, Train Acc: 0.9951
Batch [7900/8699], Train Loss: 0.0200, Train Acc: 0.9951
Batch [8000/8699], Train Loss: 0.0200, Train Acc: 0.9951
Batch [8100/8699], Train Loss: 0.0199, Train Acc: 0.9952
Batch [8200/8699], Train Loss: 0.0199, Train Acc: 0.9952
Batch [8300/8699], Train Loss: 0.0198, Train Acc: 0.9952
Batch [8400/8699], Train Loss: 0.0203, Train Acc: 0.9950
Batch [8500/8699], Train Loss: 0.0210, Train Acc: 0.9949
Batch [8600/8699], Train Loss: 0.0213, Train Acc: 0.9948
Train Loss: 0.0213, Train Acc: 0.9948
Test Accuracy: 0.9934
Confusion Matrix:
[[70778   787]
 [  136 67470]]
Saved the new best model to ../data/models/80_20_split/pklot_all_alexnet_None.pth
Epoch time: 42.6943 minutes and 41.6564 seconds
Epoch 5/5
Batch [100/8699], Train Loss: 0.0185, Train Acc: 0.9948
Batch [200/8699], Train Loss: 0.0222, Train Acc: 0.9939
Batch [300/8699], Train Loss: 0.0229, Train Acc: 0.9938
Batch [400/8699], Train Loss: 0.0231, Train Acc: 0.9941
Batch [500/8699], Train Loss: 0.0215, Train Acc: 0.9944
Batch [600/8699], Train Loss: 0.0213, Train Acc: 0.9947
Batch [700/8699], Train Loss: 0.0204, Train Acc: 0.9949
Batch [800/8699], Train Loss: 0.0202, Train Acc: 0.9950
Batch [900/8699], Train Loss: 0.0191, Train Acc: 0.9953
Batch [1000/8699], Train Loss: 0.0195, Train Acc: 0.9952
Batch [1100/8699], Train Loss: 0.0196, Train Acc: 0.9951
Batch [1200/8699], Train Loss: 0.0196, Train Acc: 0.9952
Batch [1300/8699], Train Loss: 0.0308, Train Acc: 0.9891
Batch [1400/8699], Train Loss: 0.0742, Train Acc: 0.9651
Batch [1500/8699], Train Loss: 0.0873, Train Acc: 0.9611
Batch [1600/8699], Train Loss: 0.0924, Train Acc: 0.9597
Batch [1700/8699], Train Loss: 0.0945, Train Acc: 0.9596
Batch [1800/8699], Train Loss: 0.0951, Train Acc: 0.9601
Batch [1900/8699], Train Loss: 0.0949, Train Acc: 0.9607
Batch [2000/8699], Train Loss: 0.0941, Train Acc: 0.9614
Batch [2100/8699], Train Loss: 0.0930, Train Acc: 0.9621
Batch [2200/8699], Train Loss: 0.0923, Train Acc: 0.9628
Batch [2300/8699], Train Loss: 0.0911, Train Acc: 0.9634
Batch [2400/8699], Train Loss: 0.0898, Train Acc: 0.9641
Batch [2500/8699], Train Loss: 0.0883, Train Acc: 0.9649
Batch [2600/8699], Train Loss: 0.0870, Train Acc: 0.9656
Batch [2700/8699], Train Loss: 0.0861, Train Acc: 0.9661
Batch [2800/8699], Train Loss: 0.0849, Train Acc: 0.9667
Batch [2900/8699], Train Loss: 0.0837, Train Acc: 0.9673
Batch [3000/8699], Train Loss: 0.0824, Train Acc: 0.9679
Batch [3100/8699], Train Loss: 0.0811, Train Acc: 0.9686
Batch [3200/8699], Train Loss: 0.0806, Train Acc: 0.9690
Batch [3300/8699], Train Loss: 0.0799, Train Acc: 0.9693
Batch [3400/8699], Train Loss: 0.0789, Train Acc: 0.9698
Batch [3500/8699], Train Loss: 0.0779, Train Acc: 0.9703
Batch [3600/8699], Train Loss: 0.0767, Train Acc: 0.9708
Batch [3700/8699], Train Loss: 0.0758, Train Acc: 0.9713
Batch [3800/8699], Train Loss: 0.0751, Train Acc: 0.9717
Batch [3900/8699], Train Loss: 0.0742, Train Acc: 0.9720
Batch [4000/8699], Train Loss: 0.0734, Train Acc: 0.9724
Batch [4100/8699], Train Loss: 0.0726, Train Acc: 0.9728
Batch [4200/8699], Train Loss: 0.0718, Train Acc: 0.9731
Batch [4300/8699], Train Loss: 0.0709, Train Acc: 0.9736
Batch [4400/8699], Train Loss: 0.0700, Train Acc: 0.9739
Batch [4500/8699], Train Loss: 0.0695, Train Acc: 0.9742
Batch [4600/8699], Train Loss: 0.0692, Train Acc: 0.9744
Batch [4700/8699], Train Loss: 0.0686, Train Acc: 0.9747
Batch [4800/8699], Train Loss: 0.0680, Train Acc: 0.9750
Batch [4900/8699], Train Loss: 0.0676, Train Acc: 0.9753
Batch [5000/8699], Train Loss: 0.0673, Train Acc: 0.9755
Batch [5100/8699], Train Loss: 0.0668, Train Acc: 0.9757
Batch [5200/8699], Train Loss: 0.0662, Train Acc: 0.9760
Batch [5300/8699], Train Loss: 0.0656, Train Acc: 0.9762
Batch [5400/8699], Train Loss: 0.0651, Train Acc: 0.9765
Batch [5500/8699], Train Loss: 0.0646, Train Acc: 0.9767
Batch [5600/8699], Train Loss: 0.0645, Train Acc: 0.9768
Batch [5700/8699], Train Loss: 0.0643, Train Acc: 0.9769
Batch [5800/8699], Train Loss: 0.0638, Train Acc: 0.9771
Batch [5900/8699], Train Loss: 0.0635, Train Acc: 0.9773
Batch [6000/8699], Train Loss: 0.0641, Train Acc: 0.9771
Batch [6100/8699], Train Loss: 0.0643, Train Acc: 0.9771
Batch [6200/8699], Train Loss: 0.0639, Train Acc: 0.9773
Batch [6300/8699], Train Loss: 0.0635, Train Acc: 0.9775
Batch [6400/8699], Train Loss: 0.0632, Train Acc: 0.9776
Batch [6500/8699], Train Loss: 0.0630, Train Acc: 0.9777
Batch [6600/8699], Train Loss: 0.0626, Train Acc: 0.9779
Batch [6700/8699], Train Loss: 0.0621, Train Acc: 0.9781
Batch [6800/8699], Train Loss: 0.0616, Train Acc: 0.9783
Batch [6900/8699], Train Loss: 0.0614, Train Acc: 0.9785
Batch [7000/8699], Train Loss: 0.0609, Train Acc: 0.9787
Batch [7100/8699], Train Loss: 0.0612, Train Acc: 0.9787
Batch [7200/8699], Train Loss: 0.0610, Train Acc: 0.9788
Batch [7300/8699], Train Loss: 0.0607, Train Acc: 0.9790
Batch [7400/8699], Train Loss: 0.0604, Train Acc: 0.9791
Batch [7500/8699], Train Loss: 0.0600, Train Acc: 0.9793
Batch [7600/8699], Train Loss: 0.0596, Train Acc: 0.9795
Batch [7700/8699], Train Loss: 0.0594, Train Acc: 0.9796
Batch [7800/8699], Train Loss: 0.0591, Train Acc: 0.9797
Batch [7900/8699], Train Loss: 0.0586, Train Acc: 0.9799
Batch [8000/8699], Train Loss: 0.0581, Train Acc: 0.9801
Batch [8100/8699], Train Loss: 0.0577, Train Acc: 0.9803
Batch [8200/8699], Train Loss: 0.0573, Train Acc: 0.9805
Batch [8300/8699], Train Loss: 0.0570, Train Acc: 0.9806
Batch [8400/8699], Train Loss: 0.0568, Train Acc: 0.9807
Batch [8500/8699], Train Loss: 0.0569, Train Acc: 0.9807
Batch [8600/8699], Train Loss: 0.0566, Train Acc: 0.9808
Train Loss: 0.0562, Train Acc: 0.9810
Test Accuracy: 0.9959
Confusion Matrix:
[[71157   408]
 [  168 67438]]
Epoch time: 51.5849 minutes and 35.0952 seconds
Best Train Acc: 0.9948
Total training time: 51.58503589630127 minutes and 35.10215377807617 seconds
