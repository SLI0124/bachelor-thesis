Epoch 1/5
Batch [100/8699], Train Loss: 0.9857, Train Acc: 0.4920
Batch [200/8699], Train Loss: 0.8025, Train Acc: 0.5701
Batch [300/8699], Train Loss: 0.5822, Train Acc: 0.7002
Batch [400/8699], Train Loss: 0.4607, Train Acc: 0.7672
Batch [500/8699], Train Loss: 0.3835, Train Acc: 0.8095
Batch [600/8699], Train Loss: 0.3322, Train Acc: 0.8376
Batch [700/8699], Train Loss: 0.2973, Train Acc: 0.8570
Batch [800/8699], Train Loss: 0.2674, Train Acc: 0.8728
Batch [900/8699], Train Loss: 0.2440, Train Acc: 0.8851
Batch [1000/8699], Train Loss: 0.2267, Train Acc: 0.8946
Batch [1100/8699], Train Loss: 0.2106, Train Acc: 0.9028
Batch [1200/8699], Train Loss: 0.1982, Train Acc: 0.9094
Batch [1300/8699], Train Loss: 0.1863, Train Acc: 0.9153
Batch [1400/8699], Train Loss: 0.1759, Train Acc: 0.9204
Batch [1500/8699], Train Loss: 0.1671, Train Acc: 0.9248
Batch [1600/8699], Train Loss: 0.1606, Train Acc: 0.9284
Batch [1700/8699], Train Loss: 0.1537, Train Acc: 0.9319
Batch [1800/8699], Train Loss: 0.1474, Train Acc: 0.9351
Batch [1900/8699], Train Loss: 0.1418, Train Acc: 0.9378
Batch [2000/8699], Train Loss: 0.1367, Train Acc: 0.9403
Batch [2100/8699], Train Loss: 0.1318, Train Acc: 0.9426
Batch [2200/8699], Train Loss: 0.1276, Train Acc: 0.9448
Batch [2300/8699], Train Loss: 0.1238, Train Acc: 0.9466
Batch [2400/8699], Train Loss: 0.1204, Train Acc: 0.9483
Batch [2500/8699], Train Loss: 0.1168, Train Acc: 0.9500
Batch [2600/8699], Train Loss: 0.1137, Train Acc: 0.9515
Batch [2700/8699], Train Loss: 0.1109, Train Acc: 0.9529
Batch [2800/8699], Train Loss: 0.1081, Train Acc: 0.9542
Batch [2900/8699], Train Loss: 0.1057, Train Acc: 0.9554
Batch [3000/8699], Train Loss: 0.1030, Train Acc: 0.9567
Batch [3100/8699], Train Loss: 0.1009, Train Acc: 0.9578
Batch [3200/8699], Train Loss: 0.0989, Train Acc: 0.9588
Batch [3300/8699], Train Loss: 0.0969, Train Acc: 0.9597
Batch [3400/8699], Train Loss: 0.0949, Train Acc: 0.9607
Batch [3500/8699], Train Loss: 0.0931, Train Acc: 0.9615
Batch [3600/8699], Train Loss: 0.0913, Train Acc: 0.9624
Batch [3700/8699], Train Loss: 0.0897, Train Acc: 0.9632
Batch [3800/8699], Train Loss: 0.0879, Train Acc: 0.9640
Batch [3900/8699], Train Loss: 0.0864, Train Acc: 0.9647
Batch [4000/8699], Train Loss: 0.0849, Train Acc: 0.9654
Batch [4100/8699], Train Loss: 0.0835, Train Acc: 0.9660
Batch [4200/8699], Train Loss: 0.0822, Train Acc: 0.9666
Batch [4300/8699], Train Loss: 0.0810, Train Acc: 0.9672
Batch [4400/8699], Train Loss: 0.0800, Train Acc: 0.9678
Batch [4500/8699], Train Loss: 0.0788, Train Acc: 0.9684
Batch [4600/8699], Train Loss: 0.0776, Train Acc: 0.9689
Batch [4700/8699], Train Loss: 0.0767, Train Acc: 0.9694
Batch [4800/8699], Train Loss: 0.0758, Train Acc: 0.9699
Batch [4900/8699], Train Loss: 0.0747, Train Acc: 0.9704
Batch [5000/8699], Train Loss: 0.0737, Train Acc: 0.9708
Batch [5100/8699], Train Loss: 0.0728, Train Acc: 0.9712
Batch [5200/8699], Train Loss: 0.0717, Train Acc: 0.9717
Batch [5300/8699], Train Loss: 0.0708, Train Acc: 0.9721
Batch [5400/8699], Train Loss: 0.0701, Train Acc: 0.9725
Batch [5500/8699], Train Loss: 0.0693, Train Acc: 0.9728
Batch [5600/8699], Train Loss: 0.0684, Train Acc: 0.9732
Batch [5700/8699], Train Loss: 0.0677, Train Acc: 0.9735
Batch [5800/8699], Train Loss: 0.0669, Train Acc: 0.9739
Batch [5900/8699], Train Loss: 0.0662, Train Acc: 0.9742
Batch [6000/8699], Train Loss: 0.0655, Train Acc: 0.9745
Batch [6100/8699], Train Loss: 0.0648, Train Acc: 0.9748
Batch [6200/8699], Train Loss: 0.0640, Train Acc: 0.9751
Batch [6300/8699], Train Loss: 0.0634, Train Acc: 0.9754
Batch [6400/8699], Train Loss: 0.0628, Train Acc: 0.9757
Batch [6500/8699], Train Loss: 0.0622, Train Acc: 0.9760
Batch [6600/8699], Train Loss: 0.0616, Train Acc: 0.9763
Batch [6700/8699], Train Loss: 0.0610, Train Acc: 0.9765
Batch [6800/8699], Train Loss: 0.0605, Train Acc: 0.9768
Batch [6900/8699], Train Loss: 0.0598, Train Acc: 0.9770
Batch [7000/8699], Train Loss: 0.0593, Train Acc: 0.9773
Batch [7100/8699], Train Loss: 0.0588, Train Acc: 0.9775
Batch [7200/8699], Train Loss: 0.0583, Train Acc: 0.9778
Batch [7300/8699], Train Loss: 0.0578, Train Acc: 0.9780
Batch [7400/8699], Train Loss: 0.0573, Train Acc: 0.9782
Batch [7500/8699], Train Loss: 0.0569, Train Acc: 0.9784
Batch [7600/8699], Train Loss: 0.0563, Train Acc: 0.9787
Batch [7700/8699], Train Loss: 0.0558, Train Acc: 0.9789
Batch [7800/8699], Train Loss: 0.0554, Train Acc: 0.9791
Batch [7900/8699], Train Loss: 0.0549, Train Acc: 0.9792
Batch [8000/8699], Train Loss: 0.0546, Train Acc: 0.9794
Batch [8100/8699], Train Loss: 0.0541, Train Acc: 0.9796
Batch [8200/8699], Train Loss: 0.0537, Train Acc: 0.9798
Batch [8300/8699], Train Loss: 0.0533, Train Acc: 0.9800
Batch [8400/8699], Train Loss: 0.0530, Train Acc: 0.9802
Batch [8500/8699], Train Loss: 0.0527, Train Acc: 0.9803
Batch [8600/8699], Train Loss: 0.0523, Train Acc: 0.9805
Train Loss: 0.0520, Train Acc: 0.9806
Test Accuracy: 0.9967
Confusion Matrix:
[[71427   256]
 [  210 67278]]
Saved the new best model to ../data/models/80_20_split/pklot_all_alexnet.pth
Epoch time: 11.8726 minutes and 52.3585 seconds
Epoch 2/5
Batch [100/8699], Train Loss: 0.0284, Train Acc: 0.9916
Batch [200/8699], Train Loss: 0.0239, Train Acc: 0.9932
Batch [300/8699], Train Loss: 0.0224, Train Acc: 0.9934
Batch [400/8699], Train Loss: 0.0229, Train Acc: 0.9938
Batch [500/8699], Train Loss: 0.0236, Train Acc: 0.9938
Batch [600/8699], Train Loss: 0.0233, Train Acc: 0.9938
Batch [700/8699], Train Loss: 0.0221, Train Acc: 0.9941
Batch [800/8699], Train Loss: 0.0216, Train Acc: 0.9941
Batch [900/8699], Train Loss: 0.0213, Train Acc: 0.9942
Batch [1000/8699], Train Loss: 0.0213, Train Acc: 0.9943
Batch [1100/8699], Train Loss: 0.0206, Train Acc: 0.9945
Batch [1200/8699], Train Loss: 0.0211, Train Acc: 0.9944
Batch [1300/8699], Train Loss: 0.0209, Train Acc: 0.9944
Batch [1400/8699], Train Loss: 0.0216, Train Acc: 0.9944
Batch [1500/8699], Train Loss: 0.0218, Train Acc: 0.9943
Batch [1600/8699], Train Loss: 0.0218, Train Acc: 0.9943
Batch [1700/8699], Train Loss: 0.0220, Train Acc: 0.9943
Batch [1800/8699], Train Loss: 0.0219, Train Acc: 0.9943
Batch [1900/8699], Train Loss: 0.0217, Train Acc: 0.9944
Batch [2000/8699], Train Loss: 0.0237, Train Acc: 0.9940
Batch [2100/8699], Train Loss: 0.0249, Train Acc: 0.9936
Batch [2200/8699], Train Loss: 0.0248, Train Acc: 0.9936
Batch [2300/8699], Train Loss: 0.0255, Train Acc: 0.9935
Batch [2400/8699], Train Loss: 0.0251, Train Acc: 0.9936
Batch [2500/8699], Train Loss: 0.0252, Train Acc: 0.9937
Batch [2600/8699], Train Loss: 0.0247, Train Acc: 0.9938
Batch [2700/8699], Train Loss: 0.0246, Train Acc: 0.9939
Batch [2800/8699], Train Loss: 0.0243, Train Acc: 0.9940
Batch [2900/8699], Train Loss: 0.0239, Train Acc: 0.9941
Batch [3000/8699], Train Loss: 0.0239, Train Acc: 0.9941
Batch [3100/8699], Train Loss: 0.0236, Train Acc: 0.9942
Batch [3200/8699], Train Loss: 0.0232, Train Acc: 0.9943
Batch [3300/8699], Train Loss: 0.0231, Train Acc: 0.9943
Batch [3400/8699], Train Loss: 0.0229, Train Acc: 0.9944
Batch [3500/8699], Train Loss: 0.0227, Train Acc: 0.9944
Batch [3600/8699], Train Loss: 0.0228, Train Acc: 0.9944
Batch [3700/8699], Train Loss: 0.0226, Train Acc: 0.9944
Batch [3800/8699], Train Loss: 0.0229, Train Acc: 0.9943
Batch [3900/8699], Train Loss: 0.0227, Train Acc: 0.9944
Batch [4000/8699], Train Loss: 0.0226, Train Acc: 0.9944
Batch [4100/8699], Train Loss: 0.0225, Train Acc: 0.9944
Batch [4200/8699], Train Loss: 0.0226, Train Acc: 0.9944
Batch [4300/8699], Train Loss: 0.0225, Train Acc: 0.9944
Batch [4400/8699], Train Loss: 0.0224, Train Acc: 0.9944
Batch [4500/8699], Train Loss: 0.0225, Train Acc: 0.9944
Batch [4600/8699], Train Loss: 0.0224, Train Acc: 0.9944
Batch [4700/8699], Train Loss: 0.0223, Train Acc: 0.9945
Batch [4800/8699], Train Loss: 0.0223, Train Acc: 0.9945
Batch [4900/8699], Train Loss: 0.0223, Train Acc: 0.9945
Batch [5000/8699], Train Loss: 0.0225, Train Acc: 0.9944
Batch [5100/8699], Train Loss: 0.0225, Train Acc: 0.9944
Batch [5200/8699], Train Loss: 0.0225, Train Acc: 0.9944
Batch [5300/8699], Train Loss: 0.0224, Train Acc: 0.9945
Batch [5400/8699], Train Loss: 0.0223, Train Acc: 0.9945
Batch [5500/8699], Train Loss: 0.0221, Train Acc: 0.9945
Batch [5600/8699], Train Loss: 0.0220, Train Acc: 0.9946
Batch [5700/8699], Train Loss: 0.0220, Train Acc: 0.9945
Batch [5800/8699], Train Loss: 0.0220, Train Acc: 0.9945
Batch [5900/8699], Train Loss: 0.0219, Train Acc: 0.9946
Batch [6000/8699], Train Loss: 0.0219, Train Acc: 0.9946
Batch [6100/8699], Train Loss: 0.0219, Train Acc: 0.9945
Batch [6200/8699], Train Loss: 0.0219, Train Acc: 0.9945
Batch [6300/8699], Train Loss: 0.0218, Train Acc: 0.9945
Batch [6400/8699], Train Loss: 0.0217, Train Acc: 0.9946
Batch [6500/8699], Train Loss: 0.0215, Train Acc: 0.9946
Batch [6600/8699], Train Loss: 0.0215, Train Acc: 0.9946
Batch [6700/8699], Train Loss: 0.0215, Train Acc: 0.9946
Batch [6800/8699], Train Loss: 0.0214, Train Acc: 0.9947
Batch [6900/8699], Train Loss: 0.0214, Train Acc: 0.9946
Batch [7000/8699], Train Loss: 0.0215, Train Acc: 0.9946
Batch [7100/8699], Train Loss: 0.0216, Train Acc: 0.9946
Batch [7200/8699], Train Loss: 0.0222, Train Acc: 0.9945
Batch [7300/8699], Train Loss: 0.0223, Train Acc: 0.9944
Batch [7400/8699], Train Loss: 0.0223, Train Acc: 0.9944
Batch [7500/8699], Train Loss: 0.0224, Train Acc: 0.9944
Batch [7600/8699], Train Loss: 0.0223, Train Acc: 0.9945
Batch [7700/8699], Train Loss: 0.0222, Train Acc: 0.9945
Batch [7800/8699], Train Loss: 0.0221, Train Acc: 0.9945
Batch [7900/8699], Train Loss: 0.0221, Train Acc: 0.9945
Batch [8000/8699], Train Loss: 0.0220, Train Acc: 0.9945
Batch [8100/8699], Train Loss: 0.0219, Train Acc: 0.9946
Batch [8200/8699], Train Loss: 0.0219, Train Acc: 0.9946
Batch [8300/8699], Train Loss: 0.0219, Train Acc: 0.9946
Batch [8400/8699], Train Loss: 0.0218, Train Acc: 0.9946
Batch [8500/8699], Train Loss: 0.0218, Train Acc: 0.9946
Batch [8600/8699], Train Loss: 0.0218, Train Acc: 0.9946
Train Loss: 0.0218, Train Acc: 0.9946
Test Accuracy: 0.9969
Confusion Matrix:
[[71356   327]
 [  109 67379]]
Saved the new best model to ../data/models/80_20_split/pklot_all_alexnet.pth
Epoch time: 11.3668 minutes and 22.0087 seconds
Epoch 3/5
Batch [100/8699], Train Loss: 0.0138, Train Acc: 0.9966
Batch [200/8699], Train Loss: 0.0183, Train Acc: 0.9956
Batch [300/8699], Train Loss: 0.0202, Train Acc: 0.9951
Batch [400/8699], Train Loss: 0.0190, Train Acc: 0.9954
Batch [500/8699], Train Loss: 0.0180, Train Acc: 0.9957
Batch [600/8699], Train Loss: 0.0186, Train Acc: 0.9955
Batch [700/8699], Train Loss: 0.0187, Train Acc: 0.9954
Batch [800/8699], Train Loss: 0.0191, Train Acc: 0.9954
Batch [900/8699], Train Loss: 0.0211, Train Acc: 0.9951
Batch [1000/8699], Train Loss: 0.0210, Train Acc: 0.9951
Batch [1100/8699], Train Loss: 0.0214, Train Acc: 0.9952
Batch [1200/8699], Train Loss: 0.0208, Train Acc: 0.9953
Batch [1300/8699], Train Loss: 0.0205, Train Acc: 0.9953
Batch [1400/8699], Train Loss: 0.0202, Train Acc: 0.9953
Batch [1500/8699], Train Loss: 0.0199, Train Acc: 0.9954
Batch [1600/8699], Train Loss: 0.0195, Train Acc: 0.9954
Batch [1700/8699], Train Loss: 0.0193, Train Acc: 0.9955
Batch [1800/8699], Train Loss: 0.0188, Train Acc: 0.9956
Batch [1900/8699], Train Loss: 0.0186, Train Acc: 0.9956
Batch [2000/8699], Train Loss: 0.0185, Train Acc: 0.9956
Batch [2100/8699], Train Loss: 0.0182, Train Acc: 0.9956
Batch [2200/8699], Train Loss: 0.0181, Train Acc: 0.9956
Batch [2300/8699], Train Loss: 0.0178, Train Acc: 0.9957
Batch [2400/8699], Train Loss: 0.0178, Train Acc: 0.9957
Batch [2500/8699], Train Loss: 0.0176, Train Acc: 0.9957
Batch [2600/8699], Train Loss: 0.0174, Train Acc: 0.9957
Batch [2700/8699], Train Loss: 0.0173, Train Acc: 0.9958
Batch [2800/8699], Train Loss: 0.0176, Train Acc: 0.9957
Batch [2900/8699], Train Loss: 0.0176, Train Acc: 0.9957
Batch [3000/8699], Train Loss: 0.0175, Train Acc: 0.9957
Batch [3100/8699], Train Loss: 0.0176, Train Acc: 0.9957
Batch [3200/8699], Train Loss: 0.0174, Train Acc: 0.9957
Batch [3300/8699], Train Loss: 0.0176, Train Acc: 0.9957
Batch [3400/8699], Train Loss: 0.0175, Train Acc: 0.9957
Batch [3500/8699], Train Loss: 0.0174, Train Acc: 0.9958
Batch [3600/8699], Train Loss: 0.0172, Train Acc: 0.9958
Batch [3700/8699], Train Loss: 0.0170, Train Acc: 0.9959
Batch [3800/8699], Train Loss: 0.0169, Train Acc: 0.9959
Batch [3900/8699], Train Loss: 0.0168, Train Acc: 0.9959
Batch [4000/8699], Train Loss: 0.0167, Train Acc: 0.9960
Batch [4100/8699], Train Loss: 0.0168, Train Acc: 0.9960
Batch [4200/8699], Train Loss: 0.0168, Train Acc: 0.9959
Batch [4300/8699], Train Loss: 0.0170, Train Acc: 0.9959
Batch [4400/8699], Train Loss: 0.0170, Train Acc: 0.9959
Batch [4500/8699], Train Loss: 0.0170, Train Acc: 0.9959
Batch [4600/8699], Train Loss: 0.0169, Train Acc: 0.9959
Batch [4700/8699], Train Loss: 0.0171, Train Acc: 0.9959
Batch [4800/8699], Train Loss: 0.0172, Train Acc: 0.9959
Batch [4900/8699], Train Loss: 0.0172, Train Acc: 0.9959
Batch [5000/8699], Train Loss: 0.0172, Train Acc: 0.9959
Batch [5100/8699], Train Loss: 0.0170, Train Acc: 0.9959
Batch [5200/8699], Train Loss: 0.0171, Train Acc: 0.9959
Batch [5300/8699], Train Loss: 0.0171, Train Acc: 0.9959
Batch [5400/8699], Train Loss: 0.0171, Train Acc: 0.9959
Batch [5500/8699], Train Loss: 0.0170, Train Acc: 0.9959
Batch [5600/8699], Train Loss: 0.0170, Train Acc: 0.9959
Batch [5700/8699], Train Loss: 0.0169, Train Acc: 0.9959
Batch [5800/8699], Train Loss: 0.0171, Train Acc: 0.9959
Batch [5900/8699], Train Loss: 0.0172, Train Acc: 0.9959
Batch [6000/8699], Train Loss: 0.0171, Train Acc: 0.9959
Batch [6100/8699], Train Loss: 0.0171, Train Acc: 0.9959
Batch [6200/8699], Train Loss: 0.0170, Train Acc: 0.9959
Batch [6300/8699], Train Loss: 0.0169, Train Acc: 0.9959
Batch [6400/8699], Train Loss: 0.0170, Train Acc: 0.9959
Batch [6500/8699], Train Loss: 0.0169, Train Acc: 0.9959
Batch [6600/8699], Train Loss: 0.0168, Train Acc: 0.9960
Batch [6700/8699], Train Loss: 0.0169, Train Acc: 0.9959
Batch [6800/8699], Train Loss: 0.0170, Train Acc: 0.9959
Batch [6900/8699], Train Loss: 0.0170, Train Acc: 0.9959
Batch [7000/8699], Train Loss: 0.0170, Train Acc: 0.9959
Batch [7100/8699], Train Loss: 0.0170, Train Acc: 0.9960
Batch [7200/8699], Train Loss: 0.0170, Train Acc: 0.9960
Batch [7300/8699], Train Loss: 0.0169, Train Acc: 0.9960
Batch [7400/8699], Train Loss: 0.0169, Train Acc: 0.9960
Batch [7500/8699], Train Loss: 0.0169, Train Acc: 0.9960
Batch [7600/8699], Train Loss: 0.0168, Train Acc: 0.9960
Batch [7700/8699], Train Loss: 0.0168, Train Acc: 0.9960
Batch [7800/8699], Train Loss: 0.0168, Train Acc: 0.9960
Batch [7900/8699], Train Loss: 0.0168, Train Acc: 0.9960
Batch [8000/8699], Train Loss: 0.0168, Train Acc: 0.9960
Batch [8100/8699], Train Loss: 0.0168, Train Acc: 0.9960
Batch [8200/8699], Train Loss: 0.0168, Train Acc: 0.9960
Batch [8300/8699], Train Loss: 0.0168, Train Acc: 0.9960
Batch [8400/8699], Train Loss: 0.0167, Train Acc: 0.9960
Batch [8500/8699], Train Loss: 0.0168, Train Acc: 0.9960
Batch [8600/8699], Train Loss: 0.0168, Train Acc: 0.9960
Train Loss: 0.0167, Train Acc: 0.9960
Test Accuracy: 0.9979
Confusion Matrix:
[[71546   137]
 [  158 67330]]
Saved the new best model to ../data/models/80_20_split/pklot_all_alexnet.pth
Epoch time: 11.8486 minutes and 50.9146 seconds
Epoch 4/5
Batch [100/8699], Train Loss: 0.0072, Train Acc: 0.9978
Batch [200/8699], Train Loss: 0.0098, Train Acc: 0.9973
Batch [300/8699], Train Loss: 0.0133, Train Acc: 0.9962
Batch [400/8699], Train Loss: 0.0144, Train Acc: 0.9961
Batch [500/8699], Train Loss: 0.0143, Train Acc: 0.9962
Batch [600/8699], Train Loss: 0.0153, Train Acc: 0.9962
Batch [700/8699], Train Loss: 0.0158, Train Acc: 0.9961
Batch [800/8699], Train Loss: 0.0160, Train Acc: 0.9962
Batch [900/8699], Train Loss: 0.0152, Train Acc: 0.9963
Batch [1000/8699], Train Loss: 0.0148, Train Acc: 0.9964
Batch [1100/8699], Train Loss: 0.0147, Train Acc: 0.9964
Batch [1200/8699], Train Loss: 0.0144, Train Acc: 0.9964
Batch [1300/8699], Train Loss: 0.0143, Train Acc: 0.9965
Batch [1400/8699], Train Loss: 0.0147, Train Acc: 0.9964
Batch [1500/8699], Train Loss: 0.0145, Train Acc: 0.9964
Batch [1600/8699], Train Loss: 0.0146, Train Acc: 0.9965
Batch [1700/8699], Train Loss: 0.0146, Train Acc: 0.9965
Batch [1800/8699], Train Loss: 0.0149, Train Acc: 0.9964
Batch [1900/8699], Train Loss: 0.0146, Train Acc: 0.9965
Batch [2000/8699], Train Loss: 0.0148, Train Acc: 0.9964
Batch [2100/8699], Train Loss: 0.0149, Train Acc: 0.9964
Batch [2200/8699], Train Loss: 0.0152, Train Acc: 0.9964
Batch [2300/8699], Train Loss: 0.0152, Train Acc: 0.9964
Batch [2400/8699], Train Loss: 0.0150, Train Acc: 0.9964
Batch [2500/8699], Train Loss: 0.0152, Train Acc: 0.9964
Batch [2600/8699], Train Loss: 0.0150, Train Acc: 0.9964
Batch [2700/8699], Train Loss: 0.0149, Train Acc: 0.9964
Batch [2800/8699], Train Loss: 0.0148, Train Acc: 0.9964
Batch [2900/8699], Train Loss: 0.0146, Train Acc: 0.9964
Batch [3000/8699], Train Loss: 0.0146, Train Acc: 0.9965
Batch [3100/8699], Train Loss: 0.0148, Train Acc: 0.9965
Batch [3200/8699], Train Loss: 0.0146, Train Acc: 0.9965
Batch [3300/8699], Train Loss: 0.0147, Train Acc: 0.9965
Batch [3400/8699], Train Loss: 0.0146, Train Acc: 0.9965
Batch [3500/8699], Train Loss: 0.0149, Train Acc: 0.9965
Batch [3600/8699], Train Loss: 0.0147, Train Acc: 0.9965
Batch [3700/8699], Train Loss: 0.0148, Train Acc: 0.9965
Batch [3800/8699], Train Loss: 0.0151, Train Acc: 0.9965
Batch [3900/8699], Train Loss: 0.0152, Train Acc: 0.9965
Batch [4000/8699], Train Loss: 0.0152, Train Acc: 0.9965
Batch [4100/8699], Train Loss: 0.0150, Train Acc: 0.9965
Batch [4200/8699], Train Loss: 0.0151, Train Acc: 0.9965
Batch [4300/8699], Train Loss: 0.0151, Train Acc: 0.9965
Batch [4400/8699], Train Loss: 0.0151, Train Acc: 0.9965
Batch [4500/8699], Train Loss: 0.0150, Train Acc: 0.9965
Batch [4600/8699], Train Loss: 0.0150, Train Acc: 0.9965
Batch [4700/8699], Train Loss: 0.0149, Train Acc: 0.9965
Batch [4800/8699], Train Loss: 0.0149, Train Acc: 0.9965
Batch [4900/8699], Train Loss: 0.0148, Train Acc: 0.9965
Batch [5000/8699], Train Loss: 0.0147, Train Acc: 0.9966
Batch [5100/8699], Train Loss: 0.0147, Train Acc: 0.9966
Batch [5200/8699], Train Loss: 0.0146, Train Acc: 0.9966
Batch [5300/8699], Train Loss: 0.0146, Train Acc: 0.9966
Batch [5400/8699], Train Loss: 0.0146, Train Acc: 0.9966
Batch [5500/8699], Train Loss: 0.0147, Train Acc: 0.9966
Batch [5600/8699], Train Loss: 0.0146, Train Acc: 0.9966
Batch [5700/8699], Train Loss: 0.0148, Train Acc: 0.9966
Batch [5800/8699], Train Loss: 0.0149, Train Acc: 0.9966
Batch [5900/8699], Train Loss: 0.0148, Train Acc: 0.9966
Batch [6000/8699], Train Loss: 0.0149, Train Acc: 0.9966
Batch [6100/8699], Train Loss: 0.0147, Train Acc: 0.9966
Batch [6200/8699], Train Loss: 0.0146, Train Acc: 0.9966
Batch [6300/8699], Train Loss: 0.0147, Train Acc: 0.9966
Batch [6400/8699], Train Loss: 0.0147, Train Acc: 0.9966
Batch [6500/8699], Train Loss: 0.0147, Train Acc: 0.9966
Batch [6600/8699], Train Loss: 0.0147, Train Acc: 0.9966
Batch [6700/8699], Train Loss: 0.0146, Train Acc: 0.9966
Batch [6800/8699], Train Loss: 0.0146, Train Acc: 0.9966
Batch [6900/8699], Train Loss: 0.0146, Train Acc: 0.9966
Batch [7000/8699], Train Loss: 0.0146, Train Acc: 0.9966
Batch [7100/8699], Train Loss: 0.0147, Train Acc: 0.9966
Batch [7200/8699], Train Loss: 0.0147, Train Acc: 0.9966
Batch [7300/8699], Train Loss: 0.0147, Train Acc: 0.9967
Batch [7400/8699], Train Loss: 0.0147, Train Acc: 0.9967
Batch [7500/8699], Train Loss: 0.0147, Train Acc: 0.9967
Batch [7600/8699], Train Loss: 0.0147, Train Acc: 0.9967
Batch [7700/8699], Train Loss: 0.0147, Train Acc: 0.9967
Batch [7800/8699], Train Loss: 0.0147, Train Acc: 0.9967
Batch [7900/8699], Train Loss: 0.0153, Train Acc: 0.9965
Batch [8000/8699], Train Loss: 0.0156, Train Acc: 0.9965
Batch [8100/8699], Train Loss: 0.0159, Train Acc: 0.9964
Batch [8200/8699], Train Loss: 0.0161, Train Acc: 0.9964
Batch [8300/8699], Train Loss: 0.0162, Train Acc: 0.9964
Batch [8400/8699], Train Loss: 0.0163, Train Acc: 0.9964
Batch [8500/8699], Train Loss: 0.0162, Train Acc: 0.9964
Batch [8600/8699], Train Loss: 0.0162, Train Acc: 0.9964
Train Loss: 0.0162, Train Acc: 0.9964
Test Accuracy: 0.9981
Confusion Matrix:
[[71567   116]
 [  150 67338]]
Saved the new best model to ../data/models/80_20_split/pklot_all_alexnet.pth
Epoch time: 12.9578 minutes and 57.4686 seconds
Epoch 5/5
Batch [100/8699], Train Loss: 0.0162, Train Acc: 0.9969
Batch [200/8699], Train Loss: 0.0194, Train Acc: 0.9966
Batch [300/8699], Train Loss: 0.0172, Train Acc: 0.9969
Batch [400/8699], Train Loss: 0.0153, Train Acc: 0.9970
Batch [500/8699], Train Loss: 0.0141, Train Acc: 0.9972
Batch [600/8699], Train Loss: 0.0140, Train Acc: 0.9972
Batch [700/8699], Train Loss: 0.0133, Train Acc: 0.9973
Batch [800/8699], Train Loss: 0.0129, Train Acc: 0.9973
Batch [900/8699], Train Loss: 0.0127, Train Acc: 0.9973
Batch [1000/8699], Train Loss: 0.0135, Train Acc: 0.9972
Batch [1100/8699], Train Loss: 0.0136, Train Acc: 0.9972
Batch [1200/8699], Train Loss: 0.0133, Train Acc: 0.9973
Batch [1300/8699], Train Loss: 0.0128, Train Acc: 0.9973
Batch [1400/8699], Train Loss: 0.0135, Train Acc: 0.9972
Batch [1500/8699], Train Loss: 0.0136, Train Acc: 0.9971
Batch [1600/8699], Train Loss: 0.0135, Train Acc: 0.9971
Batch [1700/8699], Train Loss: 0.0136, Train Acc: 0.9971
Batch [1800/8699], Train Loss: 0.0135, Train Acc: 0.9972
Batch [1900/8699], Train Loss: 0.0132, Train Acc: 0.9972
Batch [2000/8699], Train Loss: 0.0136, Train Acc: 0.9971
Batch [2100/8699], Train Loss: 0.0137, Train Acc: 0.9970
Batch [2200/8699], Train Loss: 0.0139, Train Acc: 0.9970
Batch [2300/8699], Train Loss: 0.0143, Train Acc: 0.9969
Batch [2400/8699], Train Loss: 0.0142, Train Acc: 0.9969
Batch [2500/8699], Train Loss: 0.0146, Train Acc: 0.9969
Batch [2600/8699], Train Loss: 0.0150, Train Acc: 0.9968
Batch [2700/8699], Train Loss: 0.0155, Train Acc: 0.9966
Batch [2800/8699], Train Loss: 0.0154, Train Acc: 0.9966
Batch [2900/8699], Train Loss: 0.0154, Train Acc: 0.9966
Batch [3000/8699], Train Loss: 0.0152, Train Acc: 0.9966
Batch [3100/8699], Train Loss: 0.0153, Train Acc: 0.9966
Batch [3200/8699], Train Loss: 0.0155, Train Acc: 0.9966
Batch [3300/8699], Train Loss: 0.0154, Train Acc: 0.9966
Batch [3400/8699], Train Loss: 0.0153, Train Acc: 0.9966
Batch [3500/8699], Train Loss: 0.0270, Train Acc: 0.9889
Batch [3600/8699], Train Loss: 0.0456, Train Acc: 0.9757
Batch [3700/8699], Train Loss: 0.0632, Train Acc: 0.9630
Batch [3800/8699], Train Loss: 0.0798, Train Acc: 0.9509
Batch [3900/8699], Train Loss: 0.0956, Train Acc: 0.9397
Batch [4000/8699], Train Loss: 0.1106, Train Acc: 0.9290
Batch [4100/8699], Train Loss: 0.1248, Train Acc: 0.9186
Batch [4200/8699], Train Loss: 0.1384, Train Acc: 0.9085
Batch [4300/8699], Train Loss: 0.1513, Train Acc: 0.8987
Batch [4400/8699], Train Loss: 0.1581, Train Acc: 0.8954
Batch [4500/8699], Train Loss: 0.1576, Train Acc: 0.8967
Batch [4600/8699], Train Loss: 0.1560, Train Acc: 0.8983
Batch [4700/8699], Train Loss: 0.1543, Train Acc: 0.8999
Batch [4800/8699], Train Loss: 0.1522, Train Acc: 0.9016
Batch [4900/8699], Train Loss: 0.1504, Train Acc: 0.9033
Batch [5000/8699], Train Loss: 0.1484, Train Acc: 0.9049
Batch [5100/8699], Train Loss: 0.1465, Train Acc: 0.9064
Batch [5200/8699], Train Loss: 0.1445, Train Acc: 0.9080
Batch [5300/8699], Train Loss: 0.1428, Train Acc: 0.9095
Batch [5400/8699], Train Loss: 0.1409, Train Acc: 0.9109
Batch [5500/8699], Train Loss: 0.1392, Train Acc: 0.9123
Batch [5600/8699], Train Loss: 0.1374, Train Acc: 0.9137
Batch [5700/8699], Train Loss: 0.1356, Train Acc: 0.9150
Batch [5800/8699], Train Loss: 0.1339, Train Acc: 0.9163
Batch [5900/8699], Train Loss: 0.1323, Train Acc: 0.9176
Batch [6000/8699], Train Loss: 0.1308, Train Acc: 0.9187
Batch [6100/8699], Train Loss: 0.1294, Train Acc: 0.9199
Batch [6200/8699], Train Loss: 0.1277, Train Acc: 0.9210
Batch [6300/8699], Train Loss: 0.1263, Train Acc: 0.9221
Batch [6400/8699], Train Loss: 0.1249, Train Acc: 0.9231
Batch [6500/8699], Train Loss: 0.1235, Train Acc: 0.9242
Batch [6600/8699], Train Loss: 0.1222, Train Acc: 0.9251
Batch [6700/8699], Train Loss: 0.1209, Train Acc: 0.9261
Batch [6800/8699], Train Loss: 0.1196, Train Acc: 0.9271
Batch [6900/8699], Train Loss: 0.1182, Train Acc: 0.9280
Batch [7000/8699], Train Loss: 0.1169, Train Acc: 0.9289
Batch [7100/8699], Train Loss: 0.1161, Train Acc: 0.9297
Batch [7200/8699], Train Loss: 0.1149, Train Acc: 0.9305
Batch [7300/8699], Train Loss: 0.1138, Train Acc: 0.9313
Batch [7400/8699], Train Loss: 0.1126, Train Acc: 0.9321
Batch [7500/8699], Train Loss: 0.1115, Train Acc: 0.9329
Batch [7600/8699], Train Loss: 0.1107, Train Acc: 0.9336
Batch [7700/8699], Train Loss: 0.1099, Train Acc: 0.9343
Batch [7800/8699], Train Loss: 0.1089, Train Acc: 0.9350
Batch [7900/8699], Train Loss: 0.1079, Train Acc: 0.9357
Batch [8000/8699], Train Loss: 0.1069, Train Acc: 0.9364
Batch [8100/8699], Train Loss: 0.1059, Train Acc: 0.9371
Batch [8200/8699], Train Loss: 0.1050, Train Acc: 0.9378
Batch [8300/8699], Train Loss: 0.1041, Train Acc: 0.9384
Batch [8400/8699], Train Loss: 0.1032, Train Acc: 0.9391
Batch [8500/8699], Train Loss: 0.1023, Train Acc: 0.9397
Batch [8600/8699], Train Loss: 0.1015, Train Acc: 0.9403
Train Loss: 0.1007, Train Acc: 0.9408
Test Accuracy: 0.9950
Confusion Matrix:
[[71201   482]
 [  215 67273]]
Epoch time: 12.5338 minutes and 32.0265 seconds
Best Train Acc: 0.9964
Total training time: 60.579650004704796 minutes and 34.7790002822876 seconds
