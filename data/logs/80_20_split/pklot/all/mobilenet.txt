2024-04-29 09:57:04,249 - Training the model...
2024-04-29 09:57:04,250 - Epoch 1/5
2024-04-29 09:57:39,096 - Batch [100/8699], Train Loss: 0.348375554648228, Train Acc: 0.95078125
2024-04-29 09:57:57,794 - Batch [200/8699], Train Loss: 0.20259669387945906, Train Acc: 0.965703125
2024-04-29 09:58:15,215 - Batch [300/8699], Train Loss: 0.14959352584245303, Train Acc: 0.9725
2024-04-29 09:58:34,298 - Batch [400/8699], Train Loss: 0.12164097518252674, Train Acc: 0.9762890625
2024-04-29 09:58:53,554 - Batch [500/8699], Train Loss: 0.10208054112142417, Train Acc: 0.97946875
2024-04-29 09:59:12,637 - Batch [600/8699], Train Loss: 0.09017545573500683, Train Acc: 0.9812760416666667
2024-04-29 09:59:32,190 - Batch [700/8699], Train Loss: 0.08171365048827803, Train Acc: 0.98234375
2024-04-29 09:59:51,453 - Batch [800/8699], Train Loss: 0.0748031834984431, Train Acc: 0.98341796875
2024-04-29 10:00:10,611 - Batch [900/8699], Train Loss: 0.06932270112938972, Train Acc: 0.9844097222222222
2024-04-29 10:00:29,784 - Batch [1000/8699], Train Loss: 0.06467192367621465, Train Acc: 0.98534375
2024-04-29 10:00:48,895 - Batch [1100/8699], Train Loss: 0.060530250713292676, Train Acc: 0.9861931818181818
2024-04-29 10:01:07,536 - Batch [1200/8699], Train Loss: 0.057489713782512504, Train Acc: 0.9867578125
2024-04-29 10:01:26,328 - Batch [1300/8699], Train Loss: 0.054447296510065475, Train Acc: 0.9872475961538462
2024-04-29 10:01:45,144 - Batch [1400/8699], Train Loss: 0.05204377533776486, Train Acc: 0.9877008928571429
2024-04-29 10:02:04,054 - Batch [1500/8699], Train Loss: 0.049925599652517125, Train Acc: 0.988125
2024-04-29 10:02:23,023 - Batch [1600/8699], Train Loss: 0.048557737871033166, Train Acc: 0.98837890625
2024-04-29 10:02:42,332 - Batch [1700/8699], Train Loss: 0.04684102176077431, Train Acc: 0.9887316176470589
2024-04-29 10:03:01,635 - Batch [1800/8699], Train Loss: 0.04549267862404425, Train Acc: 0.9890277777777777
2024-04-29 10:03:20,909 - Batch [1900/8699], Train Loss: 0.044088251447859585, Train Acc: 0.9893503289473684
2024-04-29 10:03:40,390 - Batch [2000/8699], Train Loss: 0.04311398532048043, Train Acc: 0.9895078125
2024-04-29 10:03:59,791 - Batch [2100/8699], Train Loss: 0.0415753930249706, Train Acc: 0.98984375
2024-04-29 10:04:18,236 - Batch [2200/8699], Train Loss: 0.04077007177564982, Train Acc: 0.9899644886363637
2024-04-29 10:04:36,533 - Batch [2300/8699], Train Loss: 0.03971381477925562, Train Acc: 0.9901970108695652
2024-04-29 10:04:55,658 - Batch [2400/8699], Train Loss: 0.038913491365874506, Train Acc: 0.99037109375
2024-04-29 10:05:15,686 - Batch [2500/8699], Train Loss: 0.03803257023472688, Train Acc: 0.99054375
2024-04-29 10:05:35,730 - Batch [2600/8699], Train Loss: 0.03742787520870759, Train Acc: 0.9906670673076923
2024-04-29 10:05:54,017 - Batch [2700/8699], Train Loss: 0.03683459420316029, Train Acc: 0.9907696759259259
2024-04-29 10:06:11,444 - Batch [2800/8699], Train Loss: 0.03603196718727434, Train Acc: 0.9909430803571428
2024-04-29 10:06:29,505 - Batch [2900/8699], Train Loss: 0.035244380088266115, Train Acc: 0.9911206896551724
2024-04-29 10:06:47,257 - Batch [3000/8699], Train Loss: 0.034719465926265305, Train Acc: 0.99125
2024-04-29 10:07:04,459 - Batch [3100/8699], Train Loss: 0.034089822114582335, Train Acc: 0.991421370967742
2024-04-29 10:07:23,874 - Batch [3200/8699], Train Loss: 0.03350252029888907, Train Acc: 0.9915869140625
2024-04-29 10:07:42,743 - Batch [3300/8699], Train Loss: 0.03299284863430357, Train Acc: 0.9916950757575758
2024-04-29 10:08:02,171 - Batch [3400/8699], Train Loss: 0.03256072029762436, Train Acc: 0.9917876838235294
2024-04-29 10:08:21,428 - Batch [3500/8699], Train Loss: 0.032120450304613246, Train Acc: 0.9918839285714286
2024-04-29 10:08:41,154 - Batch [3600/8699], Train Loss: 0.031837184601843344, Train Acc: 0.9919661458333333
2024-04-29 10:09:00,463 - Batch [3700/8699], Train Loss: 0.031559726292856596, Train Acc: 0.9920101351351351
2024-04-29 10:09:19,259 - Batch [3800/8699], Train Loss: 0.031015980657546988, Train Acc: 0.9921258223684211
2024-04-29 10:09:38,276 - Batch [3900/8699], Train Loss: 0.03080891133383818, Train Acc: 0.9921714743589743
2024-04-29 10:09:55,861 - Batch [4000/8699], Train Loss: 0.03053406797257412, Train Acc: 0.99225
2024-04-29 10:10:13,821 - Batch [4100/8699], Train Loss: 0.030157986436235837, Train Acc: 0.992328506097561
2024-04-29 10:10:32,279 - Batch [4200/8699], Train Loss: 0.03000718675073239, Train Acc: 0.9923697916666666
2024-04-29 10:10:50,925 - Batch [4300/8699], Train Loss: 0.029633169960765964, Train Acc: 0.9924636627906976
2024-04-29 10:11:10,208 - Batch [4400/8699], Train Loss: 0.029365243961064234, Train Acc: 0.992510653409091
2024-04-29 10:11:30,337 - Batch [4500/8699], Train Loss: 0.028943165954807126, Train Acc: 0.9926041666666666
2024-04-29 10:11:50,678 - Batch [4600/8699], Train Loss: 0.02867114441246288, Train Acc: 0.9926494565217391
2024-04-29 10:12:09,098 - Batch [4700/8699], Train Loss: 0.028460666767322767, Train Acc: 0.9927027925531915
2024-04-29 10:12:27,303 - Batch [4800/8699], Train Loss: 0.028228421479986235, Train Acc: 0.992763671875
2024-04-29 10:12:46,189 - Batch [4900/8699], Train Loss: 0.028051405459317516, Train Acc: 0.9927901785714286
2024-04-29 10:13:05,550 - Batch [5000/8699], Train Loss: 0.027734470236694325, Train Acc: 0.992865625
2024-04-29 10:13:25,457 - Batch [5100/8699], Train Loss: 0.027527058173426686, Train Acc: 0.9929136029411765
2024-04-29 10:13:43,201 - Batch [5200/8699], Train Loss: 0.027301138625190596, Train Acc: 0.9929837740384615
2024-04-29 10:14:01,525 - Batch [5300/8699], Train Loss: 0.027046647584566874, Train Acc: 0.9930454009433962
2024-04-29 10:14:19,208 - Batch [5400/8699], Train Loss: 0.026862882904688714, Train Acc: 0.9930729166666666
2024-04-29 10:14:37,461 - Batch [5500/8699], Train Loss: 0.026694027956309253, Train Acc: 0.9930965909090909
2024-04-29 10:14:55,615 - Batch [5600/8699], Train Loss: 0.026438000669550092, Train Acc: 0.9931780133928572
2024-04-29 10:15:14,410 - Batch [5700/8699], Train Loss: 0.026147385607142942, Train Acc: 0.9932428728070175
2024-04-29 10:15:33,828 - Batch [5800/8699], Train Loss: 0.0261152642781925, Train Acc: 0.993270474137931
2024-04-29 10:15:52,670 - Batch [5900/8699], Train Loss: 0.025874475497300826, Train Acc: 0.9933421610169492
2024-04-29 10:16:11,342 - Batch [6000/8699], Train Loss: 0.02573032945513478, Train Acc: 0.9933723958333334
2024-04-29 10:16:30,065 - Batch [6100/8699], Train Loss: 0.02547853909922524, Train Acc: 0.9934349385245902
2024-04-29 10:16:48,483 - Batch [6200/8699], Train Loss: 0.02534671797577762, Train Acc: 0.9934551411290322
2024-04-29 10:17:07,114 - Batch [6300/8699], Train Loss: 0.025194625734772658, Train Acc: 0.9934945436507937
2024-04-29 10:17:25,048 - Batch [6400/8699], Train Loss: 0.02501087212414177, Train Acc: 0.99352783203125
2024-04-29 10:17:42,574 - Batch [6500/8699], Train Loss: 0.024842674246062346, Train Acc: 0.9935625
2024-04-29 10:17:59,839 - Batch [6600/8699], Train Loss: 0.02467633533986593, Train Acc: 0.993610321969697
2024-04-29 10:18:17,539 - Batch [6700/8699], Train Loss: 0.024539233612617933, Train Acc: 0.9936357276119403
2024-04-29 10:18:35,411 - Batch [6800/8699], Train Loss: 0.024394113716438477, Train Acc: 0.993664981617647
2024-04-29 10:18:53,014 - Batch [6900/8699], Train Loss: 0.024247566333275322, Train Acc: 0.9937024456521739
2024-04-29 10:19:10,110 - Batch [7000/8699], Train Loss: 0.024088700727223893, Train Acc: 0.9937522321428571
2024-04-29 10:19:27,825 - Batch [7100/8699], Train Loss: 0.023948834389898047, Train Acc: 0.9937918133802817
2024-04-29 10:19:44,738 - Batch [7200/8699], Train Loss: 0.023721497981656386, Train Acc: 0.9938368055555555
2024-04-29 10:20:02,727 - Batch [7300/8699], Train Loss: 0.023646115546062118, Train Acc: 0.9938634417808219
2024-04-29 10:20:19,640 - Batch [7400/8699], Train Loss: 0.023553007662979054, Train Acc: 0.9938893581081081
2024-04-29 10:20:36,555 - Batch [7500/8699], Train Loss: 0.023433934301807312, Train Acc: 0.993925
2024-04-29 10:20:53,736 - Batch [7600/8699], Train Loss: 0.0232712658559218, Train Acc: 0.9939699835526316
2024-04-29 10:21:10,715 - Batch [7700/8699], Train Loss: 0.0232063430380594, Train Acc: 0.9939955357142857
2024-04-29 10:21:28,313 - Batch [7800/8699], Train Loss: 0.023056033906200937, Train Acc: 0.9940284455128205
2024-04-29 10:21:45,539 - Batch [7900/8699], Train Loss: 0.022941434738402884, Train Acc: 0.9940585443037975
2024-04-29 10:22:03,443 - Batch [8000/8699], Train Loss: 0.022779557324841333, Train Acc: 0.994103515625
2024-04-29 10:22:20,910 - Batch [8100/8699], Train Loss: 0.02272497499743128, Train Acc: 0.9941261574074074
2024-04-29 10:22:39,894 - Batch [8200/8699], Train Loss: 0.022595576404404176, Train Acc: 0.9941615853658536
2024-04-29 10:22:59,041 - Batch [8300/8699], Train Loss: 0.02242991932292291, Train Acc: 0.9941905120481928
2024-04-29 10:23:17,753 - Batch [8400/8699], Train Loss: 0.02227794912113755, Train Acc: 0.9942261904761904
2024-04-29 10:23:37,499 - Batch [8500/8699], Train Loss: 0.022177486744119103, Train Acc: 0.9942591911764705
2024-04-29 10:23:56,643 - Batch [8600/8699], Train Loss: 0.022039025915539325, Train Acc: 0.9942932412790698
2024-04-29 10:24:16,061 - Train Loss: 0.021935267479324685, Train Acc: 0.9943198965294244
2024-04-29 10:26:24,943 - Test Acc: 0.9964719661423717
2024-04-29 10:26:25,018 - Confusion Matrix:
 [[67200   356]
 [  135 71480]]
2024-04-29 10:26:25,089 - Saved the new best model to ../data/models/pklot/all/80_20/mobilenet.pth
2024-04-29 10:26:25,089 - Epoch time: 1760.8401041030884 seconds.
2024-04-29 10:26:25,089 - Epoch 2/5
2024-04-29 10:26:59,749 - Batch [100/8699], Train Loss: 0.009497256601971458, Train Acc: 0.99640625
2024-04-29 10:27:18,116 - Batch [200/8699], Train Loss: 0.012068848782364512, Train Acc: 0.99671875
2024-04-29 10:27:36,986 - Batch [300/8699], Train Loss: 0.011310646973943222, Train Acc: 0.9969270833333334
2024-04-29 10:27:55,728 - Batch [400/8699], Train Loss: 0.013204506724669045, Train Acc: 0.9963671875
2024-04-29 10:28:14,601 - Batch [500/8699], Train Loss: 0.012759936216767529, Train Acc: 0.99653125
2024-04-29 10:28:34,389 - Batch [600/8699], Train Loss: 0.01414590216412762, Train Acc: 0.996015625
2024-04-29 10:28:53,133 - Batch [700/8699], Train Loss: 0.014352617593363643, Train Acc: 0.9960267857142857
2024-04-29 10:29:10,258 - Batch [800/8699], Train Loss: 0.014964136202206647, Train Acc: 0.99595703125
2024-04-29 10:29:28,165 - Batch [900/8699], Train Loss: 0.014522608051298043, Train Acc: 0.9960763888888889
2024-04-29 10:29:46,173 - Batch [1000/8699], Train Loss: 0.013611887361519621, Train Acc: 0.996359375
2024-04-29 10:30:04,456 - Batch [1100/8699], Train Loss: 0.013473020036266959, Train Acc: 0.9963352272727273
2024-04-29 10:30:22,418 - Batch [1200/8699], Train Loss: 0.01315130927277399, Train Acc: 0.99640625
2024-04-29 10:30:40,123 - Batch [1300/8699], Train Loss: 0.012968793410965681, Train Acc: 0.9964903846153846
2024-04-29 10:30:58,252 - Batch [1400/8699], Train Loss: 0.01289525551297889, Train Acc: 0.9965959821428572
2024-04-29 10:31:16,428 - Batch [1500/8699], Train Loss: 0.012766464525392318, Train Acc: 0.9966354166666667
2024-04-29 10:31:34,450 - Batch [1600/8699], Train Loss: 0.012694898979157187, Train Acc: 0.996650390625
2024-04-29 10:31:51,703 - Batch [1700/8699], Train Loss: 0.012561924992050454, Train Acc: 0.9966911764705882
2024-04-29 10:32:09,757 - Batch [1800/8699], Train Loss: 0.01224352764997295, Train Acc: 0.9967795138888889
2024-04-29 10:32:27,036 - Batch [1900/8699], Train Loss: 0.012279543610849559, Train Acc: 0.9967680921052632
2024-04-29 10:32:44,730 - Batch [2000/8699], Train Loss: 0.0122215784185355, Train Acc: 0.9967890625
2024-04-29 10:33:03,016 - Batch [2100/8699], Train Loss: 0.01218621608159516, Train Acc: 0.9968229166666667
2024-04-29 10:33:20,618 - Batch [2200/8699], Train Loss: 0.011930815758966094, Train Acc: 0.9969034090909091
2024-04-29 10:33:38,709 - Batch [2300/8699], Train Loss: 0.011918918585648973, Train Acc: 0.9969157608695652
2024-04-29 10:33:57,093 - Batch [2400/8699], Train Loss: 0.012023560309295741, Train Acc: 0.9969010416666667
2024-04-29 10:34:14,665 - Batch [2500/8699], Train Loss: 0.0119505648063845, Train Acc: 0.99689375
2024-04-29 10:34:32,100 - Batch [2600/8699], Train Loss: 0.01200185448125082, Train Acc: 0.9968810096153846
2024-04-29 10:34:49,649 - Batch [2700/8699], Train Loss: 0.011898857787181678, Train Acc: 0.9969212962962963
2024-04-29 10:35:07,953 - Batch [2800/8699], Train Loss: 0.011892810830786402, Train Acc: 0.9969587053571428
2024-04-29 10:35:26,137 - Batch [2900/8699], Train Loss: 0.011997103454130662, Train Acc: 0.9969450431034482
2024-04-29 10:35:43,496 - Batch [3000/8699], Train Loss: 0.011941798023268347, Train Acc: 0.9969322916666666
2024-04-29 10:36:01,451 - Batch [3100/8699], Train Loss: 0.012146367106057192, Train Acc: 0.9968699596774193
2024-04-29 10:36:18,892 - Batch [3200/8699], Train Loss: 0.012217161946728084, Train Acc: 0.9968359375
2024-04-29 10:36:37,762 - Batch [3300/8699], Train Loss: 0.01222083012748044, Train Acc: 0.9968323863636364
2024-04-29 10:36:55,839 - Batch [3400/8699], Train Loss: 0.012202113489919985, Train Acc: 0.9968428308823529
2024-04-29 10:37:13,291 - Batch [3500/8699], Train Loss: 0.01224681969402757, Train Acc: 0.9968392857142857
2024-04-29 10:37:31,375 - Batch [3600/8699], Train Loss: 0.012082661427698945, Train Acc: 0.9969053819444444
2024-04-29 10:37:48,668 - Batch [3700/8699], Train Loss: 0.012058089048121081, Train Acc: 0.9969425675675676
2024-04-29 10:38:06,650 - Batch [3800/8699], Train Loss: 0.012094550878889429, Train Acc: 0.9969325657894736
2024-04-29 10:38:24,717 - Batch [3900/8699], Train Loss: 0.012026082589063429, Train Acc: 0.9969511217948718
2024-04-29 10:38:41,851 - Batch [4000/8699], Train Loss: 0.011878350408671395, Train Acc: 0.99698046875
2024-04-29 10:38:58,633 - Batch [4100/8699], Train Loss: 0.011761617636297959, Train Acc: 0.997016006097561
2024-04-29 10:39:15,622 - Batch [4200/8699], Train Loss: 0.011769938537118356, Train Acc: 0.9970126488095238
2024-04-29 10:39:34,187 - Batch [4300/8699], Train Loss: 0.011684171052127271, Train Acc: 0.9970348837209302
2024-04-29 10:39:51,699 - Batch [4400/8699], Train Loss: 0.011573802119244811, Train Acc: 0.9970561079545455
2024-04-29 10:40:09,108 - Batch [4500/8699], Train Loss: 0.01156716545671548, Train Acc: 0.9970659722222223
2024-04-29 10:40:28,737 - Batch [4600/8699], Train Loss: 0.011615812150206614, Train Acc: 0.997055027173913
2024-04-29 10:40:47,486 - Batch [4700/8699], Train Loss: 0.011566431647534433, Train Acc: 0.9970744680851064
2024-04-29 10:41:06,888 - Batch [4800/8699], Train Loss: 0.011490828478896825, Train Acc: 0.99708984375
2024-04-29 10:41:26,563 - Batch [4900/8699], Train Loss: 0.01134457070577791, Train Acc: 0.9971173469387755
2024-04-29 10:41:45,717 - Batch [5000/8699], Train Loss: 0.011424864929258182, Train Acc: 0.99711875
2024-04-29 10:42:05,907 - Batch [5100/8699], Train Loss: 0.011426978069855478, Train Acc: 0.9971446078431373
2024-04-29 10:42:25,838 - Batch [5200/8699], Train Loss: 0.011406668421229999, Train Acc: 0.9971514423076923
2024-04-29 10:42:45,077 - Batch [5300/8699], Train Loss: 0.0113233277762217, Train Acc: 0.9971698113207547
2024-04-29 10:43:05,151 - Batch [5400/8699], Train Loss: 0.011341755297555075, Train Acc: 0.9971672453703704
2024-04-29 10:43:25,218 - Batch [5500/8699], Train Loss: 0.011259015580055182, Train Acc: 0.9971875
2024-04-29 10:43:44,449 - Batch [5600/8699], Train Loss: 0.011276925130044739, Train Acc: 0.9972014508928572
2024-04-29 10:44:04,615 - Batch [5700/8699], Train Loss: 0.011283766107084566, Train Acc: 0.9972066885964912
2024-04-29 10:44:24,438 - Batch [5800/8699], Train Loss: 0.011298435064895, Train Acc: 0.997209051724138
2024-04-29 10:44:43,771 - Batch [5900/8699], Train Loss: 0.01135544498947669, Train Acc: 0.9972113347457627
2024-04-29 10:45:03,024 - Batch [6000/8699], Train Loss: 0.011307744222165638, Train Acc: 0.99721875
2024-04-29 10:45:22,678 - Batch [6100/8699], Train Loss: 0.011273561156743453, Train Acc: 0.997218237704918
2024-04-29 10:45:42,235 - Batch [6200/8699], Train Loss: 0.01126140439910218, Train Acc: 0.9972328629032258
2024-04-29 10:46:02,200 - Batch [6300/8699], Train Loss: 0.011280385121350437, Train Acc: 0.9972271825396826
2024-04-29 10:46:21,676 - Batch [6400/8699], Train Loss: 0.011234316807806408, Train Acc: 0.99723388671875
2024-04-29 10:46:41,256 - Batch [6500/8699], Train Loss: 0.011196253178994923, Train Acc: 0.997235576923077
2024-04-29 10:47:01,139 - Batch [6600/8699], Train Loss: 0.011086223995830964, Train Acc: 0.9972608901515152
2024-04-29 10:47:20,075 - Batch [6700/8699], Train Loss: 0.0110896854255727, Train Acc: 0.9972644589552239
2024-04-29 10:47:37,747 - Batch [6800/8699], Train Loss: 0.011124077083474784, Train Acc: 0.9972449448529411
2024-04-29 10:47:55,631 - Batch [6900/8699], Train Loss: 0.011087465726275801, Train Acc: 0.9972622282608695
2024-04-29 10:48:15,034 - Batch [7000/8699], Train Loss: 0.011083559902921739, Train Acc: 0.9972544642857143
2024-04-29 10:48:35,160 - Batch [7100/8699], Train Loss: 0.01105720626598322, Train Acc: 0.9972645246478873
2024-04-29 10:48:55,000 - Batch [7200/8699], Train Loss: 0.011041159673798373, Train Acc: 0.9972699652777778
2024-04-29 10:49:13,956 - Batch [7300/8699], Train Loss: 0.01101973338679509, Train Acc: 0.997277397260274
2024-04-29 10:49:33,637 - Batch [7400/8699], Train Loss: 0.011004491913953078, Train Acc: 0.9972867398648648
2024-04-29 10:49:53,158 - Batch [7500/8699], Train Loss: 0.010977880652271657, Train Acc: 0.9972979166666667
2024-04-29 10:50:12,431 - Batch [7600/8699], Train Loss: 0.01094958660973182, Train Acc: 0.9973149671052631
2024-04-29 10:50:32,158 - Batch [7700/8699], Train Loss: 0.010946495528343756, Train Acc: 0.9973214285714286
2024-04-29 10:50:51,307 - Batch [7800/8699], Train Loss: 0.010906347370246528, Train Acc: 0.9973277243589743
2024-04-29 10:51:11,011 - Batch [7900/8699], Train Loss: 0.010873716719878631, Train Acc: 0.9973397943037975
2024-04-29 10:51:30,941 - Batch [8000/8699], Train Loss: 0.010907364891678071, Train Acc: 0.997337890625
2024-04-29 10:51:50,301 - Batch [8100/8699], Train Loss: 0.01084868368644796, Train Acc: 0.9973572530864198
2024-04-29 10:52:10,191 - Batch [8200/8699], Train Loss: 0.010802137479135703, Train Acc: 0.9973608993902439
2024-04-29 10:52:30,358 - Batch [8300/8699], Train Loss: 0.010804157680776841, Train Acc: 0.9973606927710843
2024-04-29 10:52:50,490 - Batch [8400/8699], Train Loss: 0.01080425397850095, Train Acc: 0.997358630952381
2024-04-29 10:53:10,260 - Batch [8500/8699], Train Loss: 0.010790439242912458, Train Acc: 0.9973658088235294
2024-04-29 10:53:30,343 - Batch [8600/8699], Train Loss: 0.010796445368588498, Train Acc: 0.9973673691860465
2024-04-29 10:53:50,390 - Train Loss: 0.01072643986574741, Train Acc: 0.9973862901487389
2024-04-29 10:56:03,101 - Test Acc: 0.9987066270990365
2024-04-29 10:56:03,162 - Confusion Matrix:
 [[67425   131]
 [   49 71566]]
2024-04-29 10:56:03,217 - Saved the new best model to ../data/models/pklot/all/80_20/mobilenet.pth
2024-04-29 10:56:03,217 - Epoch time: 1778.1285276412964 seconds.
2024-04-29 10:56:03,217 - Epoch 3/5
2024-04-29 10:56:39,459 - Batch [100/8699], Train Loss: 0.008325578121293802, Train Acc: 0.99828125
2024-04-29 10:56:59,824 - Batch [200/8699], Train Loss: 0.009928067160835781, Train Acc: 0.99765625
2024-04-29 10:57:20,117 - Batch [300/8699], Train Loss: 0.00794307804753771, Train Acc: 0.9981770833333333
2024-04-29 10:57:41,221 - Batch [400/8699], Train Loss: 0.007656257513244782, Train Acc: 0.9981640625
2024-04-29 10:58:02,360 - Batch [500/8699], Train Loss: 0.00810909679668839, Train Acc: 0.99803125
2024-04-29 10:58:23,773 - Batch [600/8699], Train Loss: 0.008470663066909766, Train Acc: 0.9979947916666667
2024-04-29 10:58:45,799 - Batch [700/8699], Train Loss: 0.008348701131950033, Train Acc: 0.9979910714285715
2024-04-29 10:59:06,679 - Batch [800/8699], Train Loss: 0.008670664896544621, Train Acc: 0.998046875
2024-04-29 10:59:27,707 - Batch [900/8699], Train Loss: 0.008736213879844097, Train Acc: 0.9980381944444444
2024-04-29 10:59:48,504 - Batch [1000/8699], Train Loss: 0.008739164185186383, Train Acc: 0.9980625
2024-04-29 11:00:09,928 - Batch [1100/8699], Train Loss: 0.008640464866925454, Train Acc: 0.9981534090909091
2024-04-29 11:00:31,519 - Batch [1200/8699], Train Loss: 0.008814866768813469, Train Acc: 0.9981380208333334
2024-04-29 11:00:53,266 - Batch [1300/8699], Train Loss: 0.008909024577817315, Train Acc: 0.9980528846153847
2024-04-29 11:01:14,627 - Batch [1400/8699], Train Loss: 0.008902482083872851, Train Acc: 0.9980580357142858
2024-04-29 11:01:35,642 - Batch [1500/8699], Train Loss: 0.008797986514876054, Train Acc: 0.99809375
2024-04-29 11:01:56,708 - Batch [1600/8699], Train Loss: 0.008687221777477135, Train Acc: 0.99810546875
2024-04-29 11:02:16,949 - Batch [1700/8699], Train Loss: 0.008999667388086571, Train Acc: 0.9980238970588236
2024-04-29 11:02:37,761 - Batch [1800/8699], Train Loss: 0.008939583199555476, Train Acc: 0.9979861111111111
2024-04-29 11:02:58,804 - Batch [1900/8699], Train Loss: 0.008918134171487365, Train Acc: 0.9979851973684211
2024-04-29 11:03:19,952 - Batch [2000/8699], Train Loss: 0.008980279450468516, Train Acc: 0.997984375
2024-04-29 11:03:40,857 - Batch [2100/8699], Train Loss: 0.008983344817135645, Train Acc: 0.9979985119047619
2024-04-29 11:04:01,893 - Batch [2200/8699], Train Loss: 0.008729396609647996, Train Acc: 0.9980255681818182
2024-04-29 11:04:22,684 - Batch [2300/8699], Train Loss: 0.008654710997492973, Train Acc: 0.998023097826087
2024-04-29 11:04:43,104 - Batch [2400/8699], Train Loss: 0.008780957403346293, Train Acc: 0.9980208333333334
2024-04-29 11:05:03,870 - Batch [2500/8699], Train Loss: 0.008723467680560135, Train Acc: 0.9980375
2024-04-29 11:05:24,786 - Batch [2600/8699], Train Loss: 0.008760647708439557, Train Acc: 0.998046875
2024-04-29 11:05:45,702 - Batch [2700/8699], Train Loss: 0.008807725611945056, Train Acc: 0.9980381944444444
2024-04-29 11:06:07,087 - Batch [2800/8699], Train Loss: 0.008649277769888743, Train Acc: 0.9980524553571428
2024-04-29 11:06:28,563 - Batch [2900/8699], Train Loss: 0.008580229728623667, Train Acc: 0.9980711206896552
2024-04-29 11:06:50,390 - Batch [3000/8699], Train Loss: 0.00850163489991731, Train Acc: 0.99809375
2024-04-29 11:07:12,577 - Batch [3100/8699], Train Loss: 0.008483257738349024, Train Acc: 0.9980997983870967
2024-04-29 11:07:34,463 - Batch [3200/8699], Train Loss: 0.00850318156874664, Train Acc: 0.9980908203125
2024-04-29 11:07:56,612 - Batch [3300/8699], Train Loss: 0.008524241215237646, Train Acc: 0.998091856060606
2024-04-29 11:08:18,227 - Batch [3400/8699], Train Loss: 0.008563626759130463, Train Acc: 0.998079044117647
2024-04-29 11:08:40,123 - Batch [3500/8699], Train Loss: 0.008602990339541325, Train Acc: 0.9980625
2024-04-29 11:09:01,605 - Batch [3600/8699], Train Loss: 0.008558160441742884, Train Acc: 0.9980729166666666
2024-04-29 11:09:22,743 - Batch [3700/8699], Train Loss: 0.008625594681949665, Train Acc: 0.9980363175675676
2024-04-29 11:09:43,476 - Batch [3800/8699], Train Loss: 0.008585178258213809, Train Acc: 0.9980633223684211
2024-04-29 11:10:05,046 - Batch [3900/8699], Train Loss: 0.008524863727966127, Train Acc: 0.9980649038461539
2024-04-29 11:10:26,376 - Batch [4000/8699], Train Loss: 0.00851756221627511, Train Acc: 0.998078125
2024-04-29 11:10:47,638 - Batch [4100/8699], Train Loss: 0.008480040513815942, Train Acc: 0.9980830792682926
2024-04-29 11:11:09,391 - Batch [4200/8699], Train Loss: 0.008428741558151766, Train Acc: 0.9980952380952381
2024-04-29 11:11:30,935 - Batch [4300/8699], Train Loss: 0.008431589490150949, Train Acc: 0.9981068313953488
2024-04-29 11:11:52,774 - Batch [4400/8699], Train Loss: 0.008337057864486765, Train Acc: 0.998125
2024-04-29 11:12:14,272 - Batch [4500/8699], Train Loss: 0.00832386540166125, Train Acc: 0.9981180555555556
2024-04-29 11:12:35,517 - Batch [4600/8699], Train Loss: 0.008229337875395488, Train Acc: 0.9981419836956522
2024-04-29 11:12:56,906 - Batch [4700/8699], Train Loss: 0.008160981078283239, Train Acc: 0.9981615691489362
2024-04-29 11:13:17,682 - Batch [4800/8699], Train Loss: 0.008062504784788871, Train Acc: 0.99818359375
2024-04-29 11:13:38,707 - Batch [4900/8699], Train Loss: 0.00806742050151245, Train Acc: 0.9981887755102041
2024-04-29 11:14:00,170 - Batch [5000/8699], Train Loss: 0.008083677069647093, Train Acc: 0.9982
2024-04-29 11:14:20,855 - Batch [5100/8699], Train Loss: 0.008074148606611547, Train Acc: 0.9982107843137255
2024-04-29 11:14:41,683 - Batch [5200/8699], Train Loss: 0.008039336200431185, Train Acc: 0.9982241586538462
2024-04-29 11:15:02,924 - Batch [5300/8699], Train Loss: 0.008016574901848112, Train Acc: 0.9982370283018868
2024-04-29 11:15:24,457 - Batch [5400/8699], Train Loss: 0.008036056536517814, Train Acc: 0.9982378472222222
2024-04-29 11:15:44,657 - Batch [5500/8699], Train Loss: 0.00809212059281113, Train Acc: 0.9982272727272727
2024-04-29 11:16:05,538 - Batch [5600/8699], Train Loss: 0.008181138675536853, Train Acc: 0.9982198660714285
2024-04-29 11:16:26,748 - Batch [5700/8699], Train Loss: 0.008074909428736678, Train Acc: 0.9982428728070175
2024-04-29 11:16:47,348 - Batch [5800/8699], Train Loss: 0.008196234329638612, Train Acc: 0.9982165948275862
2024-04-29 11:17:08,310 - Batch [5900/8699], Train Loss: 0.008154875105344942, Train Acc: 0.9982229872881356
2024-04-29 11:17:29,179 - Batch [6000/8699], Train Loss: 0.00812572541678249, Train Acc: 0.9982291666666666
2024-04-29 11:17:49,693 - Batch [6100/8699], Train Loss: 0.008060827462565508, Train Acc: 0.9982300204918033
2024-04-29 11:18:09,550 - Batch [6200/8699], Train Loss: 0.008088818397952691, Train Acc: 0.9982232862903225
2024-04-29 11:18:30,685 - Batch [6300/8699], Train Loss: 0.008125756283352818, Train Acc: 0.9982242063492064
2024-04-29 11:18:51,757 - Batch [6400/8699], Train Loss: 0.008077815068796781, Train Acc: 0.99823486328125
2024-04-29 11:19:13,465 - Batch [6500/8699], Train Loss: 0.00806043074048872, Train Acc: 0.9982379807692308
2024-04-29 11:19:35,613 - Batch [6600/8699], Train Loss: 0.00803236584554697, Train Acc: 0.9982457386363637
2024-04-29 11:19:57,163 - Batch [6700/8699], Train Loss: 0.008057325636817502, Train Acc: 0.9982392723880597
2024-04-29 11:20:17,412 - Batch [6800/8699], Train Loss: 0.007982154038863347, Train Acc: 0.9982559742647059
2024-04-29 11:20:38,426 - Batch [6900/8699], Train Loss: 0.007935618857444607, Train Acc: 0.9982586050724638
2024-04-29 11:20:59,870 - Batch [7000/8699], Train Loss: 0.008009189713240111, Train Acc: 0.9982455357142858
2024-04-29 11:21:20,990 - Batch [7100/8699], Train Loss: 0.008076351387025567, Train Acc: 0.9982240316901408
2024-04-29 11:21:42,374 - Batch [7200/8699], Train Loss: 0.008089720262951232, Train Acc: 0.9982204861111111
2024-04-29 11:22:03,869 - Batch [7300/8699], Train Loss: 0.008172088338394869, Train Acc: 0.9981999143835616
2024-04-29 11:22:25,326 - Batch [7400/8699], Train Loss: 0.008165441101938651, Train Acc: 0.998203125
2024-04-29 11:22:46,563 - Batch [7500/8699], Train Loss: 0.008213299881408846, Train Acc: 0.99819375
2024-04-29 11:23:08,590 - Batch [7600/8699], Train Loss: 0.008254526457000649, Train Acc: 0.9981907894736842
2024-04-29 11:23:30,460 - Batch [7700/8699], Train Loss: 0.008242096508285801, Train Acc: 0.9981838474025974
2024-04-29 11:23:52,473 - Batch [7800/8699], Train Loss: 0.00821859950549902, Train Acc: 0.998183092948718
2024-04-29 11:24:14,330 - Batch [7900/8699], Train Loss: 0.008177171913393746, Train Acc: 0.9981962025316455
2024-04-29 11:24:36,505 - Batch [8000/8699], Train Loss: 0.00813646336875172, Train Acc: 0.998205078125
2024-04-29 11:24:58,339 - Batch [8100/8699], Train Loss: 0.008143388455705631, Train Acc: 0.9982021604938272
2024-04-29 11:25:19,312 - Batch [8200/8699], Train Loss: 0.008148186580402558, Train Acc: 0.9982012195121951
2024-04-29 11:25:41,466 - Batch [8300/8699], Train Loss: 0.008134902510357212, Train Acc: 0.9982021837349397
2024-04-29 11:26:03,513 - Batch [8400/8699], Train Loss: 0.008147652902365994, Train Acc: 0.998203125
2024-04-29 11:26:25,434 - Batch [8500/8699], Train Loss: 0.008178675164547337, Train Acc: 0.998202205882353
2024-04-29 11:26:46,936 - Batch [8600/8699], Train Loss: 0.00817380944446276, Train Acc: 0.9982013081395349
2024-04-29 11:27:08,888 - Train Loss: 0.008150175737058766, Train Acc: 0.9982054322052166
2024-04-29 11:29:31,947 - Test Acc: 0.9987425541240632
2024-04-29 11:29:32,006 - Confusion Matrix:
 [[67424   132]
 [   43 71572]]
2024-04-29 11:29:32,063 - Saved the new best model to ../data/models/pklot/all/80_20/mobilenet.pth
2024-04-29 11:29:32,063 - Epoch time: 2008.8457443714142 seconds.
2024-04-29 11:29:32,063 - Epoch 4/5
2024-04-29 11:30:10,239 - Batch [100/8699], Train Loss: 0.005750741355150239, Train Acc: 0.9984375
2024-04-29 11:30:30,915 - Batch [200/8699], Train Loss: 0.008971078032263904, Train Acc: 0.99796875
2024-04-29 11:30:52,200 - Batch [300/8699], Train Loss: 0.008246323111864816, Train Acc: 0.9980729166666666
2024-04-29 11:31:14,534 - Batch [400/8699], Train Loss: 0.008864343475543136, Train Acc: 0.99796875
2024-04-29 11:31:37,725 - Batch [500/8699], Train Loss: 0.007425138674378104, Train Acc: 0.99834375
2024-04-29 11:32:00,728 - Batch [600/8699], Train Loss: 0.0075473106448832065, Train Acc: 0.998359375
2024-04-29 11:32:22,191 - Batch [700/8699], Train Loss: 0.00771930680506817, Train Acc: 0.9983482142857143
2024-04-29 11:32:43,236 - Batch [800/8699], Train Loss: 0.008463966690874259, Train Acc: 0.99806640625
2024-04-29 11:33:05,310 - Batch [900/8699], Train Loss: 0.007943053010223796, Train Acc: 0.9981597222222223
2024-04-29 11:33:29,089 - Batch [1000/8699], Train Loss: 0.007506967724635615, Train Acc: 0.998234375
2024-04-29 11:33:52,771 - Batch [1100/8699], Train Loss: 0.0070162783401577725, Train Acc: 0.9983238636363636
2024-04-29 11:34:15,761 - Batch [1200/8699], Train Loss: 0.0067182739758103105, Train Acc: 0.9983333333333333
2024-04-29 11:34:36,563 - Batch [1300/8699], Train Loss: 0.006556159457514485, Train Acc: 0.9983774038461538
2024-04-29 11:34:56,422 - Batch [1400/8699], Train Loss: 0.00639673216511775, Train Acc: 0.9984263392857143
2024-04-29 11:35:15,791 - Batch [1500/8699], Train Loss: 0.006562125600084983, Train Acc: 0.9984270833333333
2024-04-29 11:35:35,004 - Batch [1600/8699], Train Loss: 0.006697279333671986, Train Acc: 0.998427734375
2024-04-29 11:35:54,882 - Batch [1700/8699], Train Loss: 0.006625511903596763, Train Acc: 0.9984558823529411
2024-04-29 11:36:13,876 - Batch [1800/8699], Train Loss: 0.006713824233573986, Train Acc: 0.9984201388888889
2024-04-29 11:36:33,532 - Batch [1900/8699], Train Loss: 0.006829349016201089, Train Acc: 0.9984046052631579
2024-04-29 11:36:52,866 - Batch [2000/8699], Train Loss: 0.00694786557039788, Train Acc: 0.9983671875
2024-04-29 11:37:12,104 - Batch [2100/8699], Train Loss: 0.006911347195987868, Train Acc: 0.9984002976190476
2024-04-29 11:37:30,107 - Batch [2200/8699], Train Loss: 0.006791777080021678, Train Acc: 0.9984375
2024-04-29 11:37:47,931 - Batch [2300/8699], Train Loss: 0.006868006727894997, Train Acc: 0.9984510869565217
2024-04-29 11:38:06,492 - Batch [2400/8699], Train Loss: 0.007049573616293401, Train Acc: 0.9984375
2024-04-29 11:38:26,906 - Batch [2500/8699], Train Loss: 0.006991442242949415, Train Acc: 0.99845
2024-04-29 11:38:45,938 - Batch [2600/8699], Train Loss: 0.007115873099949637, Train Acc: 0.9984194711538461
2024-04-29 11:39:04,187 - Batch [2700/8699], Train Loss: 0.007199304857417533, Train Acc: 0.9983854166666667
2024-04-29 11:39:21,497 - Batch [2800/8699], Train Loss: 0.0072339920287134065, Train Acc: 0.9983872767857143
2024-04-29 11:39:39,458 - Batch [2900/8699], Train Loss: 0.0072790666016332795, Train Acc: 0.9983782327586207
2024-04-29 11:39:59,227 - Batch [3000/8699], Train Loss: 0.007221174906396603, Train Acc: 0.9983802083333333
2024-04-29 11:40:17,904 - Batch [3100/8699], Train Loss: 0.0072804545491776335, Train Acc: 0.9983770161290323
2024-04-29 11:40:36,751 - Batch [3200/8699], Train Loss: 0.007246666519404812, Train Acc: 0.9983837890625
2024-04-29 11:40:54,949 - Batch [3300/8699], Train Loss: 0.007186955742048612, Train Acc: 0.9983712121212122
2024-04-29 11:41:12,804 - Batch [3400/8699], Train Loss: 0.007303103381536858, Train Acc: 0.9983318014705882
2024-04-29 11:41:32,056 - Batch [3500/8699], Train Loss: 0.0072928450479235575, Train Acc: 0.9983214285714286
2024-04-29 11:41:50,142 - Batch [3600/8699], Train Loss: 0.007390551290773651, Train Acc: 0.9983072916666667
2024-04-29 11:42:09,532 - Batch [3700/8699], Train Loss: 0.007293808483696134, Train Acc: 0.9983361486486486
2024-04-29 11:42:29,131 - Batch [3800/8699], Train Loss: 0.0073386336915298575, Train Acc: 0.9983264802631578
2024-04-29 11:42:48,519 - Batch [3900/8699], Train Loss: 0.007247559616946371, Train Acc: 0.9983413461538462
2024-04-29 11:43:07,651 - Batch [4000/8699], Train Loss: 0.007236929639246682, Train Acc: 0.9983515625
2024-04-29 11:43:27,424 - Batch [4100/8699], Train Loss: 0.007237918660053632, Train Acc: 0.9983574695121952
2024-04-29 11:43:47,132 - Batch [4200/8699], Train Loss: 0.00731312891830861, Train Acc: 0.9983556547619048
2024-04-29 11:44:06,900 - Batch [4300/8699], Train Loss: 0.00725693746803636, Train Acc: 0.9983757267441861
2024-04-29 11:44:24,720 - Batch [4400/8699], Train Loss: 0.007138350240406908, Train Acc: 0.9984019886363636
2024-04-29 11:44:43,089 - Batch [4500/8699], Train Loss: 0.007210723454950413, Train Acc: 0.9983819444444444
2024-04-29 11:45:01,901 - Batch [4600/8699], Train Loss: 0.007272301466170931, Train Acc: 0.9983797554347826
2024-04-29 11:45:21,160 - Batch [4700/8699], Train Loss: 0.007247702036435859, Train Acc: 0.9983909574468085
2024-04-29 11:45:40,517 - Batch [4800/8699], Train Loss: 0.0072697896057673005, Train Acc: 0.9983756510416667
2024-04-29 11:46:00,227 - Batch [4900/8699], Train Loss: 0.007358971119582358, Train Acc: 0.9983673469387755
2024-04-29 11:46:19,179 - Batch [5000/8699], Train Loss: 0.007312005928725921, Train Acc: 0.998378125
2024-04-29 11:46:38,076 - Batch [5100/8699], Train Loss: 0.007291715866891429, Train Acc: 0.9983823529411765
2024-04-29 11:46:56,881 - Batch [5200/8699], Train Loss: 0.007403487019131926, Train Acc: 0.9983683894230769
2024-04-29 11:47:15,500 - Batch [5300/8699], Train Loss: 0.007455846454897324, Train Acc: 0.9983637971698113
2024-04-29 11:47:36,006 - Batch [5400/8699], Train Loss: 0.007479160240038793, Train Acc: 0.9983622685185185
2024-04-29 11:47:55,415 - Batch [5500/8699], Train Loss: 0.0074715413436136835, Train Acc: 0.9983664772727273
2024-04-29 11:48:14,416 - Batch [5600/8699], Train Loss: 0.0074034353001645415, Train Acc: 0.9983761160714286
2024-04-29 11:48:33,825 - Batch [5700/8699], Train Loss: 0.007394670147058876, Train Acc: 0.9983854166666667
2024-04-29 11:48:53,323 - Batch [5800/8699], Train Loss: 0.007356504039730209, Train Acc: 0.9983943965517241
2024-04-29 11:49:13,222 - Batch [5900/8699], Train Loss: 0.007371139218253505, Train Acc: 0.9984004237288135
2024-04-29 11:49:31,025 - Batch [6000/8699], Train Loss: 0.00729656829827915, Train Acc: 0.9984192708333334
2024-04-29 11:49:50,068 - Batch [6100/8699], Train Loss: 0.007244100681327836, Train Acc: 0.9984323770491803
2024-04-29 11:50:12,296 - Batch [6200/8699], Train Loss: 0.0072105568685498335, Train Acc: 0.9984450604838709
2024-04-29 11:50:32,599 - Batch [6300/8699], Train Loss: 0.00717978645469812, Train Acc: 0.9984474206349206
2024-04-29 11:50:51,179 - Batch [6400/8699], Train Loss: 0.007164670078053348, Train Acc: 0.99845458984375
2024-04-29 11:51:10,206 - Batch [6500/8699], Train Loss: 0.007090788775460309, Train Acc: 0.9984735576923077
2024-04-29 11:51:30,297 - Batch [6600/8699], Train Loss: 0.007077526191228709, Train Acc: 0.9984706439393939
2024-04-29 11:51:50,667 - Batch [6700/8699], Train Loss: 0.007034012537238704, Train Acc: 0.9984748134328358
2024-04-29 11:52:09,760 - Batch [6800/8699], Train Loss: 0.0070444468318044745, Train Acc: 0.9984742647058824
2024-04-29 11:52:29,401 - Batch [6900/8699], Train Loss: 0.007046899343916701, Train Acc: 0.9984759963768116
2024-04-29 11:52:47,891 - Batch [7000/8699], Train Loss: 0.007013029020993729, Train Acc: 0.9984866071428572
2024-04-29 11:53:07,777 - Batch [7100/8699], Train Loss: 0.007026326988758535, Train Acc: 0.9984903169014084
2024-04-29 11:53:25,706 - Batch [7200/8699], Train Loss: 0.007014590069573185, Train Acc: 0.9984939236111111
2024-04-29 11:53:43,852 - Batch [7300/8699], Train Loss: 0.007019889562076583, Train Acc: 0.9984931506849315
2024-04-29 11:54:01,810 - Batch [7400/8699], Train Loss: 0.006978923214433913, Train Acc: 0.9985008445945946
2024-04-29 11:54:19,389 - Batch [7500/8699], Train Loss: 0.006986227509316329, Train Acc: 0.9985041666666666
2024-04-29 11:54:37,293 - Batch [7600/8699], Train Loss: 0.006929807126112121, Train Acc: 0.998515625
2024-04-29 11:54:55,150 - Batch [7700/8699], Train Loss: 0.006901174649903695, Train Acc: 0.9985247564935065
2024-04-29 11:55:12,924 - Batch [7800/8699], Train Loss: 0.006897119923196442, Train Acc: 0.9985216346153846
2024-04-29 11:55:30,947 - Batch [7900/8699], Train Loss: 0.006889353121158923, Train Acc: 0.9985245253164557
2024-04-29 11:55:48,610 - Batch [8000/8699], Train Loss: 0.006887208310361075, Train Acc: 0.998521484375
2024-04-29 11:56:06,397 - Batch [8100/8699], Train Loss: 0.006885250332336538, Train Acc: 0.9985223765432099
2024-04-29 11:56:24,302 - Batch [8200/8699], Train Loss: 0.006860480702788907, Train Acc: 0.9985270579268293
2024-04-29 11:56:41,939 - Batch [8300/8699], Train Loss: 0.006870799123031927, Train Acc: 0.9985278614457831
2024-04-29 11:56:59,819 - Batch [8400/8699], Train Loss: 0.006940094238260869, Train Acc: 0.9985137648809523
2024-04-29 11:57:17,892 - Batch [8500/8699], Train Loss: 0.006977293774008371, Train Acc: 0.9985036764705882
2024-04-29 11:57:36,133 - Batch [8600/8699], Train Loss: 0.006995845188080556, Train Acc: 0.998499273255814
2024-04-29 11:57:54,521 - Train Loss: 0.006989104426173669, Train Acc: 0.9984964431989652
2024-04-29 11:59:56,470 - Test Acc: 0.9985341773789079
2024-04-29 11:59:56,531 - Confusion Matrix:
 [[67466    90]
 [  114 71501]]
2024-04-29 11:59:56,581 - Saved the new best model to ../data/models/pklot/all/80_20/mobilenet.pth
2024-04-29 11:59:56,581 - Epoch time: 1824.5179708003998 seconds.
2024-04-29 11:59:56,581 - Epoch 5/5
2024-04-29 12:00:29,323 - Batch [100/8699], Train Loss: 0.001854856841964647, Train Acc: 0.99953125
2024-04-29 12:00:46,250 - Batch [200/8699], Train Loss: 0.005212396937022277, Train Acc: 0.999140625
2024-04-29 12:01:03,687 - Batch [300/8699], Train Loss: 0.006447192605337477, Train Acc: 0.99875
2024-04-29 12:01:21,484 - Batch [400/8699], Train Loss: 0.006576296550538246, Train Acc: 0.998671875
2024-04-29 12:01:39,178 - Batch [500/8699], Train Loss: 0.005996030752328806, Train Acc: 0.9988125
2024-04-29 12:01:57,016 - Batch [600/8699], Train Loss: 0.006367799056206423, Train Acc: 0.9986979166666666
2024-04-29 12:02:14,972 - Batch [700/8699], Train Loss: 0.006841076568681663, Train Acc: 0.9985714285714286
2024-04-29 12:02:33,075 - Batch [800/8699], Train Loss: 0.006843471106672041, Train Acc: 0.99853515625
2024-04-29 12:02:51,151 - Batch [900/8699], Train Loss: 0.006781164865771845, Train Acc: 0.9985416666666667
2024-04-29 12:03:09,056 - Batch [1000/8699], Train Loss: 0.0064612476679722025, Train Acc: 0.998609375
2024-04-29 12:03:27,104 - Batch [1100/8699], Train Loss: 0.0060812279112426705, Train Acc: 0.9986647727272727
2024-04-29 12:03:45,175 - Batch [1200/8699], Train Loss: 0.006141518350432307, Train Acc: 0.9986067708333334
2024-04-29 12:04:03,250 - Batch [1300/8699], Train Loss: 0.005889901484084616, Train Acc: 0.9985697115384615
2024-04-29 12:04:21,314 - Batch [1400/8699], Train Loss: 0.005706249655777356, Train Acc: 0.9986272321428571
2024-04-29 12:04:39,403 - Batch [1500/8699], Train Loss: 0.00596083618374784, Train Acc: 0.9986354166666667
2024-04-29 12:04:57,381 - Batch [1600/8699], Train Loss: 0.00589193274220861, Train Acc: 0.9986328125
2024-04-29 12:05:15,123 - Batch [1700/8699], Train Loss: 0.005928773332332853, Train Acc: 0.9986121323529412
2024-04-29 12:05:32,997 - Batch [1800/8699], Train Loss: 0.0058059329183116565, Train Acc: 0.9986458333333333
2024-04-29 12:05:50,825 - Batch [1900/8699], Train Loss: 0.005855449711037325, Train Acc: 0.9986266447368422
2024-04-29 12:06:09,539 - Batch [2000/8699], Train Loss: 0.005892326863138806, Train Acc: 0.9986171875
2024-04-29 12:06:29,088 - Batch [2100/8699], Train Loss: 0.0059356554216026865, Train Acc: 0.9986383928571428
2024-04-29 12:06:46,674 - Batch [2200/8699], Train Loss: 0.005797805217875562, Train Acc: 0.9986647727272727
2024-04-29 12:07:04,108 - Batch [2300/8699], Train Loss: 0.005746757767261917, Train Acc: 0.9986820652173913
2024-04-29 12:07:23,076 - Batch [2400/8699], Train Loss: 0.005761535704389947, Train Acc: 0.9987044270833333
2024-04-29 12:07:41,377 - Batch [2500/8699], Train Loss: 0.005694172549532959, Train Acc: 0.99873125
2024-04-29 12:08:00,499 - Batch [2600/8699], Train Loss: 0.005693979749373214, Train Acc: 0.9987379807692308
2024-04-29 12:08:18,666 - Batch [2700/8699], Train Loss: 0.005752862849993916, Train Acc: 0.998744212962963
2024-04-29 12:08:36,466 - Batch [2800/8699], Train Loss: 0.006002795767763018, Train Acc: 0.9987165178571429
2024-04-29 12:08:54,648 - Batch [2900/8699], Train Loss: 0.00596808708637174, Train Acc: 0.99875
2024-04-29 12:09:11,760 - Batch [3000/8699], Train Loss: 0.005960706745783682, Train Acc: 0.99875
2024-04-29 12:09:29,409 - Batch [3100/8699], Train Loss: 0.00606448349842873, Train Acc: 0.9987348790322581
2024-04-29 12:09:47,779 - Batch [3200/8699], Train Loss: 0.006089374810153458, Train Acc: 0.9987353515625
2024-04-29 12:10:05,160 - Batch [3300/8699], Train Loss: 0.006076095595657755, Train Acc: 0.9987310606060606
2024-04-29 12:10:24,437 - Batch [3400/8699], Train Loss: 0.0060746885323597405, Train Acc: 0.9987362132352942
2024-04-29 12:10:42,038 - Batch [3500/8699], Train Loss: 0.006199738635960135, Train Acc: 0.9987232142857143
2024-04-29 12:11:00,173 - Batch [3600/8699], Train Loss: 0.0062065131852149435, Train Acc: 0.9987326388888889
2024-04-29 12:11:17,905 - Batch [3700/8699], Train Loss: 0.006219402116029586, Train Acc: 0.998745777027027
2024-04-29 12:11:35,746 - Batch [3800/8699], Train Loss: 0.006174212933960677, Train Acc: 0.9987582236842105
2024-04-29 12:11:53,251 - Batch [3900/8699], Train Loss: 0.006106426430431804, Train Acc: 0.998770032051282
2024-04-29 12:12:12,015 - Batch [4000/8699], Train Loss: 0.006017927862429133, Train Acc: 0.9987890625
2024-04-29 12:12:29,817 - Batch [4100/8699], Train Loss: 0.006111102258169345, Train Acc: 0.9987614329268293
2024-04-29 12:12:48,058 - Batch [4200/8699], Train Loss: 0.006143786450579466, Train Acc: 0.9987462797619048
2024-04-29 12:13:05,864 - Batch [4300/8699], Train Loss: 0.006132534101008448, Train Acc: 0.99875
2024-04-29 12:13:24,224 - Batch [4400/8699], Train Loss: 0.006242566890519315, Train Acc: 0.9987286931818182
2024-04-29 12:13:44,348 - Batch [4500/8699], Train Loss: 0.0061916934167133555, Train Acc: 0.9987291666666667
2024-04-29 12:14:04,455 - Batch [4600/8699], Train Loss: 0.006307037771201304, Train Acc: 0.9987058423913043
2024-04-29 12:14:23,949 - Batch [4700/8699], Train Loss: 0.0062510089511016165, Train Acc: 0.9987101063829787
2024-04-29 12:14:43,671 - Batch [4800/8699], Train Loss: 0.006230184972383389, Train Acc: 0.998720703125
2024-04-29 12:15:01,391 - Batch [4900/8699], Train Loss: 0.0063286124473538345, Train Acc: 0.9987117346938775
2024-04-29 12:15:18,984 - Batch [5000/8699], Train Loss: 0.006268244529072399, Train Acc: 0.998715625
2024-04-29 12:15:37,951 - Batch [5100/8699], Train Loss: 0.006271677577137512, Train Acc: 0.9987101715686274
2024-04-29 12:15:57,513 - Batch [5200/8699], Train Loss: 0.006224576236185245, Train Acc: 0.9987079326923077
2024-04-29 12:16:15,343 - Batch [5300/8699], Train Loss: 0.006168335678314247, Train Acc: 0.9987205188679246
2024-04-29 12:16:33,064 - Batch [5400/8699], Train Loss: 0.006158539837104197, Train Acc: 0.9987239583333334
2024-04-29 12:16:53,524 - Batch [5500/8699], Train Loss: 0.006150416313624936, Train Acc: 0.9987244318181818
2024-04-29 12:17:12,189 - Batch [5600/8699], Train Loss: 0.006166953884439213, Train Acc: 0.9987193080357143
2024-04-29 12:17:29,988 - Batch [5700/8699], Train Loss: 0.006183282814433226, Train Acc: 0.998719846491228
2024-04-29 12:17:47,499 - Batch [5800/8699], Train Loss: 0.006189606169951605, Train Acc: 0.998728448275862
2024-04-29 12:18:04,436 - Batch [5900/8699], Train Loss: 0.0062308916245419205, Train Acc: 0.998718220338983
2024-04-29 12:18:21,899 - Batch [6000/8699], Train Loss: 0.0062164612069676274, Train Acc: 0.9987213541666666
2024-04-29 12:18:40,689 - Batch [6100/8699], Train Loss: 0.006247940586981116, Train Acc: 0.9987243852459017
2024-04-29 12:18:57,881 - Batch [6200/8699], Train Loss: 0.006242983888965799, Train Acc: 0.9987222782258065
2024-04-29 12:19:15,806 - Batch [6300/8699], Train Loss: 0.006217030910865726, Train Acc: 0.9987251984126985
2024-04-29 12:19:33,524 - Batch [6400/8699], Train Loss: 0.006199427682337841, Train Acc: 0.9987353515625
2024-04-29 12:19:52,572 - Batch [6500/8699], Train Loss: 0.006138635318774994, Train Acc: 0.9987403846153846
2024-04-29 12:20:09,841 - Batch [6600/8699], Train Loss: 0.006194736623240191, Train Acc: 0.9987263257575758
2024-04-29 12:20:27,222 - Batch [6700/8699], Train Loss: 0.006233684905164952, Train Acc: 0.9987196828358209
2024-04-29 12:20:44,598 - Batch [6800/8699], Train Loss: 0.00622046212177445, Train Acc: 0.9987201286764706
2024-04-29 12:21:01,743 - Batch [6900/8699], Train Loss: 0.006217665170527429, Train Acc: 0.9987273550724638
2024-04-29 12:21:19,144 - Batch [7000/8699], Train Loss: 0.006160022614804932, Train Acc: 0.9987433035714286
2024-04-29 12:21:36,547 - Batch [7100/8699], Train Loss: 0.006173481636945159, Train Acc: 0.9987389964788732
2024-04-29 12:21:54,130 - Batch [7200/8699], Train Loss: 0.006186630206052542, Train Acc: 0.9987282986111111
2024-04-29 12:22:11,237 - Batch [7300/8699], Train Loss: 0.006164165778572082, Train Acc: 0.9987328767123288
2024-04-29 12:22:28,219 - Batch [7400/8699], Train Loss: 0.00610950706209248, Train Acc: 0.9987436655405405
2024-04-29 12:22:45,334 - Batch [7500/8699], Train Loss: 0.006144346371998351, Train Acc: 0.9987416666666666
2024-04-29 12:23:02,543 - Batch [7600/8699], Train Loss: 0.006077271801584031, Train Acc: 0.9987561677631579
2024-04-29 12:23:20,034 - Batch [7700/8699], Train Loss: 0.006072744548671528, Train Acc: 0.9987581168831169
2024-04-29 12:23:37,514 - Batch [7800/8699], Train Loss: 0.006084872749607968, Train Acc: 0.9987560096153846
2024-04-29 12:23:54,979 - Batch [7900/8699], Train Loss: 0.006146544962878268, Train Acc: 0.9987361550632912
2024-04-29 12:24:12,136 - Batch [8000/8699], Train Loss: 0.006156786281379937, Train Acc: 0.998732421875
2024-04-29 12:24:29,312 - Batch [8100/8699], Train Loss: 0.006142586274718381, Train Acc: 0.9987345679012346
2024-04-29 12:24:46,683 - Batch [8200/8699], Train Loss: 0.006145603061548439, Train Acc: 0.9987328506097561
2024-04-29 12:25:04,108 - Batch [8300/8699], Train Loss: 0.006144107324186066, Train Acc: 0.9987311746987951
2024-04-29 12:25:21,259 - Batch [8400/8699], Train Loss: 0.006092420225099236, Train Acc: 0.9987369791666667
2024-04-29 12:25:38,656 - Batch [8500/8699], Train Loss: 0.00612627932582708, Train Acc: 0.998733455882353
2024-04-29 12:25:56,101 - Batch [8600/8699], Train Loss: 0.006150143476356049, Train Acc: 0.9987245639534884
2024-04-29 12:26:13,745 - Train Loss: 0.006174159300952207, Train Acc: 0.9987173959905152
2024-04-29 12:28:16,257 - Test Acc: 0.9979809011934958
2024-04-29 12:28:16,315 - Confusion Matrix:
 [[67477    79]
 [  202 71413]]
2024-04-29 12:28:16,371 - Saved the new best model to ../data/models/pklot/all/80_20/mobilenet.pth
2024-04-29 12:28:16,371 - Epoch time: 1699.7903084754944 seconds.
2024-04-29 12:28:16,372 - Best Train Acc: 0.9987173959905152
2024-04-29 12:28:16,374 - Total training time: 9072.124654769897 seconds.
