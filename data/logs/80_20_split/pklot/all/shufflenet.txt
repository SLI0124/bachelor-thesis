2024-04-29 18:00:32,366 - Training the model...
2024-04-29 18:00:32,366 - Epoch 1/5
2024-04-29 18:00:54,902 - Batch [100/8699], Train Loss: 0.44329729737713935, Train Acc: 0.9259375
2024-04-29 18:01:00,147 - Batch [200/8699], Train Loss: 0.25891525669023396, Train Acc: 0.951171875
2024-04-29 18:01:05,352 - Batch [300/8699], Train Loss: 0.19237875301080445, Train Acc: 0.96046875
2024-04-29 18:01:10,624 - Batch [400/8699], Train Loss: 0.15542298524465878, Train Acc: 0.9663671875
2024-04-29 18:01:18,197 - Batch [500/8699], Train Loss: 0.13101973701943642, Train Acc: 0.971
2024-04-29 18:01:23,610 - Batch [600/8699], Train Loss: 0.11581042749477395, Train Acc: 0.9737239583333334
2024-04-29 18:01:29,324 - Batch [700/8699], Train Loss: 0.10336852355178312, Train Acc: 0.97625
2024-04-29 18:01:35,199 - Batch [800/8699], Train Loss: 0.0947113780399377, Train Acc: 0.977890625
2024-04-29 18:01:40,426 - Batch [900/8699], Train Loss: 0.08753824477640187, Train Acc: 0.9792708333333333
2024-04-29 18:01:45,470 - Batch [1000/8699], Train Loss: 0.08153040257346583, Train Acc: 0.98053125
2024-04-29 18:01:50,865 - Batch [1100/8699], Train Loss: 0.07680681275087409, Train Acc: 0.9814914772727272
2024-04-29 18:01:56,048 - Batch [1200/8699], Train Loss: 0.0724067595040348, Train Acc: 0.9824479166666666
2024-04-29 18:02:00,882 - Batch [1300/8699], Train Loss: 0.06871202439763763, Train Acc: 0.9832091346153846
2024-04-29 18:02:06,882 - Batch [1400/8699], Train Loss: 0.06522554570139619, Train Acc: 0.9840066964285714
2024-04-29 18:02:12,477 - Batch [1500/8699], Train Loss: 0.06197704204185478, Train Acc: 0.9847916666666666
2024-04-29 18:02:17,832 - Batch [1600/8699], Train Loss: 0.05883932927770729, Train Acc: 0.985595703125
2024-04-29 18:02:24,197 - Batch [1700/8699], Train Loss: 0.056917936052024526, Train Acc: 0.9860110294117647
2024-04-29 18:02:29,666 - Batch [1800/8699], Train Loss: 0.05472554498879213, Train Acc: 0.9865017361111111
2024-04-29 18:02:34,922 - Batch [1900/8699], Train Loss: 0.052857728672740786, Train Acc: 0.9869078947368422
2024-04-29 18:02:40,088 - Batch [2000/8699], Train Loss: 0.0511983986068808, Train Acc: 0.98728125
2024-04-29 18:02:46,247 - Batch [2100/8699], Train Loss: 0.04993695048554357, Train Acc: 0.9875223214285714
2024-04-29 18:02:52,113 - Batch [2200/8699], Train Loss: 0.048704384165572594, Train Acc: 0.9877698863636364
2024-04-29 18:02:58,418 - Batch [2300/8699], Train Loss: 0.04760843362633908, Train Acc: 0.9880366847826086
2024-04-29 18:03:05,242 - Batch [2400/8699], Train Loss: 0.046655083342751216, Train Acc: 0.9883268229166666
2024-04-29 18:03:13,222 - Batch [2500/8699], Train Loss: 0.04537198484390974, Train Acc: 0.9886125
2024-04-29 18:03:19,594 - Batch [2600/8699], Train Loss: 0.04436940232681361, Train Acc: 0.9888521634615385
2024-04-29 18:03:26,077 - Batch [2700/8699], Train Loss: 0.04332699429247037, Train Acc: 0.9890914351851852
2024-04-29 18:03:32,634 - Batch [2800/8699], Train Loss: 0.04218502181345164, Train Acc: 0.9893526785714286
2024-04-29 18:03:39,130 - Batch [2900/8699], Train Loss: 0.041199742878113815, Train Acc: 0.989552801724138
2024-04-29 18:03:45,709 - Batch [3000/8699], Train Loss: 0.040344404454098065, Train Acc: 0.9897447916666666
2024-04-29 18:03:52,471 - Batch [3100/8699], Train Loss: 0.03947716831082465, Train Acc: 0.9899596774193549
2024-04-29 18:03:58,532 - Batch [3200/8699], Train Loss: 0.03868252306440581, Train Acc: 0.990166015625
2024-04-29 18:04:04,429 - Batch [3300/8699], Train Loss: 0.03791739115376196, Train Acc: 0.9903882575757575
2024-04-29 18:04:10,311 - Batch [3400/8699], Train Loss: 0.03739074593303111, Train Acc: 0.9904917279411765
2024-04-29 18:04:16,731 - Batch [3500/8699], Train Loss: 0.0369927009789244, Train Acc: 0.9906294642857143
2024-04-29 18:04:22,970 - Batch [3600/8699], Train Loss: 0.03635218989248945, Train Acc: 0.9908029513888889
2024-04-29 18:04:28,979 - Batch [3700/8699], Train Loss: 0.03581036158900895, Train Acc: 0.990933277027027
2024-04-29 18:04:34,641 - Batch [3800/8699], Train Loss: 0.03541168843882923, Train Acc: 0.9910074013157895
2024-04-29 18:04:40,452 - Batch [3900/8699], Train Loss: 0.03492661684197605, Train Acc: 0.9911378205128205
2024-04-29 18:04:46,213 - Batch [4000/8699], Train Loss: 0.034353736283743275, Train Acc: 0.99128125
2024-04-29 18:04:52,274 - Batch [4100/8699], Train Loss: 0.03381076666488697, Train Acc: 0.9913910060975609
2024-04-29 18:04:58,243 - Batch [4200/8699], Train Loss: 0.03343220375960387, Train Acc: 0.9914918154761905
2024-04-29 18:05:04,045 - Batch [4300/8699], Train Loss: 0.03299324606132909, Train Acc: 0.991609738372093
2024-04-29 18:05:10,196 - Batch [4400/8699], Train Loss: 0.03238434859689567, Train Acc: 0.9917578125
2024-04-29 18:05:16,421 - Batch [4500/8699], Train Loss: 0.031846724872149124, Train Acc: 0.9918923611111111
2024-04-29 18:05:23,027 - Batch [4600/8699], Train Loss: 0.031591229141016336, Train Acc: 0.9919463315217392
2024-04-29 18:05:29,345 - Batch [4700/8699], Train Loss: 0.031176410194511457, Train Acc: 0.9920412234042553
2024-04-29 18:05:35,344 - Batch [4800/8699], Train Loss: 0.030735305813767204, Train Acc: 0.9921549479166667
2024-04-29 18:05:41,170 - Batch [4900/8699], Train Loss: 0.03050766279922866, Train Acc: 0.9922417091836735
2024-04-29 18:05:47,358 - Batch [5000/8699], Train Loss: 0.030045335210674966, Train Acc: 0.992365625
2024-04-29 18:05:53,579 - Batch [5100/8699], Train Loss: 0.029803733059215673, Train Acc: 0.9924172794117647
2024-04-29 18:05:59,680 - Batch [5200/8699], Train Loss: 0.029531090670071324, Train Acc: 0.9924849759615385
2024-04-29 18:06:05,714 - Batch [5300/8699], Train Loss: 0.02918235369761121, Train Acc: 0.9925707547169811
2024-04-29 18:06:12,007 - Batch [5400/8699], Train Loss: 0.028965400501509538, Train Acc: 0.9926388888888888
2024-04-29 18:06:18,124 - Batch [5500/8699], Train Loss: 0.028727777003911218, Train Acc: 0.992721590909091
2024-04-29 18:06:24,786 - Batch [5600/8699], Train Loss: 0.028368027720964945, Train Acc: 0.9928125
2024-04-29 18:06:31,118 - Batch [5700/8699], Train Loss: 0.028032653086593837, Train Acc: 0.9928782894736842
2024-04-29 18:06:37,206 - Batch [5800/8699], Train Loss: 0.027698772535180164, Train Acc: 0.9929445043103449
2024-04-29 18:06:43,518 - Batch [5900/8699], Train Loss: 0.027513258048546325, Train Acc: 0.9930084745762712
2024-04-29 18:06:49,722 - Batch [6000/8699], Train Loss: 0.027345691693575647, Train Acc: 0.9930546875
2024-04-29 18:06:56,333 - Batch [6100/8699], Train Loss: 0.027164575190180302, Train Acc: 0.9931019467213115
2024-04-29 18:07:02,377 - Batch [6200/8699], Train Loss: 0.02687893617813731, Train Acc: 0.9931854838709677
2024-04-29 18:07:08,312 - Batch [6300/8699], Train Loss: 0.026646831698015464, Train Acc: 0.9932465277777778
2024-04-29 18:07:14,269 - Batch [6400/8699], Train Loss: 0.026420139348936687, Train Acc: 0.99330078125
2024-04-29 18:07:20,767 - Batch [6500/8699], Train Loss: 0.026337990115708424, Train Acc: 0.9933076923076923
2024-04-29 18:07:26,968 - Batch [6600/8699], Train Loss: 0.02617904900507545, Train Acc: 0.9933522727272728
2024-04-29 18:07:32,929 - Batch [6700/8699], Train Loss: 0.026002774246427628, Train Acc: 0.9933652052238806
2024-04-29 18:07:38,984 - Batch [6800/8699], Train Loss: 0.025747255784843433, Train Acc: 0.9934397977941176
2024-04-29 18:07:45,383 - Batch [6900/8699], Train Loss: 0.025509075791094907, Train Acc: 0.9934782608695653
2024-04-29 18:07:51,716 - Batch [7000/8699], Train Loss: 0.025359169859382486, Train Acc: 0.9935111607142857
2024-04-29 18:07:57,910 - Batch [7100/8699], Train Loss: 0.025110161979609472, Train Acc: 0.9935761443661972
2024-04-29 18:08:03,887 - Batch [7200/8699], Train Loss: 0.024904217155406815, Train Acc: 0.9936306423611111
2024-04-29 18:08:09,959 - Batch [7300/8699], Train Loss: 0.02475294318966867, Train Acc: 0.9936857876712328
2024-04-29 18:08:16,417 - Batch [7400/8699], Train Loss: 0.024579992480085893, Train Acc: 0.9937331081081081
2024-04-29 18:08:22,995 - Batch [7500/8699], Train Loss: 0.02440961523975857, Train Acc: 0.99378125
2024-04-29 18:08:29,273 - Batch [7600/8699], Train Loss: 0.024222740437562607, Train Acc: 0.9938240131578947
2024-04-29 18:08:35,515 - Batch [7700/8699], Train Loss: 0.023993313767699306, Train Acc: 0.9938818993506493
2024-04-29 18:08:41,532 - Batch [7800/8699], Train Loss: 0.023884078680888567, Train Acc: 0.993916266025641
2024-04-29 18:08:47,694 - Batch [7900/8699], Train Loss: 0.023701504213184513, Train Acc: 0.9939616297468354
2024-04-29 18:08:54,276 - Batch [8000/8699], Train Loss: 0.02359197017367751, Train Acc: 0.993986328125
2024-04-29 18:09:00,309 - Batch [8100/8699], Train Loss: 0.023440431460825674, Train Acc: 0.9940277777777777
2024-04-29 18:09:06,416 - Batch [8200/8699], Train Loss: 0.023295123177139897, Train Acc: 0.9940758384146341
2024-04-29 18:09:12,260 - Batch [8300/8699], Train Loss: 0.023116790905624806, Train Acc: 0.9941265060240964
2024-04-29 18:09:18,506 - Batch [8400/8699], Train Loss: 0.02297078938001245, Train Acc: 0.9941685267857143
2024-04-29 18:09:25,192 - Batch [8500/8699], Train Loss: 0.022834218817167257, Train Acc: 0.9942040441176471
2024-04-29 18:09:31,104 - Batch [8600/8699], Train Loss: 0.022699992290490204, Train Acc: 0.9942405523255814
2024-04-29 18:09:37,661 - Train Loss: 0.022521998305610684, Train Acc: 0.9942875619745635
2024-04-29 18:11:47,712 - Test Acc: 0.9984623233288544
2024-04-29 18:11:47,771 - Confusion Matrix:
 [[67427   129]
 [   85 71530]]
2024-04-29 18:11:47,822 - Saved the new best model to ../data/models/pklot/all/80_20/shufflenet.pth
2024-04-29 18:11:47,822 - Epoch time: 675.4551205635071 seconds.
2024-04-29 18:11:47,823 - Epoch 2/5
2024-04-29 18:12:11,352 - Batch [100/8699], Train Loss: 0.011177329392521642, Train Acc: 0.99671875
2024-04-29 18:12:16,864 - Batch [200/8699], Train Loss: 0.010559727620529884, Train Acc: 0.997109375
2024-04-29 18:12:22,660 - Batch [300/8699], Train Loss: 0.009288922652461527, Train Acc: 0.9976041666666666
2024-04-29 18:12:28,506 - Batch [400/8699], Train Loss: 0.009846570328245435, Train Acc: 0.9973828125
2024-04-29 18:12:33,969 - Batch [500/8699], Train Loss: 0.00942399927729275, Train Acc: 0.99740625
2024-04-29 18:12:39,540 - Batch [600/8699], Train Loss: 0.00957636754563282, Train Acc: 0.997421875
2024-04-29 18:12:44,878 - Batch [700/8699], Train Loss: 0.009841195829285426, Train Acc: 0.9973214285714286
2024-04-29 18:12:50,558 - Batch [800/8699], Train Loss: 0.010631785473133277, Train Acc: 0.997265625
2024-04-29 18:12:56,885 - Batch [900/8699], Train Loss: 0.010858596003745334, Train Acc: 0.9971701388888888
2024-04-29 18:13:02,427 - Batch [1000/8699], Train Loss: 0.011123786215532163, Train Acc: 0.997109375
2024-04-29 18:13:08,806 - Batch [1100/8699], Train Loss: 0.011215530935303171, Train Acc: 0.9971022727272727
2024-04-29 18:13:14,305 - Batch [1200/8699], Train Loss: 0.010873190809561492, Train Acc: 0.9972005208333333
2024-04-29 18:13:19,591 - Batch [1300/8699], Train Loss: 0.010632219267281471, Train Acc: 0.9972716346153846
2024-04-29 18:13:25,731 - Batch [1400/8699], Train Loss: 0.010941143581996065, Train Acc: 0.9971986607142858
2024-04-29 18:13:31,529 - Batch [1500/8699], Train Loss: 0.01097272366702479, Train Acc: 0.9971979166666667
2024-04-29 18:13:37,195 - Batch [1600/8699], Train Loss: 0.011189576995993775, Train Acc: 0.9971484375
2024-04-29 18:13:42,690 - Batch [1700/8699], Train Loss: 0.010672144331217758, Train Acc: 0.9972702205882353
2024-04-29 18:13:48,167 - Batch [1800/8699], Train Loss: 0.010484806314352682, Train Acc: 0.9973263888888889
2024-04-29 18:13:54,098 - Batch [1900/8699], Train Loss: 0.010476675022411272, Train Acc: 0.99734375
2024-04-29 18:13:59,717 - Batch [2000/8699], Train Loss: 0.01036098831043364, Train Acc: 0.997359375
2024-04-29 18:14:05,576 - Batch [2100/8699], Train Loss: 0.010432001581819002, Train Acc: 0.99734375
2024-04-29 18:14:11,175 - Batch [2200/8699], Train Loss: 0.010119782744496578, Train Acc: 0.9974076704545455
2024-04-29 18:14:16,802 - Batch [2300/8699], Train Loss: 0.010073193910145916, Train Acc: 0.9974320652173913
2024-04-29 18:14:22,835 - Batch [2400/8699], Train Loss: 0.01020004877800981, Train Acc: 0.9974153645833334
2024-04-29 18:14:28,539 - Batch [2500/8699], Train Loss: 0.010139489938165207, Train Acc: 0.99739375
2024-04-29 18:14:34,519 - Batch [2600/8699], Train Loss: 0.010039269122110525, Train Acc: 0.9974579326923076
2024-04-29 18:14:40,338 - Batch [2700/8699], Train Loss: 0.010191937921382406, Train Acc: 0.9974131944444444
2024-04-29 18:14:46,157 - Batch [2800/8699], Train Loss: 0.010148098194443783, Train Acc: 0.997421875
2024-04-29 18:14:51,935 - Batch [2900/8699], Train Loss: 0.010003695156689807, Train Acc: 0.9974407327586207
2024-04-29 18:14:57,913 - Batch [3000/8699], Train Loss: 0.00996727223357387, Train Acc: 0.997453125
2024-04-29 18:15:03,324 - Batch [3100/8699], Train Loss: 0.009896317291525432, Train Acc: 0.9974596774193548
2024-04-29 18:15:09,213 - Batch [3200/8699], Train Loss: 0.009843784531256575, Train Acc: 0.9975048828125
2024-04-29 18:15:14,968 - Batch [3300/8699], Train Loss: 0.009791939007694357, Train Acc: 0.9975094696969697
2024-04-29 18:15:20,767 - Batch [3400/8699], Train Loss: 0.009673443866849459, Train Acc: 0.9975551470588235
2024-04-29 18:15:26,806 - Batch [3500/8699], Train Loss: 0.009770236381549434, Train Acc: 0.9975625
2024-04-29 18:15:32,938 - Batch [3600/8699], Train Loss: 0.009714677375061709, Train Acc: 0.9975607638888889
2024-04-29 18:15:38,951 - Batch [3700/8699], Train Loss: 0.009773488371879097, Train Acc: 0.9975548986486487
2024-04-29 18:15:45,148 - Batch [3800/8699], Train Loss: 0.009752332767512167, Train Acc: 0.9975534539473684
2024-04-29 18:15:51,008 - Batch [3900/8699], Train Loss: 0.009718754668842733, Train Acc: 0.9975560897435898
2024-04-29 18:15:56,836 - Batch [4000/8699], Train Loss: 0.00982035170685367, Train Acc: 0.99753125
2024-04-29 18:16:02,325 - Batch [4100/8699], Train Loss: 0.009921596194109464, Train Acc: 0.9975
2024-04-29 18:16:07,986 - Batch [4200/8699], Train Loss: 0.009820147220828274, Train Acc: 0.9975223214285714
2024-04-29 18:16:13,758 - Batch [4300/8699], Train Loss: 0.00987810941245148, Train Acc: 0.9975254360465117
2024-04-29 18:16:19,248 - Batch [4400/8699], Train Loss: 0.009904599536632553, Train Acc: 0.9975390625
2024-04-29 18:16:25,185 - Batch [4500/8699], Train Loss: 0.00984989941737917, Train Acc: 0.9975555555555555
2024-04-29 18:16:30,539 - Batch [4600/8699], Train Loss: 0.009764063190829762, Train Acc: 0.9975611413043478
2024-04-29 18:16:36,003 - Batch [4700/8699], Train Loss: 0.00971919639560354, Train Acc: 0.9975764627659575
2024-04-29 18:16:41,469 - Batch [4800/8699], Train Loss: 0.009733068059305197, Train Acc: 0.9975911458333333
2024-04-29 18:16:46,919 - Batch [4900/8699], Train Loss: 0.00973631659991692, Train Acc: 0.9975860969387755
2024-04-29 18:16:53,299 - Batch [5000/8699], Train Loss: 0.009645949015311999, Train Acc: 0.99759375
2024-04-29 18:16:58,839 - Batch [5100/8699], Train Loss: 0.00965134178189806, Train Acc: 0.997594975490196
2024-04-29 18:17:04,300 - Batch [5200/8699], Train Loss: 0.009637292049133066, Train Acc: 0.9976051682692307
2024-04-29 18:17:10,063 - Batch [5300/8699], Train Loss: 0.009632657666823193, Train Acc: 0.9976002358490565
2024-04-29 18:17:15,697 - Batch [5400/8699], Train Loss: 0.00966902533068538, Train Acc: 0.9976012731481482
2024-04-29 18:17:21,455 - Batch [5500/8699], Train Loss: 0.00966980155809506, Train Acc: 0.9976136363636363
2024-04-29 18:17:27,556 - Batch [5600/8699], Train Loss: 0.009720243640546675, Train Acc: 0.9976032366071429
2024-04-29 18:17:33,497 - Batch [5700/8699], Train Loss: 0.009783398827347124, Train Acc: 0.9976014254385965
2024-04-29 18:17:39,174 - Batch [5800/8699], Train Loss: 0.009712234017623783, Train Acc: 0.9976158405172414
2024-04-29 18:17:45,086 - Batch [5900/8699], Train Loss: 0.009621348843133308, Train Acc: 0.9976297669491525
2024-04-29 18:17:50,837 - Batch [6000/8699], Train Loss: 0.00962684437669274, Train Acc: 0.9976197916666667
2024-04-29 18:17:56,998 - Batch [6100/8699], Train Loss: 0.009524933743939118, Train Acc: 0.997640881147541
2024-04-29 18:18:02,687 - Batch [6200/8699], Train Loss: 0.009507432533673636, Train Acc: 0.99765625
2024-04-29 18:18:08,827 - Batch [6300/8699], Train Loss: 0.009469513159998777, Train Acc: 0.9976636904761905
2024-04-29 18:18:14,754 - Batch [6400/8699], Train Loss: 0.009541580345329806, Train Acc: 0.9976611328125
2024-04-29 18:18:20,870 - Batch [6500/8699], Train Loss: 0.00951979987512599, Train Acc: 0.997670673076923
2024-04-29 18:18:27,036 - Batch [6600/8699], Train Loss: 0.009500520953338998, Train Acc: 0.9976775568181818
2024-04-29 18:18:32,673 - Batch [6700/8699], Train Loss: 0.009388759346769152, Train Acc: 0.9977005597014925
2024-04-29 18:18:38,462 - Batch [6800/8699], Train Loss: 0.00932791304338774, Train Acc: 0.9977136948529411
2024-04-29 18:18:44,126 - Batch [6900/8699], Train Loss: 0.009306349947260257, Train Acc: 0.9977151268115942
2024-04-29 18:18:49,778 - Batch [7000/8699], Train Loss: 0.009317758565041004, Train Acc: 0.9977232142857143
2024-04-29 18:18:55,926 - Batch [7100/8699], Train Loss: 0.00933175895652491, Train Acc: 0.997731073943662
2024-04-29 18:19:01,798 - Batch [7200/8699], Train Loss: 0.009306627394676576, Train Acc: 0.9977452256944445
2024-04-29 18:19:07,616 - Batch [7300/8699], Train Loss: 0.009267478570846796, Train Acc: 0.9977504280821918
2024-04-29 18:19:13,402 - Batch [7400/8699], Train Loss: 0.00920511932310399, Train Acc: 0.9977618243243244
2024-04-29 18:19:19,054 - Batch [7500/8699], Train Loss: 0.00914894182359179, Train Acc: 0.997775
2024-04-29 18:19:25,470 - Batch [7600/8699], Train Loss: 0.009097301587064162, Train Acc: 0.997789884868421
2024-04-29 18:19:31,129 - Batch [7700/8699], Train Loss: 0.009106426346850924, Train Acc: 0.9977780032467533
2024-04-29 18:19:36,853 - Batch [7800/8699], Train Loss: 0.009152397625213127, Train Acc: 0.9977804487179487
2024-04-29 18:19:42,481 - Batch [7900/8699], Train Loss: 0.00910478392571706, Train Acc: 0.9977927215189873
2024-04-29 18:19:47,992 - Batch [8000/8699], Train Loss: 0.009089605997526179, Train Acc: 0.997794921875
2024-04-29 18:19:54,211 - Batch [8100/8699], Train Loss: 0.009097961183883237, Train Acc: 0.997800925925926
2024-04-29 18:19:59,860 - Batch [8200/8699], Train Loss: 0.009112903541621696, Train Acc: 0.9978010670731707
2024-04-29 18:20:05,868 - Batch [8300/8699], Train Loss: 0.009147838006241487, Train Acc: 0.9978068524096385
2024-04-29 18:20:11,332 - Batch [8400/8699], Train Loss: 0.009126822844231615, Train Acc: 0.9978106398809524
2024-04-29 18:20:16,908 - Batch [8500/8699], Train Loss: 0.009104716171585417, Train Acc: 0.9978088235294118
2024-04-29 18:20:23,111 - Batch [8600/8699], Train Loss: 0.009109982306379733, Train Acc: 0.9978088662790697
2024-04-29 18:20:29,656 - Train Loss: 0.009110433955544905, Train Acc: 0.9978174175468851
2024-04-29 18:23:00,453 - Test Acc: 0.998821593579122
2024-04-29 18:23:00,518 - Confusion Matrix:
 [[67476    80]
 [   84 71531]]
2024-04-29 18:23:00,564 - Saved the new best model to ../data/models/pklot/all/80_20/shufflenet.pth
2024-04-29 18:23:00,564 - Epoch time: 672.7419011592865 seconds.
2024-04-29 18:23:00,564 - Epoch 3/5
2024-04-29 18:23:27,014 - Batch [100/8699], Train Loss: 0.009270286697428673, Train Acc: 0.99796875
2024-04-29 18:23:32,760 - Batch [200/8699], Train Loss: 0.009296595522755524, Train Acc: 0.998125
2024-04-29 18:23:38,885 - Batch [300/8699], Train Loss: 0.010526980117235022, Train Acc: 0.9980729166666666
2024-04-29 18:23:46,241 - Batch [400/8699], Train Loss: 0.009809403535182355, Train Acc: 0.9982421875
2024-04-29 18:23:53,011 - Batch [500/8699], Train Loss: 0.00958473409198632, Train Acc: 0.99815625
2024-04-29 18:24:01,349 - Batch [600/8699], Train Loss: 0.010520685361395105, Train Acc: 0.9979427083333333
2024-04-29 18:24:07,185 - Batch [700/8699], Train Loss: 0.010023217900857811, Train Acc: 0.9979464285714286
2024-04-29 18:24:14,682 - Batch [800/8699], Train Loss: 0.009914427519079254, Train Acc: 0.9979296875
2024-04-29 18:24:21,686 - Batch [900/8699], Train Loss: 0.009570239942719733, Train Acc: 0.9980034722222222
2024-04-29 18:24:28,433 - Batch [1000/8699], Train Loss: 0.009197350307098532, Train Acc: 0.99809375
2024-04-29 18:24:33,874 - Batch [1100/8699], Train Loss: 0.00913926539685318, Train Acc: 0.9980539772727273
2024-04-29 18:24:39,333 - Batch [1200/8699], Train Loss: 0.008940056335225866, Train Acc: 0.9980598958333333
2024-04-29 18:24:44,774 - Batch [1300/8699], Train Loss: 0.008743315402820232, Train Acc: 0.9981009615384615
2024-04-29 18:24:50,040 - Batch [1400/8699], Train Loss: 0.008323789989574705, Train Acc: 0.9981473214285714
2024-04-29 18:24:55,993 - Batch [1500/8699], Train Loss: 0.008206766021401564, Train Acc: 0.9981875
2024-04-29 18:25:01,204 - Batch [1600/8699], Train Loss: 0.00806124272783336, Train Acc: 0.99822265625
2024-04-29 18:25:06,302 - Batch [1700/8699], Train Loss: 0.008063444343967122, Train Acc: 0.9982261029411764
2024-04-29 18:25:11,821 - Batch [1800/8699], Train Loss: 0.007882319057134737, Train Acc: 0.9982552083333334
2024-04-29 18:25:16,905 - Batch [1900/8699], Train Loss: 0.007876208611732612, Train Acc: 0.9982648026315789
2024-04-29 18:25:22,145 - Batch [2000/8699], Train Loss: 0.008037929065649223, Train Acc: 0.998265625
2024-04-29 18:25:27,425 - Batch [2100/8699], Train Loss: 0.007974600238861361, Train Acc: 0.9982886904761905
2024-04-29 18:25:32,559 - Batch [2200/8699], Train Loss: 0.007791280514496644, Train Acc: 0.9983451704545454
2024-04-29 18:25:37,669 - Batch [2300/8699], Train Loss: 0.007753936737815662, Train Acc: 0.9983763586956522
2024-04-29 18:25:42,870 - Batch [2400/8699], Train Loss: 0.007960150517183138, Train Acc: 0.9983528645833334
2024-04-29 18:25:47,963 - Batch [2500/8699], Train Loss: 0.007948163687664782, Train Acc: 0.9983375
2024-04-29 18:25:53,741 - Batch [2600/8699], Train Loss: 0.008009208955095696, Train Acc: 0.998329326923077
2024-04-29 18:25:59,064 - Batch [2700/8699], Train Loss: 0.008026326547567603, Train Acc: 0.9983391203703704
2024-04-29 18:26:04,193 - Batch [2800/8699], Train Loss: 0.008081380538969824, Train Acc: 0.9983258928571429
2024-04-29 18:26:09,322 - Batch [2900/8699], Train Loss: 0.008129635243676603, Train Acc: 0.9983297413793103
2024-04-29 18:26:14,515 - Batch [3000/8699], Train Loss: 0.008119795157937915, Train Acc: 0.9983333333333333
2024-04-29 18:26:19,981 - Batch [3100/8699], Train Loss: 0.00814182757409834, Train Acc: 0.9983467741935483
2024-04-29 18:26:25,841 - Batch [3200/8699], Train Loss: 0.008082909510098943, Train Acc: 0.9983349609375
2024-04-29 18:26:31,008 - Batch [3300/8699], Train Loss: 0.008087180269393491, Train Acc: 0.9983143939393939
2024-04-29 18:26:36,543 - Batch [3400/8699], Train Loss: 0.008164501810665302, Train Acc: 0.9983042279411765
2024-04-29 18:26:41,748 - Batch [3500/8699], Train Loss: 0.00810401573375462, Train Acc: 0.9983214285714286
2024-04-29 18:26:47,537 - Batch [3600/8699], Train Loss: 0.00804715384126818, Train Acc: 0.9983376736111111
2024-04-29 18:26:53,169 - Batch [3700/8699], Train Loss: 0.008041112554082418, Train Acc: 0.9983319256756756
2024-04-29 18:26:58,534 - Batch [3800/8699], Train Loss: 0.007886147824806119, Train Acc: 0.9983552631578947
2024-04-29 18:27:03,655 - Batch [3900/8699], Train Loss: 0.007877974140591016, Train Acc: 0.9983413461538462
2024-04-29 18:27:08,798 - Batch [4000/8699], Train Loss: 0.007936627961056729, Train Acc: 0.998328125
2024-04-29 18:27:13,954 - Batch [4100/8699], Train Loss: 0.007868454066481761, Train Acc: 0.9983307926829268
2024-04-29 18:27:19,328 - Batch [4200/8699], Train Loss: 0.007974696701823545, Train Acc: 0.9983258928571429
2024-04-29 18:27:24,645 - Batch [4300/8699], Train Loss: 0.00794257610896873, Train Acc: 0.9983357558139535
2024-04-29 18:27:29,819 - Batch [4400/8699], Train Loss: 0.007841359705023272, Train Acc: 0.9983664772727273
2024-04-29 18:27:34,934 - Batch [4500/8699], Train Loss: 0.007758471793614768, Train Acc: 0.998375
2024-04-29 18:27:40,379 - Batch [4600/8699], Train Loss: 0.00773944359784408, Train Acc: 0.998383152173913
2024-04-29 18:27:45,625 - Batch [4700/8699], Train Loss: 0.007759285920438607, Train Acc: 0.9983776595744681
2024-04-29 18:27:51,018 - Batch [4800/8699], Train Loss: 0.007742354586866895, Train Acc: 0.99837890625
2024-04-29 18:27:56,589 - Batch [4900/8699], Train Loss: 0.0077133152914831615, Train Acc: 0.9983673469387755
2024-04-29 18:28:01,886 - Batch [5000/8699], Train Loss: 0.00772070312047872, Train Acc: 0.99838125
2024-04-29 18:28:07,112 - Batch [5100/8699], Train Loss: 0.007713266202127652, Train Acc: 0.9983731617647059
2024-04-29 18:28:12,396 - Batch [5200/8699], Train Loss: 0.007675227284040515, Train Acc: 0.9983743990384616
2024-04-29 18:28:17,772 - Batch [5300/8699], Train Loss: 0.007732805203401236, Train Acc: 0.9983549528301887
2024-04-29 18:28:23,394 - Batch [5400/8699], Train Loss: 0.007750807796949596, Train Acc: 0.998359375
2024-04-29 18:28:28,881 - Batch [5500/8699], Train Loss: 0.007689346507902056, Train Acc: 0.9983693181818182
2024-04-29 18:28:33,985 - Batch [5600/8699], Train Loss: 0.007634308281228966, Train Acc: 0.9983872767857143
2024-04-29 18:28:39,369 - Batch [5700/8699], Train Loss: 0.007668863284070859, Train Acc: 0.9983826754385965
2024-04-29 18:28:44,616 - Batch [5800/8699], Train Loss: 0.0076317068564627525, Train Acc: 0.9983970905172413
2024-04-29 18:28:50,185 - Batch [5900/8699], Train Loss: 0.007588465941184564, Train Acc: 0.9983951271186441
2024-04-29 18:28:56,068 - Batch [6000/8699], Train Loss: 0.007608456910720634, Train Acc: 0.998390625
2024-04-29 18:29:01,192 - Batch [6100/8699], Train Loss: 0.007642303610628601, Train Acc: 0.998391393442623
2024-04-29 18:29:06,498 - Batch [6200/8699], Train Loss: 0.00762416615746852, Train Acc: 0.9984022177419355
2024-04-29 18:29:11,669 - Batch [6300/8699], Train Loss: 0.007616563862042861, Train Acc: 0.9984126984126984
2024-04-29 18:29:16,791 - Batch [6400/8699], Train Loss: 0.007559670771193509, Train Acc: 0.99843017578125
2024-04-29 18:29:22,709 - Batch [6500/8699], Train Loss: 0.007509411962347468, Train Acc: 0.9984399038461539
2024-04-29 18:29:28,100 - Batch [6600/8699], Train Loss: 0.007483356035494525, Train Acc: 0.9984351325757576
2024-04-29 18:29:33,280 - Batch [6700/8699], Train Loss: 0.0074666220551134485, Train Acc: 0.9984444962686567
2024-04-29 18:29:38,547 - Batch [6800/8699], Train Loss: 0.007459686903631497, Train Acc: 0.9984443933823529
2024-04-29 18:29:43,690 - Batch [6900/8699], Train Loss: 0.007442393676073402, Train Acc: 0.9984488224637681
2024-04-29 18:29:48,887 - Batch [7000/8699], Train Loss: 0.0074511206781280636, Train Acc: 0.9984375
2024-04-29 18:29:54,913 - Batch [7100/8699], Train Loss: 0.007417785987322724, Train Acc: 0.9984375
2024-04-29 18:30:00,028 - Batch [7200/8699], Train Loss: 0.007400466638359325, Train Acc: 0.9984461805555556
2024-04-29 18:30:05,164 - Batch [7300/8699], Train Loss: 0.007335571255550835, Train Acc: 0.998458904109589
2024-04-29 18:30:10,351 - Batch [7400/8699], Train Loss: 0.007280930385858409, Train Acc: 0.9984628378378378
2024-04-29 18:30:15,559 - Batch [7500/8699], Train Loss: 0.007254918312194059, Train Acc: 0.9984625
2024-04-29 18:30:21,178 - Batch [7600/8699], Train Loss: 0.007270337045044328, Train Acc: 0.9984580592105263
2024-04-29 18:30:26,429 - Batch [7700/8699], Train Loss: 0.007275216549199037, Train Acc: 0.998465909090909
2024-04-29 18:30:31,609 - Batch [7800/8699], Train Loss: 0.007217596434082411, Train Acc: 0.9984755608974359
2024-04-29 18:30:36,819 - Batch [7900/8699], Train Loss: 0.007246340016138709, Train Acc: 0.998467167721519
2024-04-29 18:30:42,146 - Batch [8000/8699], Train Loss: 0.0072207207817382366, Train Acc: 0.998474609375
2024-04-29 18:30:47,386 - Batch [8100/8699], Train Loss: 0.007241492232908373, Train Acc: 0.998474151234568
2024-04-29 18:30:52,949 - Batch [8200/8699], Train Loss: 0.007275443208517816, Train Acc: 0.9984717987804878
2024-04-29 18:30:58,396 - Batch [8300/8699], Train Loss: 0.007287240235532244, Train Acc: 0.9984695030120482
2024-04-29 18:31:03,658 - Batch [8400/8699], Train Loss: 0.007222056218222947, Train Acc: 0.9984784226190476
2024-04-29 18:31:08,821 - Batch [8500/8699], Train Loss: 0.007205646440962857, Train Acc: 0.9984797794117647
2024-04-29 18:31:14,001 - Batch [8600/8699], Train Loss: 0.0072085330300759, Train Acc: 0.9984756540697675
2024-04-29 18:31:20,247 - Train Loss: 0.00717008987636555, Train Acc: 0.9984820722856937
2024-04-29 18:33:20,679 - Test Acc: 0.9989653016792291
2024-04-29 18:33:20,738 - Confusion Matrix:
 [[67471    85]
 [   59 71556]]
2024-04-29 18:33:20,781 - Saved the new best model to ../data/models/pklot/all/80_20/shufflenet.pth
2024-04-29 18:33:20,781 - Epoch time: 620.2164967060089 seconds.
2024-04-29 18:33:20,781 - Epoch 4/5
2024-04-29 18:33:42,942 - Batch [100/8699], Train Loss: 0.009403667669466813, Train Acc: 0.9975
2024-04-29 18:33:47,876 - Batch [200/8699], Train Loss: 0.00715273674684795, Train Acc: 0.998203125
2024-04-29 18:33:52,901 - Batch [300/8699], Train Loss: 0.006951881988388777, Train Acc: 0.9984375
2024-04-29 18:33:57,784 - Batch [400/8699], Train Loss: 0.006538040221839765, Train Acc: 0.9984765625
2024-04-29 18:34:02,663 - Batch [500/8699], Train Loss: 0.0063468494057888165, Train Acc: 0.99853125
2024-04-29 18:34:07,546 - Batch [600/8699], Train Loss: 0.005593409055557761, Train Acc: 0.9986979166666666
2024-04-29 18:34:12,402 - Batch [700/8699], Train Loss: 0.006397265266778049, Train Acc: 0.9986160714285715
2024-04-29 18:34:17,294 - Batch [800/8699], Train Loss: 0.006829815548518354, Train Acc: 0.99853515625
2024-04-29 18:34:22,833 - Batch [900/8699], Train Loss: 0.006780752099213917, Train Acc: 0.9985416666666667
2024-04-29 18:34:28,088 - Batch [1000/8699], Train Loss: 0.006854646871704063, Train Acc: 0.998515625
2024-04-29 18:34:33,091 - Batch [1100/8699], Train Loss: 0.006595456202869834, Train Acc: 0.9985653409090909
2024-04-29 18:34:37,966 - Batch [1200/8699], Train Loss: 0.006429239172867559, Train Acc: 0.9986067708333334
2024-04-29 18:34:42,880 - Batch [1300/8699], Train Loss: 0.0063966430573789415, Train Acc: 0.9986298076923077
2024-04-29 18:34:47,748 - Batch [1400/8699], Train Loss: 0.006331086569917456, Train Acc: 0.9986272321428571
2024-04-29 18:34:52,767 - Batch [1500/8699], Train Loss: 0.006051084774093397, Train Acc: 0.9986875
2024-04-29 18:34:57,700 - Batch [1600/8699], Train Loss: 0.005867654184261824, Train Acc: 0.998740234375
2024-04-29 18:35:02,599 - Batch [1700/8699], Train Loss: 0.0059884098249350405, Train Acc: 0.99875
2024-04-29 18:35:07,627 - Batch [1800/8699], Train Loss: 0.005958842137713165, Train Acc: 0.9987673611111111
2024-04-29 18:35:12,557 - Batch [1900/8699], Train Loss: 0.00607157276204194, Train Acc: 0.9987582236842105
2024-04-29 18:35:17,505 - Batch [2000/8699], Train Loss: 0.005939592817721405, Train Acc: 0.99878125
2024-04-29 18:35:22,802 - Batch [2100/8699], Train Loss: 0.00586388151854191, Train Acc: 0.9987946428571428
2024-04-29 18:35:27,747 - Batch [2200/8699], Train Loss: 0.005933218807164684, Train Acc: 0.9987926136363636
2024-04-29 18:35:32,934 - Batch [2300/8699], Train Loss: 0.005723497188315456, Train Acc: 0.9988247282608695
2024-04-29 18:35:37,885 - Batch [2400/8699], Train Loss: 0.005624980859064408, Train Acc: 0.9988216145833333
2024-04-29 18:35:42,916 - Batch [2500/8699], Train Loss: 0.005850749502923645, Train Acc: 0.9988
2024-04-29 18:35:48,113 - Batch [2600/8699], Train Loss: 0.005808396135573905, Train Acc: 0.9987920673076923
2024-04-29 18:35:53,058 - Batch [2700/8699], Train Loss: 0.0058590163413144315, Train Acc: 0.9987962962962963
2024-04-29 18:35:58,342 - Batch [2800/8699], Train Loss: 0.005870146539733534, Train Acc: 0.9988002232142857
2024-04-29 18:36:03,412 - Batch [2900/8699], Train Loss: 0.005838075476961829, Train Acc: 0.9988038793103449
2024-04-29 18:36:08,399 - Batch [3000/8699], Train Loss: 0.006050555114826239, Train Acc: 0.9987760416666667
2024-04-29 18:36:13,720 - Batch [3100/8699], Train Loss: 0.006020953495575844, Train Acc: 0.9987903225806452
2024-04-29 18:36:18,952 - Batch [3200/8699], Train Loss: 0.0058912776311254335, Train Acc: 0.9988134765625
2024-04-29 18:36:24,922 - Batch [3300/8699], Train Loss: 0.005909137453647803, Train Acc: 0.9988068181818182
2024-04-29 18:36:30,056 - Batch [3400/8699], Train Loss: 0.005820872751901601, Train Acc: 0.9988143382352941
2024-04-29 18:36:35,214 - Batch [3500/8699], Train Loss: 0.005933256115564031, Train Acc: 0.9988080357142857
2024-04-29 18:36:40,262 - Batch [3600/8699], Train Loss: 0.00591350808895211, Train Acc: 0.9988020833333333
2024-04-29 18:36:45,472 - Batch [3700/8699], Train Loss: 0.00603294185576635, Train Acc: 0.9987753378378378
2024-04-29 18:36:50,488 - Batch [3800/8699], Train Loss: 0.005965356731311371, Train Acc: 0.9987828947368421
2024-04-29 18:36:55,766 - Batch [3900/8699], Train Loss: 0.005971649831509262, Train Acc: 0.9987780448717949
2024-04-29 18:37:00,796 - Batch [4000/8699], Train Loss: 0.00605150811565386, Train Acc: 0.99876171875
2024-04-29 18:37:05,901 - Batch [4100/8699], Train Loss: 0.006065914004329011, Train Acc: 0.9987614329268293
2024-04-29 18:37:11,050 - Batch [4200/8699], Train Loss: 0.006108737804622597, Train Acc: 0.9987537202380953
2024-04-29 18:37:16,217 - Batch [4300/8699], Train Loss: 0.0060887924523459055, Train Acc: 0.9987609011627907
2024-04-29 18:37:22,142 - Batch [4400/8699], Train Loss: 0.006097563258047516, Train Acc: 0.9987606534090909
2024-04-29 18:37:27,565 - Batch [4500/8699], Train Loss: 0.0060552742678759795, Train Acc: 0.9987743055555556
2024-04-29 18:37:32,649 - Batch [4600/8699], Train Loss: 0.006044227014296429, Train Acc: 0.998773777173913
2024-04-29 18:37:37,817 - Batch [4700/8699], Train Loss: 0.006085070282800169, Train Acc: 0.9987732712765958
2024-04-29 18:37:42,951 - Batch [4800/8699], Train Loss: 0.006151757315453968, Train Acc: 0.99876953125
2024-04-29 18:37:48,086 - Batch [4900/8699], Train Loss: 0.006137254957594098, Train Acc: 0.9987723214285714
2024-04-29 18:37:53,652 - Batch [5000/8699], Train Loss: 0.006125616971887394, Train Acc: 0.998784375
2024-04-29 18:37:58,799 - Batch [5100/8699], Train Loss: 0.006090091289364079, Train Acc: 0.9987928921568627
2024-04-29 18:38:03,986 - Batch [5200/8699], Train Loss: 0.00615633018395661, Train Acc: 0.9987740384615384
2024-04-29 18:38:09,179 - Batch [5300/8699], Train Loss: 0.006062980510382744, Train Acc: 0.9987912735849057
2024-04-29 18:38:14,329 - Batch [5400/8699], Train Loss: 0.0060037176551252375, Train Acc: 0.9987962962962963
2024-04-29 18:38:19,738 - Batch [5500/8699], Train Loss: 0.005980090604999284, Train Acc: 0.9987982954545455
2024-04-29 18:38:24,929 - Batch [5600/8699], Train Loss: 0.006012178406278151, Train Acc: 0.9988002232142857
2024-04-29 18:38:30,033 - Batch [5700/8699], Train Loss: 0.005995737593117602, Train Acc: 0.9988075657894737
2024-04-29 18:38:35,260 - Batch [5800/8699], Train Loss: 0.006006913372199709, Train Acc: 0.9988038793103449
2024-04-29 18:38:40,440 - Batch [5900/8699], Train Loss: 0.006079892546944455, Train Acc: 0.998802966101695
2024-04-29 18:38:45,752 - Batch [6000/8699], Train Loss: 0.006160584764210853, Train Acc: 0.9987916666666666
2024-04-29 18:38:51,266 - Batch [6100/8699], Train Loss: 0.00609450190320562, Train Acc: 0.9988063524590164
2024-04-29 18:38:56,776 - Batch [6200/8699], Train Loss: 0.006137554574155465, Train Acc: 0.9988054435483871
2024-04-29 18:39:01,910 - Batch [6300/8699], Train Loss: 0.006174160945535429, Train Acc: 0.9988020833333333
2024-04-29 18:39:07,090 - Batch [6400/8699], Train Loss: 0.00612826770156758, Train Acc: 0.99880859375
2024-04-29 18:39:12,224 - Batch [6500/8699], Train Loss: 0.006101028077232863, Train Acc: 0.9988149038461539
2024-04-29 18:39:17,358 - Batch [6600/8699], Train Loss: 0.006101838625360428, Train Acc: 0.998811553030303
2024-04-29 18:39:23,433 - Batch [6700/8699], Train Loss: 0.006121941427599363, Train Acc: 0.9988106343283583
2024-04-29 18:39:28,746 - Batch [6800/8699], Train Loss: 0.006198597786536699, Train Acc: 0.9987936580882353
2024-04-29 18:39:33,847 - Batch [6900/8699], Train Loss: 0.006210208386825099, Train Acc: 0.9987952898550725
2024-04-29 18:39:39,016 - Batch [7000/8699], Train Loss: 0.006271111923375039, Train Acc: 0.9987879464285714
2024-04-29 18:39:44,330 - Batch [7100/8699], Train Loss: 0.006300580121190981, Train Acc: 0.9987786091549296
2024-04-29 18:39:49,569 - Batch [7200/8699], Train Loss: 0.006323453942262884, Train Acc: 0.9987760416666667
2024-04-29 18:39:55,447 - Batch [7300/8699], Train Loss: 0.006293579117298527, Train Acc: 0.9987863869863014
2024-04-29 18:40:00,704 - Batch [7400/8699], Train Loss: 0.006270211376958336, Train Acc: 0.9987901182432433
2024-04-29 18:40:05,919 - Batch [7500/8699], Train Loss: 0.006243430447028974, Train Acc: 0.9987958333333333
2024-04-29 18:40:11,095 - Batch [7600/8699], Train Loss: 0.00626663959730422, Train Acc: 0.9987890625
2024-04-29 18:40:16,251 - Batch [7700/8699], Train Loss: 0.006261425474427691, Train Acc: 0.998786525974026
2024-04-29 18:40:22,394 - Batch [7800/8699], Train Loss: 0.006258747649924608, Train Acc: 0.9987820512820513
2024-04-29 18:40:28,007 - Batch [7900/8699], Train Loss: 0.006262630245962411, Train Acc: 0.9987796677215189
2024-04-29 18:40:33,267 - Batch [8000/8699], Train Loss: 0.006294002847406432, Train Acc: 0.998771484375
2024-04-29 18:40:38,405 - Batch [8100/8699], Train Loss: 0.006271107244186584, Train Acc: 0.9987731481481481
2024-04-29 18:40:43,548 - Batch [8200/8699], Train Loss: 0.0062715850817595285, Train Acc: 0.9987747713414634
2024-04-29 18:40:48,809 - Batch [8300/8699], Train Loss: 0.006248505546330428, Train Acc: 0.9987744728915663
2024-04-29 18:40:54,770 - Batch [8400/8699], Train Loss: 0.006252805472868745, Train Acc: 0.9987760416666667
2024-04-29 18:41:00,177 - Batch [8500/8699], Train Loss: 0.006221532775063144, Train Acc: 0.99878125
2024-04-29 18:41:05,378 - Batch [8600/8699], Train Loss: 0.006274798239346109, Train Acc: 0.9987699854651163
2024-04-29 18:41:11,399 - Train Loss: 0.006269683224797229, Train Acc: 0.9987694905511245
2024-04-29 18:43:07,341 - Test Acc: 0.9991018243743308
2024-04-29 18:43:07,401 - Confusion Matrix:
 [[67481    75]
 [   50 71565]]
2024-04-29 18:43:07,447 - Saved the new best model to ../data/models/pklot/all/80_20/shufflenet.pth
2024-04-29 18:43:07,447 - Epoch time: 586.666134595871 seconds.
2024-04-29 18:43:07,447 - Epoch 5/5
2024-04-29 18:43:31,253 - Batch [100/8699], Train Loss: 0.006497321976639796, Train Acc: 0.99890625
2024-04-29 18:43:36,136 - Batch [200/8699], Train Loss: 0.00663204525342735, Train Acc: 0.998828125
2024-04-29 18:43:41,107 - Batch [300/8699], Train Loss: 0.0051199965391424485, Train Acc: 0.9990625
2024-04-29 18:43:46,169 - Batch [400/8699], Train Loss: 0.005480223978574941, Train Acc: 0.9989453125
2024-04-29 18:43:51,274 - Batch [500/8699], Train Loss: 0.005985366872148006, Train Acc: 0.99871875
2024-04-29 18:43:57,025 - Batch [600/8699], Train Loss: 0.005949092200086549, Train Acc: 0.9986979166666666
2024-04-29 18:44:02,093 - Batch [700/8699], Train Loss: 0.005803025656953521, Train Acc: 0.99875
2024-04-29 18:44:07,302 - Batch [800/8699], Train Loss: 0.005901830723450985, Train Acc: 0.99880859375
2024-04-29 18:44:12,266 - Batch [900/8699], Train Loss: 0.005906046729845306, Train Acc: 0.9988715277777778
2024-04-29 18:44:17,170 - Batch [1000/8699], Train Loss: 0.00565179499626538, Train Acc: 0.99890625
2024-04-29 18:44:22,860 - Batch [1100/8699], Train Loss: 0.005959233269201253, Train Acc: 0.9988210227272727
2024-04-29 18:44:28,295 - Batch [1200/8699], Train Loss: 0.0057354140173871805, Train Acc: 0.9988671875
2024-04-29 18:44:33,247 - Batch [1300/8699], Train Loss: 0.005726287121535559, Train Acc: 0.998858173076923
2024-04-29 18:44:38,230 - Batch [1400/8699], Train Loss: 0.005460388172736462, Train Acc: 0.99890625
2024-04-29 18:44:43,130 - Batch [1500/8699], Train Loss: 0.005503761677491032, Train Acc: 0.9988854166666666
2024-04-29 18:44:48,068 - Batch [1600/8699], Train Loss: 0.005480008519436978, Train Acc: 0.998876953125
2024-04-29 18:44:53,003 - Batch [1700/8699], Train Loss: 0.0054337377932375495, Train Acc: 0.9988786764705883
2024-04-29 18:44:58,092 - Batch [1800/8699], Train Loss: 0.00535475038658357, Train Acc: 0.9988888888888889
2024-04-29 18:45:03,052 - Batch [1900/8699], Train Loss: 0.005305606304198017, Train Acc: 0.9988733552631579
2024-04-29 18:45:07,967 - Batch [2000/8699], Train Loss: 0.005187925993004683, Train Acc: 0.99890625
2024-04-29 18:45:12,945 - Batch [2100/8699], Train Loss: 0.004994305705140071, Train Acc: 0.9989434523809524
2024-04-29 18:45:18,039 - Batch [2200/8699], Train Loss: 0.004808605673249738, Train Acc: 0.9989772727272728
2024-04-29 18:45:23,852 - Batch [2300/8699], Train Loss: 0.00489075948499387, Train Acc: 0.9989605978260869
2024-04-29 18:45:29,042 - Batch [2400/8699], Train Loss: 0.005082584542050957, Train Acc: 0.9988997395833333
2024-04-29 18:45:34,079 - Batch [2500/8699], Train Loss: 0.0051586942716090566, Train Acc: 0.9988875
2024-04-29 18:45:40,062 - Batch [2600/8699], Train Loss: 0.00531450603160605, Train Acc: 0.9988641826923077
2024-04-29 18:45:45,255 - Batch [2700/8699], Train Loss: 0.005246851171182748, Train Acc: 0.9988831018518518
2024-04-29 18:45:50,506 - Batch [2800/8699], Train Loss: 0.005230126662356724, Train Acc: 0.9988783482142857
2024-04-29 18:45:56,369 - Batch [2900/8699], Train Loss: 0.005280095307672472, Train Acc: 0.9988577586206897
2024-04-29 18:46:01,482 - Batch [3000/8699], Train Loss: 0.0052922041621274426, Train Acc: 0.9988645833333333
2024-04-29 18:46:06,663 - Batch [3100/8699], Train Loss: 0.005190805503135937, Train Acc: 0.9988860887096774
2024-04-29 18:46:11,743 - Batch [3200/8699], Train Loss: 0.005287384615713506, Train Acc: 0.9988720703125
2024-04-29 18:46:16,869 - Batch [3300/8699], Train Loss: 0.005347077492788506, Train Acc: 0.9988541666666667
2024-04-29 18:46:22,857 - Batch [3400/8699], Train Loss: 0.0053561253986885386, Train Acc: 0.9988602941176471
2024-04-29 18:46:28,215 - Batch [3500/8699], Train Loss: 0.005548479687775658, Train Acc: 0.9988303571428572
2024-04-29 18:46:33,366 - Batch [3600/8699], Train Loss: 0.005516602358899389, Train Acc: 0.998828125
2024-04-29 18:46:38,548 - Batch [3700/8699], Train Loss: 0.005490599442739187, Train Acc: 0.9988429054054054
2024-04-29 18:46:43,662 - Batch [3800/8699], Train Loss: 0.005488585584058025, Train Acc: 0.9988486842105263
2024-04-29 18:46:48,847 - Batch [3900/8699], Train Loss: 0.005454327738567512, Train Acc: 0.9988461538461538
2024-04-29 18:46:54,739 - Batch [4000/8699], Train Loss: 0.005505831075897504, Train Acc: 0.99884765625
2024-04-29 18:46:59,970 - Batch [4100/8699], Train Loss: 0.005416512248740862, Train Acc: 0.9988567073170732
2024-04-29 18:47:05,148 - Batch [4200/8699], Train Loss: 0.00550881673101057, Train Acc: 0.9988467261904762
2024-04-29 18:47:11,159 - Batch [4300/8699], Train Loss: 0.005572005588789347, Train Acc: 0.9988335755813953
2024-04-29 18:47:16,408 - Batch [4400/8699], Train Loss: 0.005546180837290897, Train Acc: 0.9988352272727272
2024-04-29 18:47:23,030 - Batch [4500/8699], Train Loss: 0.0055511201195208235, Train Acc: 0.9988298611111112
2024-04-29 18:47:29,257 - Batch [4600/8699], Train Loss: 0.00546753252585661, Train Acc: 0.9988417119565217
2024-04-29 18:47:35,037 - Batch [4700/8699], Train Loss: 0.005509174701200925, Train Acc: 0.9988397606382978
2024-04-29 18:47:41,281 - Batch [4800/8699], Train Loss: 0.005459547596588171, Train Acc: 0.9988444010416667
2024-04-29 18:47:47,238 - Batch [4900/8699], Train Loss: 0.005518676572438213, Train Acc: 0.9988392857142857
2024-04-29 18:47:53,791 - Batch [5000/8699], Train Loss: 0.005524728398422485, Train Acc: 0.998846875
2024-04-29 18:47:59,555 - Batch [5100/8699], Train Loss: 0.0055209756509438926, Train Acc: 0.9988449754901961
2024-04-29 18:48:05,509 - Batch [5200/8699], Train Loss: 0.005465750221874434, Train Acc: 0.9988551682692308
2024-04-29 18:48:11,276 - Batch [5300/8699], Train Loss: 0.005479814078960875, Train Acc: 0.9988531839622642
2024-04-29 18:48:17,032 - Batch [5400/8699], Train Loss: 0.0055353983049680104, Train Acc: 0.9988454861111111
2024-04-29 18:48:23,354 - Batch [5500/8699], Train Loss: 0.005577969109879797, Train Acc: 0.9988380681818182
2024-04-29 18:48:29,608 - Batch [5600/8699], Train Loss: 0.005589468436324003, Train Acc: 0.9988392857142857
2024-04-29 18:48:35,338 - Batch [5700/8699], Train Loss: 0.005580792115728113, Train Acc: 0.9988404605263158
2024-04-29 18:48:41,038 - Batch [5800/8699], Train Loss: 0.005605276974556389, Train Acc: 0.9988469827586207
2024-04-29 18:48:46,639 - Batch [5900/8699], Train Loss: 0.005590333292717579, Train Acc: 0.9988532838983051
2024-04-29 18:48:52,535 - Batch [6000/8699], Train Loss: 0.005542966428936325, Train Acc: 0.9988645833333333
2024-04-29 18:48:58,499 - Batch [6100/8699], Train Loss: 0.00548720683940686, Train Acc: 0.9988780737704918
2024-04-29 18:49:04,224 - Batch [6200/8699], Train Loss: 0.005467279350856746, Train Acc: 0.9988886088709678
2024-04-29 18:49:09,757 - Batch [6300/8699], Train Loss: 0.005460297468849921, Train Acc: 0.9988963293650793
2024-04-29 18:49:15,596 - Batch [6400/8699], Train Loss: 0.005475460865464612, Train Acc: 0.99889404296875
2024-04-29 18:49:21,484 - Batch [6500/8699], Train Loss: 0.005475914016473045, Train Acc: 0.9988942307692308
2024-04-29 18:49:27,435 - Batch [6600/8699], Train Loss: 0.005443682022281874, Train Acc: 0.9988991477272727
2024-04-29 18:49:33,137 - Batch [6700/8699], Train Loss: 0.005450564679268378, Train Acc: 0.998896921641791
2024-04-29 18:49:38,694 - Batch [6800/8699], Train Loss: 0.00555359897772726, Train Acc: 0.9988809742647059
2024-04-29 18:49:44,266 - Batch [6900/8699], Train Loss: 0.0055362763536134256, Train Acc: 0.9988858695652174
2024-04-29 18:49:49,895 - Batch [7000/8699], Train Loss: 0.005516256307233691, Train Acc: 0.9988861607142857
2024-04-29 18:49:55,906 - Batch [7100/8699], Train Loss: 0.005509901685476071, Train Acc: 0.9988864436619719
2024-04-29 18:50:01,339 - Batch [7200/8699], Train Loss: 0.005532817394791007, Train Acc: 0.9988823784722223
2024-04-29 18:50:06,885 - Batch [7300/8699], Train Loss: 0.005523913596840704, Train Acc: 0.998882705479452
2024-04-29 18:50:12,299 - Batch [7400/8699], Train Loss: 0.005533311715874432, Train Acc: 0.9988872466216216
2024-04-29 18:50:17,866 - Batch [7500/8699], Train Loss: 0.00553276547992391, Train Acc: 0.9988854166666666
2024-04-29 18:50:24,117 - Batch [7600/8699], Train Loss: 0.00557054629105419, Train Acc: 0.9988774671052632
2024-04-29 18:50:29,616 - Batch [7700/8699], Train Loss: 0.005539844381048476, Train Acc: 0.9988839285714286
2024-04-29 18:50:35,358 - Batch [7800/8699], Train Loss: 0.005535830161037643, Train Acc: 0.9988902243589743
2024-04-29 18:50:40,704 - Batch [7900/8699], Train Loss: 0.005571661351739726, Train Acc: 0.998884493670886
2024-04-29 18:50:46,634 - Batch [8000/8699], Train Loss: 0.005630970734116659, Train Acc: 0.998873046875
2024-04-29 18:50:52,501 - Batch [8100/8699], Train Loss: 0.005621713087056501, Train Acc: 0.9988792438271605
2024-04-29 18:50:58,147 - Batch [8200/8699], Train Loss: 0.005627635372222868, Train Acc: 0.9988833841463415
2024-04-29 18:51:03,765 - Batch [8300/8699], Train Loss: 0.005605167976570764, Train Acc: 0.9988855421686746
2024-04-29 18:51:09,526 - Batch [8400/8699], Train Loss: 0.005598210430289869, Train Acc: 0.998891369047619
2024-04-29 18:51:15,142 - Batch [8500/8699], Train Loss: 0.005610870054831085, Train Acc: 0.9988933823529412
2024-04-29 18:51:20,903 - Batch [8600/8699], Train Loss: 0.005618000279926089, Train Acc: 0.998889898255814
2024-04-29 18:51:27,512 - Train Loss: 0.0056142540303557725, Train Acc: 0.9988898469497737
2024-04-29 18:53:32,472 - Test Acc: 0.9991161951843416
2024-04-29 18:53:32,531 - Confusion Matrix:
 [[67491    65]
 [   58 71557]]
2024-04-29 18:53:32,574 - Saved the new best model to ../data/models/pklot/all/80_20/shufflenet.pth
2024-04-29 18:53:32,574 - Epoch time: 625.1267716884613 seconds.
2024-04-29 18:53:32,574 - Best Train Acc: 0.9988898469497737
2024-04-29 18:53:32,575 - Total training time: 3180.2084283828735 seconds.
