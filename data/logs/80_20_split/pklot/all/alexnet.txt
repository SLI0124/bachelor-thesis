2024-04-29 09:11:15,926 - Training the model...
2024-04-29 09:11:15,926 - Epoch 1/5
2024-04-29 09:11:37,502 - Batch [100/8699], Train Loss: 0.6902264156937599, Train Acc: 0.7740625
2024-04-29 09:11:42,247 - Batch [200/8699], Train Loss: 0.4062777322623879, Train Acc: 0.8653125
2024-04-29 09:11:46,734 - Batch [300/8699], Train Loss: 0.3003807716242348, Train Acc: 0.9003125
2024-04-29 09:11:51,394 - Batch [400/8699], Train Loss: 0.24228728846297598, Train Acc: 0.919609375
2024-04-29 09:11:55,999 - Batch [500/8699], Train Loss: 0.20632277529174461, Train Acc: 0.9315625
2024-04-29 09:12:00,636 - Batch [600/8699], Train Loss: 0.18292447665987613, Train Acc: 0.939140625
2024-04-29 09:12:05,186 - Batch [700/8699], Train Loss: 0.16422120274119412, Train Acc: 0.9454464285714286
2024-04-29 09:12:09,647 - Batch [800/8699], Train Loss: 0.148958444793534, Train Acc: 0.95044921875
2024-04-29 09:12:14,280 - Batch [900/8699], Train Loss: 0.13852917727199382, Train Acc: 0.9540277777777778
2024-04-29 09:12:18,897 - Batch [1000/8699], Train Loss: 0.1291828253370477, Train Acc: 0.95725
2024-04-29 09:12:23,469 - Batch [1100/8699], Train Loss: 0.1203676984373967, Train Acc: 0.960284090909091
2024-04-29 09:12:28,071 - Batch [1200/8699], Train Loss: 0.1134671693854519, Train Acc: 0.962578125
2024-04-29 09:12:32,636 - Batch [1300/8699], Train Loss: 0.10749854407360264, Train Acc: 0.9645793269230769
2024-04-29 09:12:37,067 - Batch [1400/8699], Train Loss: 0.10206760595834047, Train Acc: 0.9664620535714286
2024-04-29 09:12:41,614 - Batch [1500/8699], Train Loss: 0.09846250056245238, Train Acc: 0.9677708333333334
2024-04-29 09:12:46,329 - Batch [1600/8699], Train Loss: 0.09549012498343246, Train Acc: 0.9688671875
2024-04-29 09:12:51,558 - Batch [1700/8699], Train Loss: 0.09287790996249147, Train Acc: 0.9697610294117647
2024-04-29 09:12:56,853 - Batch [1800/8699], Train Loss: 0.08973642711557356, Train Acc: 0.9708940972222222
2024-04-29 09:13:01,799 - Batch [1900/8699], Train Loss: 0.08660507706613364, Train Acc: 0.9719983552631579
2024-04-29 09:13:06,479 - Batch [2000/8699], Train Loss: 0.0835543486186125, Train Acc: 0.9730546875
2024-04-29 09:13:11,072 - Batch [2100/8699], Train Loss: 0.08158783967867791, Train Acc: 0.9737872023809524
2024-04-29 09:13:15,894 - Batch [2200/8699], Train Loss: 0.07996629168115925, Train Acc: 0.974375
2024-04-29 09:13:20,734 - Batch [2300/8699], Train Loss: 0.07848429271169785, Train Acc: 0.9748980978260869
2024-04-29 09:13:25,462 - Batch [2400/8699], Train Loss: 0.07654330522721012, Train Acc: 0.9755598958333334
2024-04-29 09:13:30,237 - Batch [2500/8699], Train Loss: 0.07620788598069193, Train Acc: 0.975875
2024-04-29 09:13:34,982 - Batch [2600/8699], Train Loss: 0.07504829237039863, Train Acc: 0.9762019230769231
2024-04-29 09:13:39,755 - Batch [2700/8699], Train Loss: 0.07343963936581767, Train Acc: 0.976724537037037
2024-04-29 09:13:44,536 - Batch [2800/8699], Train Loss: 0.07225934513481662, Train Acc: 0.9770870535714286
2024-04-29 09:13:49,325 - Batch [2900/8699], Train Loss: 0.07063849576722689, Train Acc: 0.9776131465517242
2024-04-29 09:13:53,939 - Batch [3000/8699], Train Loss: 0.06909619547763941, Train Acc: 0.9781614583333333
2024-04-29 09:13:58,578 - Batch [3100/8699], Train Loss: 0.06801730970222003, Train Acc: 0.978523185483871
2024-04-29 09:14:03,252 - Batch [3200/8699], Train Loss: 0.06651194698570521, Train Acc: 0.9790185546875
2024-04-29 09:14:07,826 - Batch [3300/8699], Train Loss: 0.0656378054928207, Train Acc: 0.9793276515151516
2024-04-29 09:14:12,334 - Batch [3400/8699], Train Loss: 0.06448409438576538, Train Acc: 0.9796231617647059
2024-04-29 09:14:16,985 - Batch [3500/8699], Train Loss: 0.06358352771487781, Train Acc: 0.9799508928571429
2024-04-29 09:14:21,822 - Batch [3600/8699], Train Loss: 0.06213627488638849, Train Acc: 0.9803819444444445
2024-04-29 09:14:26,499 - Batch [3700/8699], Train Loss: 0.06164174247020816, Train Acc: 0.9806038851351352
2024-04-29 09:14:31,117 - Batch [3800/8699], Train Loss: 0.06070656976647833, Train Acc: 0.9809498355263158
2024-04-29 09:14:35,634 - Batch [3900/8699], Train Loss: 0.059827834759771346, Train Acc: 0.9812419871794872
2024-04-29 09:14:40,235 - Batch [4000/8699], Train Loss: 0.0593836840434833, Train Acc: 0.9814375
2024-04-29 09:14:45,099 - Batch [4100/8699], Train Loss: 0.05857044235644358, Train Acc: 0.9816653963414634
2024-04-29 09:14:50,490 - Batch [4200/8699], Train Loss: 0.05871773312152592, Train Acc: 0.9817113095238095
2024-04-29 09:14:55,988 - Batch [4300/8699], Train Loss: 0.05812564928934884, Train Acc: 0.9819004360465117
2024-04-29 09:15:01,562 - Batch [4400/8699], Train Loss: 0.05748128657630084, Train Acc: 0.9821306818181819
2024-04-29 09:15:06,527 - Batch [4500/8699], Train Loss: 0.0567391107351642, Train Acc: 0.9823819444444445
2024-04-29 09:15:12,036 - Batch [4600/8699], Train Loss: 0.05604457299553716, Train Acc: 0.9826086956521739
2024-04-29 09:15:17,115 - Batch [4700/8699], Train Loss: 0.05540350178923542, Train Acc: 0.9828191489361702
2024-04-29 09:15:21,971 - Batch [4800/8699], Train Loss: 0.054735365074052425, Train Acc: 0.9830598958333333
2024-04-29 09:15:26,698 - Batch [4900/8699], Train Loss: 0.05423945286277057, Train Acc: 0.9832110969387755
2024-04-29 09:15:31,459 - Batch [5000/8699], Train Loss: 0.053738887515469104, Train Acc: 0.983409375
2024-04-29 09:15:36,007 - Batch [5100/8699], Train Loss: 0.053390774058016, Train Acc: 0.9835814950980392
2024-04-29 09:15:40,773 - Batch [5200/8699], Train Loss: 0.05296777747881536, Train Acc: 0.9837349759615385
2024-04-29 09:15:45,560 - Batch [5300/8699], Train Loss: 0.05261251532975672, Train Acc: 0.9838679245283019
2024-04-29 09:15:50,447 - Batch [5400/8699], Train Loss: 0.052144193770757366, Train Acc: 0.9840335648148149
2024-04-29 09:15:55,407 - Batch [5500/8699], Train Loss: 0.05171072802746097, Train Acc: 0.9841789772727273
2024-04-29 09:16:00,504 - Batch [5600/8699], Train Loss: 0.051204733230195934, Train Acc: 0.9843359375
2024-04-29 09:16:05,464 - Batch [5700/8699], Train Loss: 0.05081615463820574, Train Acc: 0.9844873903508772
2024-04-29 09:16:10,208 - Batch [5800/8699], Train Loss: 0.05043405144192642, Train Acc: 0.9846417025862069
2024-04-29 09:16:14,990 - Batch [5900/8699], Train Loss: 0.05000334516593592, Train Acc: 0.9847907838983051
2024-04-29 09:16:19,734 - Batch [6000/8699], Train Loss: 0.049634431654701376, Train Acc: 0.9849036458333333
2024-04-29 09:16:24,436 - Batch [6100/8699], Train Loss: 0.04951987932612819, Train Acc: 0.9849205942622951
2024-04-29 09:16:29,189 - Batch [6200/8699], Train Loss: 0.04984791267791978, Train Acc: 0.9847857862903225
2024-04-29 09:16:34,966 - Batch [6300/8699], Train Loss: 0.050107815441240544, Train Acc: 0.9847817460317461
2024-04-29 09:16:41,121 - Batch [6400/8699], Train Loss: 0.04990427898904159, Train Acc: 0.98484375
2024-04-29 09:16:47,401 - Batch [6500/8699], Train Loss: 0.049549656231959276, Train Acc: 0.9849663461538462
2024-04-29 09:16:53,458 - Batch [6600/8699], Train Loss: 0.049133530828826634, Train Acc: 0.9851017992424242
2024-04-29 09:16:58,391 - Batch [6700/8699], Train Loss: 0.05043049289344952, Train Acc: 0.9848530783582089
2024-04-29 09:17:03,438 - Batch [6800/8699], Train Loss: 0.05044094664846317, Train Acc: 0.9848460477941177
2024-04-29 09:17:08,098 - Batch [6900/8699], Train Loss: 0.05021791488862262, Train Acc: 0.9849071557971014
2024-04-29 09:17:12,819 - Batch [7000/8699], Train Loss: 0.049967296262084605, Train Acc: 0.9849866071428571
2024-04-29 09:17:17,399 - Batch [7100/8699], Train Loss: 0.049631024298580316, Train Acc: 0.9850814260563381
2024-04-29 09:17:22,132 - Batch [7200/8699], Train Loss: 0.04939306076313288, Train Acc: 0.9851714409722222
2024-04-29 09:17:26,829 - Batch [7300/8699], Train Loss: 0.04906554790647072, Train Acc: 0.9852696917808219
2024-04-29 09:17:31,599 - Batch [7400/8699], Train Loss: 0.04882018293745795, Train Acc: 0.9853758445945946
2024-04-29 09:17:36,257 - Batch [7500/8699], Train Loss: 0.048491754141646866, Train Acc: 0.9854958333333333
2024-04-29 09:17:40,943 - Batch [7600/8699], Train Loss: 0.04812343003351711, Train Acc: 0.9855921052631579
2024-04-29 09:17:45,567 - Batch [7700/8699], Train Loss: 0.04788386212386321, Train Acc: 0.9856635551948052
2024-04-29 09:17:50,336 - Batch [7800/8699], Train Loss: 0.04764566264469184, Train Acc: 0.9857532051282051
2024-04-29 09:17:55,116 - Batch [7900/8699], Train Loss: 0.04750413050185233, Train Acc: 0.985818829113924
2024-04-29 09:17:59,819 - Batch [8000/8699], Train Loss: 0.0472978344256826, Train Acc: 0.985888671875
2024-04-29 09:18:04,594 - Batch [8100/8699], Train Loss: 0.04710236781841233, Train Acc: 0.9859567901234568
2024-04-29 09:18:09,380 - Batch [8200/8699], Train Loss: 0.04694396827762653, Train Acc: 0.9859984756097561
2024-04-29 09:18:14,183 - Batch [8300/8699], Train Loss: 0.046718340847602305, Train Acc: 0.9860805722891566
2024-04-29 09:18:18,960 - Batch [8400/8699], Train Loss: 0.04643388194236433, Train Acc: 0.9861737351190476
2024-04-29 09:18:23,756 - Batch [8500/8699], Train Loss: 0.04620969278778306, Train Acc: 0.9862536764705883
2024-04-29 09:18:28,488 - Batch [8600/8699], Train Loss: 0.046056175382755735, Train Acc: 0.9862827034883721
2024-04-29 09:18:33,896 - Train Loss: 0.04573838690972291, Train Acc: 0.9863871524035353
2024-04-29 09:20:17,220 - Test Acc: 0.9964863369523823
2024-04-29 09:20:17,274 - Confusion Matrix:
 [[67413   143]
 [  346 71269]]
2024-04-29 09:20:17,623 - Saved the new best model to ../data/models/pklot/all/80_20/alexnet.pth
2024-04-29 09:20:17,623 - Epoch time: 541.6978185176849 seconds.
2024-04-29 09:20:17,623 - Epoch 2/5
2024-04-29 09:20:37,444 - Batch [100/8699], Train Loss: 0.020796055944920226, Train Acc: 0.99359375
2024-04-29 09:20:41,861 - Batch [200/8699], Train Loss: 0.02253579637990697, Train Acc: 0.99359375
2024-04-29 09:20:46,312 - Batch [300/8699], Train Loss: 0.025144885517086855, Train Acc: 0.9936979166666666
2024-04-29 09:20:50,792 - Batch [400/8699], Train Loss: 0.02653596819248378, Train Acc: 0.9934765625
2024-04-29 09:20:55,269 - Batch [500/8699], Train Loss: 0.02476116732087394, Train Acc: 0.9936875
2024-04-29 09:20:59,756 - Batch [600/8699], Train Loss: 0.02504718248321903, Train Acc: 0.993671875
2024-04-29 09:21:04,233 - Batch [700/8699], Train Loss: 0.023401335795887074, Train Acc: 0.9940178571428572
2024-04-29 09:21:08,710 - Batch [800/8699], Train Loss: 0.026419591371518437, Train Acc: 0.9933203125
2024-04-29 09:21:13,186 - Batch [900/8699], Train Loss: 0.028310452206783843, Train Acc: 0.99296875
2024-04-29 09:21:17,679 - Batch [1000/8699], Train Loss: 0.02832347101729465, Train Acc: 0.992921875
2024-04-29 09:21:22,194 - Batch [1100/8699], Train Loss: 0.028269805151447308, Train Acc: 0.9929403409090909
2024-04-29 09:21:26,726 - Batch [1200/8699], Train Loss: 0.030210422078839658, Train Acc: 0.99234375
2024-04-29 09:21:31,279 - Batch [1300/8699], Train Loss: 0.030696978187108752, Train Acc: 0.9921995192307692
2024-04-29 09:21:35,838 - Batch [1400/8699], Train Loss: 0.030823228163697942, Train Acc: 0.9923102678571428
2024-04-29 09:21:40,402 - Batch [1500/8699], Train Loss: 0.031646203878327166, Train Acc: 0.9923020833333334
2024-04-29 09:21:44,983 - Batch [1600/8699], Train Loss: 0.041761665454615696, Train Acc: 0.99078125
2024-04-29 09:21:49,576 - Batch [1700/8699], Train Loss: 0.044166632641642056, Train Acc: 0.9897058823529412
2024-04-29 09:21:54,171 - Batch [1800/8699], Train Loss: 0.04453570850820951, Train Acc: 0.9894270833333333
2024-04-29 09:21:58,762 - Batch [1900/8699], Train Loss: 0.04398114846988775, Train Acc: 0.9894654605263158
2024-04-29 09:22:03,357 - Batch [2000/8699], Train Loss: 0.04377997375867653, Train Acc: 0.9895546875
2024-04-29 09:22:07,973 - Batch [2100/8699], Train Loss: 0.0435909793448887, Train Acc: 0.9895089285714286
2024-04-29 09:22:12,577 - Batch [2200/8699], Train Loss: 0.044578379834156294, Train Acc: 0.9890909090909091
2024-04-29 09:22:17,193 - Batch [2300/8699], Train Loss: 0.04438074333471852, Train Acc: 0.9890285326086956
2024-04-29 09:22:21,808 - Batch [2400/8699], Train Loss: 0.04439932838128471, Train Acc: 0.9889583333333334
2024-04-29 09:22:26,430 - Batch [2500/8699], Train Loss: 0.04439850648820939, Train Acc: 0.98890625
2024-04-29 09:22:31,056 - Batch [2600/8699], Train Loss: 0.04353034937773373, Train Acc: 0.9890504807692307
2024-04-29 09:22:35,677 - Batch [2700/8699], Train Loss: 0.04287578838059306, Train Acc: 0.9891145833333334
2024-04-29 09:22:40,314 - Batch [2800/8699], Train Loss: 0.0421126923923092, Train Acc: 0.9892857142857143
2024-04-29 09:22:44,942 - Batch [2900/8699], Train Loss: 0.041940178849859434, Train Acc: 0.989364224137931
2024-04-29 09:22:49,581 - Batch [3000/8699], Train Loss: 0.041727247451335645, Train Acc: 0.9894375
2024-04-29 09:22:54,217 - Batch [3100/8699], Train Loss: 0.041056451023971846, Train Acc: 0.9895614919354838
2024-04-29 09:22:58,851 - Batch [3200/8699], Train Loss: 0.04034397306626545, Train Acc: 0.9897607421875
2024-04-29 09:23:03,497 - Batch [3300/8699], Train Loss: 0.03995907325537535, Train Acc: 0.9898768939393939
2024-04-29 09:23:08,141 - Batch [3400/8699], Train Loss: 0.0394344866081867, Train Acc: 0.9899908088235294
2024-04-29 09:23:12,776 - Batch [3500/8699], Train Loss: 0.0395323068272893, Train Acc: 0.9899196428571428
2024-04-29 09:23:17,427 - Batch [3600/8699], Train Loss: 0.03914399914021538, Train Acc: 0.9900086805555556
2024-04-29 09:23:22,071 - Batch [3700/8699], Train Loss: 0.0387957416730692, Train Acc: 0.9900929054054054
2024-04-29 09:23:26,716 - Batch [3800/8699], Train Loss: 0.03839402693597549, Train Acc: 0.9901768092105263
2024-04-29 09:23:31,368 - Batch [3900/8699], Train Loss: 0.03815553593053361, Train Acc: 0.9901883012820513
2024-04-29 09:23:36,013 - Batch [4000/8699], Train Loss: 0.03781189772388416, Train Acc: 0.99022265625
2024-04-29 09:23:40,661 - Batch [4100/8699], Train Loss: 0.0372590835353846, Train Acc: 0.9903353658536586
2024-04-29 09:23:45,302 - Batch [4200/8699], Train Loss: 0.03682539857392363, Train Acc: 0.9904427083333334
2024-04-29 09:23:49,942 - Batch [4300/8699], Train Loss: 0.036411903996921506, Train Acc: 0.9905414244186046
2024-04-29 09:23:54,591 - Batch [4400/8699], Train Loss: 0.036043110919615005, Train Acc: 0.9906036931818182
2024-04-29 09:23:59,239 - Batch [4500/8699], Train Loss: 0.03562051759782359, Train Acc: 0.99071875
2024-04-29 09:24:03,890 - Batch [4600/8699], Train Loss: 0.035323469490496556, Train Acc: 0.990757472826087
2024-04-29 09:24:08,538 - Batch [4700/8699], Train Loss: 0.036754708469925006, Train Acc: 0.9903557180851064
2024-04-29 09:24:13,190 - Batch [4800/8699], Train Loss: 0.03725834084931838, Train Acc: 0.99009765625
2024-04-29 09:24:17,836 - Batch [4900/8699], Train Loss: 0.037247570220034526, Train Acc: 0.9900924744897959
2024-04-29 09:24:22,498 - Batch [5000/8699], Train Loss: 0.037359885562514315, Train Acc: 0.99008125
2024-04-29 09:24:27,166 - Batch [5100/8699], Train Loss: 0.03829825176165233, Train Acc: 0.9898314950980392
2024-04-29 09:24:31,835 - Batch [5200/8699], Train Loss: 0.03855089097641737, Train Acc: 0.9897806490384615
2024-04-29 09:24:36,513 - Batch [5300/8699], Train Loss: 0.038612453191778154, Train Acc: 0.9897346698113207
2024-04-29 09:24:41,189 - Batch [5400/8699], Train Loss: 0.03874955731504862, Train Acc: 0.9897280092592593
2024-04-29 09:24:45,870 - Batch [5500/8699], Train Loss: 0.03859371909191627, Train Acc: 0.9897528409090909
2024-04-29 09:24:50,594 - Batch [5600/8699], Train Loss: 0.03846135532757768, Train Acc: 0.9897823660714286
2024-04-29 09:24:55,287 - Batch [5700/8699], Train Loss: 0.03824788971939294, Train Acc: 0.9898273026315789
2024-04-29 09:24:59,977 - Batch [5800/8699], Train Loss: 0.038092009565402644, Train Acc: 0.9898922413793103
2024-04-29 09:25:04,670 - Batch [5900/8699], Train Loss: 0.03801965042946164, Train Acc: 0.9899126059322034
2024-04-29 09:25:09,358 - Batch [6000/8699], Train Loss: 0.03774392474460819, Train Acc: 0.9899765625
2024-04-29 09:25:14,050 - Batch [6100/8699], Train Loss: 0.03746040496819317, Train Acc: 0.9900563524590164
2024-04-29 09:25:18,739 - Batch [6200/8699], Train Loss: 0.03738479018732564, Train Acc: 0.9900730846774194
2024-04-29 09:25:23,438 - Batch [6300/8699], Train Loss: 0.03726682172182538, Train Acc: 0.9901264880952381
2024-04-29 09:25:28,122 - Batch [6400/8699], Train Loss: 0.03727121800101287, Train Acc: 0.99012939453125
2024-04-29 09:25:32,802 - Batch [6500/8699], Train Loss: 0.03695527616829853, Train Acc: 0.9901923076923077
2024-04-29 09:25:37,496 - Batch [6600/8699], Train Loss: 0.03678433345540146, Train Acc: 0.990250946969697
2024-04-29 09:25:42,194 - Batch [6700/8699], Train Loss: 0.03656911888128753, Train Acc: 0.9903101679104478
2024-04-29 09:25:46,891 - Batch [6800/8699], Train Loss: 0.03661494582361603, Train Acc: 0.9903010110294118
2024-04-29 09:25:51,591 - Batch [6900/8699], Train Loss: 0.037094879736389925, Train Acc: 0.9902060688405797
2024-04-29 09:25:56,290 - Batch [7000/8699], Train Loss: 0.03924156531146894, Train Acc: 0.9896919642857143
2024-04-29 09:26:00,990 - Batch [7100/8699], Train Loss: 0.04069177889397112, Train Acc: 0.9893661971830986
2024-04-29 09:26:05,693 - Batch [7200/8699], Train Loss: 0.04132948099461727, Train Acc: 0.9891927083333333
2024-04-29 09:26:10,396 - Batch [7300/8699], Train Loss: 0.04209505686020536, Train Acc: 0.9890025684931507
2024-04-29 09:26:15,103 - Batch [7400/8699], Train Loss: 0.042181382553055695, Train Acc: 0.9889759290540541
2024-04-29 09:26:19,807 - Batch [7500/8699], Train Loss: 0.04230610466047656, Train Acc: 0.988925
2024-04-29 09:26:24,514 - Batch [7600/8699], Train Loss: 0.042211986799290904, Train Acc: 0.9889329769736842
2024-04-29 09:26:29,214 - Batch [7700/8699], Train Loss: 0.04375884748445733, Train Acc: 0.9883685064935065
2024-04-29 09:26:33,929 - Batch [7800/8699], Train Loss: 0.04438427911600462, Train Acc: 0.9881850961538462
2024-04-29 09:26:38,638 - Batch [7900/8699], Train Loss: 0.044671507447293396, Train Acc: 0.9880992879746835
2024-04-29 09:26:43,353 - Batch [8000/8699], Train Loss: 0.04510776911707216, Train Acc: 0.988044921875
2024-04-29 09:26:48,071 - Batch [8100/8699], Train Loss: 0.04501849842029997, Train Acc: 0.9880632716049382
2024-04-29 09:26:52,785 - Batch [8200/8699], Train Loss: 0.04490686450046402, Train Acc: 0.9880697408536585
2024-04-29 09:26:57,502 - Batch [8300/8699], Train Loss: 0.04486743611891625, Train Acc: 0.9881118222891566
2024-04-29 09:27:02,223 - Batch [8400/8699], Train Loss: 0.045153345158718626, Train Acc: 0.9880226934523809
2024-04-29 09:27:06,940 - Batch [8500/8699], Train Loss: 0.04497121359688668, Train Acc: 0.9880551470588236
2024-04-29 09:27:11,663 - Batch [8600/8699], Train Loss: 0.04488693289351812, Train Acc: 0.9880977470930232
2024-04-29 09:27:17,013 - Train Loss: 0.04486769203311874, Train Acc: 0.9880954947186894
2024-04-29 09:28:56,594 - Test Acc: 0.9947690251561029
2024-04-29 09:28:56,646 - Confusion Matrix:
 [[67313   243]
 [  485 71130]]
2024-04-29 09:28:56,977 - Saved the new best model to ../data/models/pklot/all/80_20/alexnet.pth
2024-04-29 09:28:56,977 - Epoch time: 519.3534414768219 seconds.
2024-04-29 09:28:56,977 - Epoch 3/5
2024-04-29 09:29:17,390 - Batch [100/8699], Train Loss: 0.04176579442995717, Train Acc: 0.9909375
2024-04-29 09:29:21,885 - Batch [200/8699], Train Loss: 0.04525785072917642, Train Acc: 0.989765625
2024-04-29 09:29:26,524 - Batch [300/8699], Train Loss: 0.04923209549922224, Train Acc: 0.9882291666666667
2024-04-29 09:29:31,037 - Batch [400/8699], Train Loss: 0.043967579205746, Train Acc: 0.988671875
2024-04-29 09:29:35,547 - Batch [500/8699], Train Loss: 0.04553096366513637, Train Acc: 0.98896875
2024-04-29 09:29:40,076 - Batch [600/8699], Train Loss: 0.044149844779773656, Train Acc: 0.98890625
2024-04-29 09:29:44,648 - Batch [700/8699], Train Loss: 0.05039834630494754, Train Acc: 0.9880357142857142
2024-04-29 09:29:49,238 - Batch [800/8699], Train Loss: 0.059865232596221174, Train Acc: 0.98494140625
2024-04-29 09:29:53,842 - Batch [900/8699], Train Loss: 0.06662255913292434, Train Acc: 0.9823263888888889
2024-04-29 09:29:58,474 - Batch [1000/8699], Train Loss: 0.0820893496057397, Train Acc: 0.97790625
2024-04-29 09:30:03,118 - Batch [1100/8699], Train Loss: 0.08456933526037821, Train Acc: 0.9770596590909091
2024-04-29 09:30:07,775 - Batch [1200/8699], Train Loss: 0.08467102557237619, Train Acc: 0.9770833333333333
2024-04-29 09:30:12,445 - Batch [1300/8699], Train Loss: 0.08501373812960362, Train Acc: 0.9765384615384616
2024-04-29 09:30:17,120 - Batch [1400/8699], Train Loss: 0.09212842230378425, Train Acc: 0.9753571428571428
2024-04-29 09:30:21,817 - Batch [1500/8699], Train Loss: 0.11249287097366566, Train Acc: 0.9721666666666666
2024-04-29 09:30:26,522 - Batch [1600/8699], Train Loss: 0.11204439195070336, Train Acc: 0.9718359375
2024-04-29 09:30:31,229 - Batch [1700/8699], Train Loss: 0.10985363915419678, Train Acc: 0.9723988970588235
2024-04-29 09:30:35,939 - Batch [1800/8699], Train Loss: 0.10655374826210998, Train Acc: 0.973125
2024-04-29 09:30:40,658 - Batch [1900/8699], Train Loss: 0.10438070729075423, Train Acc: 0.9736595394736842
2024-04-29 09:30:45,383 - Batch [2000/8699], Train Loss: 0.1025051271144257, Train Acc: 0.97409375
2024-04-29 09:30:50,116 - Batch [2100/8699], Train Loss: 0.10059628200135887, Train Acc: 0.9745833333333334
2024-04-29 09:30:54,848 - Batch [2200/8699], Train Loss: 0.09810081284975405, Train Acc: 0.9751420454545454
2024-04-29 09:30:59,582 - Batch [2300/8699], Train Loss: 0.09610862792880179, Train Acc: 0.9757608695652173
2024-04-29 09:31:04,322 - Batch [2400/8699], Train Loss: 0.09475014069821555, Train Acc: 0.97599609375
2024-04-29 09:31:09,069 - Batch [2500/8699], Train Loss: 0.09791012811442489, Train Acc: 0.97559375
2024-04-29 09:31:13,813 - Batch [2600/8699], Train Loss: 0.09674241805275065, Train Acc: 0.9758052884615385
2024-04-29 09:31:18,559 - Batch [2700/8699], Train Loss: 0.09479867356825572, Train Acc: 0.9762094907407407
2024-04-29 09:31:23,309 - Batch [2800/8699], Train Loss: 0.09293647897858526, Train Acc: 0.9766629464285714
2024-04-29 09:31:28,069 - Batch [2900/8699], Train Loss: 0.09234032121379077, Train Acc: 0.9770797413793103
2024-04-29 09:31:32,828 - Batch [3000/8699], Train Loss: 0.09175392332894747, Train Acc: 0.97721875
2024-04-29 09:31:37,590 - Batch [3100/8699], Train Loss: 0.09130926927135255, Train Acc: 0.9773235887096774
2024-04-29 09:31:42,351 - Batch [3200/8699], Train Loss: 0.09696859234526073, Train Acc: 0.9757275390625
2024-04-29 09:31:47,117 - Batch [3300/8699], Train Loss: 0.09562441343385603, Train Acc: 0.9759659090909091
2024-04-29 09:31:51,879 - Batch [3400/8699], Train Loss: 0.09840364534418554, Train Acc: 0.9757858455882353
2024-04-29 09:31:56,648 - Batch [3500/8699], Train Loss: 0.09695248519546502, Train Acc: 0.9760892857142857
2024-04-29 09:32:01,416 - Batch [3600/8699], Train Loss: 0.0952021965028487, Train Acc: 0.9764756944444445
2024-04-29 09:32:06,183 - Batch [3700/8699], Train Loss: 0.09351754966529001, Train Acc: 0.9768496621621622
2024-04-29 09:32:10,953 - Batch [3800/8699], Train Loss: 0.09187317163435708, Train Acc: 0.9772245065789473
2024-04-29 09:32:15,731 - Batch [3900/8699], Train Loss: 0.09002012626078422, Train Acc: 0.97765625
2024-04-29 09:32:20,508 - Batch [4000/8699], Train Loss: 0.08876976349083998, Train Acc: 0.977984375
2024-04-29 09:32:25,287 - Batch [4100/8699], Train Loss: 0.08754796010965947, Train Acc: 0.978250762195122
2024-04-29 09:32:30,059 - Batch [4200/8699], Train Loss: 0.08854782424077885, Train Acc: 0.9784077380952381
2024-04-29 09:32:34,841 - Batch [4300/8699], Train Loss: 0.09015223886783175, Train Acc: 0.9777579941860465
2024-04-29 09:32:39,622 - Batch [4400/8699], Train Loss: 0.09037346094770658, Train Acc: 0.9775390625
2024-04-29 09:32:44,407 - Batch [4500/8699], Train Loss: 0.09348971438416306, Train Acc: 0.9769444444444444
2024-04-29 09:32:49,183 - Batch [4600/8699], Train Loss: 0.09494688252137047, Train Acc: 0.9769769021739131
2024-04-29 09:32:53,968 - Batch [4700/8699], Train Loss: 0.09454420467153157, Train Acc: 0.9769780585106383
2024-04-29 09:32:58,735 - Batch [4800/8699], Train Loss: 0.09413513872838546, Train Acc: 0.9770703125
2024-04-29 09:33:03,510 - Batch [4900/8699], Train Loss: 0.09357662074465652, Train Acc: 0.9771588010204082
2024-04-29 09:33:08,279 - Batch [5000/8699], Train Loss: 0.09294109505571542, Train Acc: 0.977215625
2024-04-29 09:33:13,049 - Batch [5100/8699], Train Loss: 0.09247693021496982, Train Acc: 0.9772365196078432
2024-04-29 09:33:17,811 - Batch [5200/8699], Train Loss: 0.09256055720569678, Train Acc: 0.9770823317307692
2024-04-29 09:33:22,579 - Batch [5300/8699], Train Loss: 0.09222686169184151, Train Acc: 0.9771049528301887
2024-04-29 09:33:27,346 - Batch [5400/8699], Train Loss: 0.09124110112775707, Train Acc: 0.9772858796296297
2024-04-29 09:33:32,101 - Batch [5500/8699], Train Loss: 0.09056658178532433, Train Acc: 0.9774005681818182
2024-04-29 09:33:36,850 - Batch [5600/8699], Train Loss: 0.08980483077107368, Train Acc: 0.9775641741071428
2024-04-29 09:33:41,599 - Batch [5700/8699], Train Loss: 0.08905013750518137, Train Acc: 0.9777001096491228
2024-04-29 09:33:46,351 - Batch [5800/8699], Train Loss: 0.08840038459031975, Train Acc: 0.9778448275862069
2024-04-29 09:33:51,109 - Batch [5900/8699], Train Loss: 0.08935582851591004, Train Acc: 0.9774814618644068
2024-04-29 09:33:55,869 - Batch [6000/8699], Train Loss: 0.0937295394817144, Train Acc: 0.9759765625
2024-04-29 09:34:00,637 - Batch [6100/8699], Train Loss: 0.09410796294762222, Train Acc: 0.9757684426229508
2024-04-29 09:34:05,408 - Batch [6200/8699], Train Loss: 0.0937076674709181, Train Acc: 0.9758744959677419
2024-04-29 09:34:10,175 - Batch [6300/8699], Train Loss: 0.09323173143688888, Train Acc: 0.975999503968254
2024-04-29 09:34:14,936 - Batch [6400/8699], Train Loss: 0.09243281187557387, Train Acc: 0.976171875
2024-04-29 09:34:19,700 - Batch [6500/8699], Train Loss: 0.09181897198188996, Train Acc: 0.9763028846153846
2024-04-29 09:34:24,479 - Batch [6600/8699], Train Loss: 0.09118243919257304, Train Acc: 0.9764559659090909
2024-04-29 09:34:29,256 - Batch [6700/8699], Train Loss: 0.09048374282288688, Train Acc: 0.9766324626865671
2024-04-29 09:34:34,039 - Batch [6800/8699], Train Loss: 0.0897637562352611, Train Acc: 0.9768037683823529
2024-04-29 09:34:38,815 - Batch [6900/8699], Train Loss: 0.08899742421183307, Train Acc: 0.9770040760869565
2024-04-29 09:34:43,588 - Batch [7000/8699], Train Loss: 0.08817181673634747, Train Acc: 0.9772098214285714
2024-04-29 09:34:48,358 - Batch [7100/8699], Train Loss: 0.08743491549483044, Train Acc: 0.9773943661971831
2024-04-29 09:34:53,132 - Batch [7200/8699], Train Loss: 0.08660869015987474, Train Acc: 0.9775998263888889
2024-04-29 09:34:57,901 - Batch [7300/8699], Train Loss: 0.08578850830227777, Train Acc: 0.9777953767123287
2024-04-29 09:35:02,679 - Batch [7400/8699], Train Loss: 0.08505172021248507, Train Acc: 0.9779603040540541
2024-04-29 09:35:07,453 - Batch [7500/8699], Train Loss: 0.08433107840669109, Train Acc: 0.97813125
2024-04-29 09:35:12,227 - Batch [7600/8699], Train Loss: 0.08358763748833888, Train Acc: 0.9783100328947368
2024-04-29 09:35:16,995 - Batch [7700/8699], Train Loss: 0.08289781870612611, Train Acc: 0.9784801136363637
2024-04-29 09:35:21,816 - Batch [7800/8699], Train Loss: 0.08227616895145799, Train Acc: 0.9786278044871795
2024-04-29 09:35:26,621 - Batch [7900/8699], Train Loss: 0.08316849939999998, Train Acc: 0.9783583860759494
2024-04-29 09:35:31,418 - Batch [8000/8699], Train Loss: 0.08516579822291169, Train Acc: 0.977796875
2024-04-29 09:35:36,598 - Batch [8100/8699], Train Loss: 0.0850367730195716, Train Acc: 0.9778028549382716
2024-04-29 09:35:41,599 - Batch [8200/8699], Train Loss: 0.08792715753789597, Train Acc: 0.9771798780487805
2024-04-29 09:35:46,371 - Batch [8300/8699], Train Loss: 0.09089133215033385, Train Acc: 0.9763836596385542
2024-04-29 09:35:51,143 - Batch [8400/8699], Train Loss: 0.09127147978036235, Train Acc: 0.9762593005952381
2024-04-29 09:35:55,916 - Batch [8500/8699], Train Loss: 0.09109192986531964, Train Acc: 0.9762720588235294
2024-04-29 09:36:00,687 - Batch [8600/8699], Train Loss: 0.09063738495206561, Train Acc: 0.976359011627907
2024-04-29 09:36:06,024 - Train Loss: 0.09039772911493191, Train Acc: 0.9764173313214055
2024-04-29 09:37:45,611 - Test Acc: 0.9853345883840743
2024-04-29 09:37:45,665 - Confusion Matrix:
 [[66764   792]
 [ 1249 70366]]
2024-04-29 09:37:45,668 - Epoch time: 528.6913018226624 seconds.
2024-04-29 09:37:45,668 - Epoch 4/5
2024-04-29 09:38:05,823 - Batch [100/8699], Train Loss: 0.06763588005676865, Train Acc: 0.97984375
2024-04-29 09:38:10,341 - Batch [200/8699], Train Loss: 0.056682644495740536, Train Acc: 0.982734375
2024-04-29 09:38:14,887 - Batch [300/8699], Train Loss: 0.04984193059693401, Train Acc: 0.9847916666666666
2024-04-29 09:38:19,473 - Batch [400/8699], Train Loss: 0.046119262049905956, Train Acc: 0.9861328125
2024-04-29 09:38:24,080 - Batch [500/8699], Train Loss: 0.04579452193155885, Train Acc: 0.98671875
2024-04-29 09:38:28,697 - Batch [600/8699], Train Loss: 0.04236389299078534, Train Acc: 0.9877083333333333
2024-04-29 09:38:33,338 - Batch [700/8699], Train Loss: 0.042863476650922425, Train Acc: 0.9877901785714286
2024-04-29 09:38:37,999 - Batch [800/8699], Train Loss: 0.042111402768350674, Train Acc: 0.9880859375
2024-04-29 09:38:42,662 - Batch [900/8699], Train Loss: 0.04624923890663518, Train Acc: 0.98703125
2024-04-29 09:38:47,335 - Batch [1000/8699], Train Loss: 0.04977170184487477, Train Acc: 0.98628125
2024-04-29 09:38:52,034 - Batch [1100/8699], Train Loss: 0.04921462176240642, Train Acc: 0.9862642045454545
2024-04-29 09:38:56,718 - Batch [1200/8699], Train Loss: 0.055094373127406775, Train Acc: 0.9855989583333333
2024-04-29 09:39:01,419 - Batch [1300/8699], Train Loss: 0.05686901439321586, Train Acc: 0.9852163461538461
2024-04-29 09:39:06,120 - Batch [1400/8699], Train Loss: 0.058142902564889354, Train Acc: 0.9844754464285714
2024-04-29 09:39:10,833 - Batch [1500/8699], Train Loss: 0.06236420019164992, Train Acc: 0.9836041666666666
2024-04-29 09:39:15,542 - Batch [1600/8699], Train Loss: 0.06742587206194002, Train Acc: 0.982421875
2024-04-29 09:39:20,272 - Batch [1700/8699], Train Loss: 0.06835424940218218, Train Acc: 0.9821139705882352
2024-04-29 09:39:24,995 - Batch [1800/8699], Train Loss: 0.06801228074570341, Train Acc: 0.9820399305555556
2024-04-29 09:39:29,726 - Batch [1900/8699], Train Loss: 0.09024191068908151, Train Acc: 0.9809128289473684
2024-04-29 09:39:34,449 - Batch [2000/8699], Train Loss: 0.09795315476815449, Train Acc: 0.9796015625
2024-04-29 09:39:39,213 - Batch [2100/8699], Train Loss: 0.10180924934983653, Train Acc: 0.9791666666666666
2024-04-29 09:39:43,949 - Batch [2200/8699], Train Loss: 0.10074224112962839, Train Acc: 0.9791974431818182
2024-04-29 09:39:48,683 - Batch [2300/8699], Train Loss: 0.10023308439489009, Train Acc: 0.9787364130434782
2024-04-29 09:39:53,419 - Batch [2400/8699], Train Loss: 0.1190966434670554, Train Acc: 0.97732421875
2024-04-29 09:39:58,150 - Batch [2500/8699], Train Loss: 0.12173873967365362, Train Acc: 0.97620625
2024-04-29 09:40:02,893 - Batch [2600/8699], Train Loss: 0.15134948977757282, Train Acc: 0.9737199519230769
2024-04-29 09:40:07,642 - Batch [2700/8699], Train Loss: 0.15028924251583198, Train Acc: 0.9733275462962963
2024-04-29 09:40:12,402 - Batch [2800/8699], Train Loss: 0.14831950628452303, Train Acc: 0.9732645089285714
2024-04-29 09:40:17,191 - Batch [2900/8699], Train Loss: 0.14654943654237412, Train Acc: 0.9731465517241379
2024-04-29 09:40:21,981 - Batch [3000/8699], Train Loss: 0.1441238277720986, Train Acc: 0.9731875
2024-04-29 09:40:26,748 - Batch [3100/8699], Train Loss: 0.14198959679692053, Train Acc: 0.9732056451612904
2024-04-29 09:40:31,517 - Batch [3200/8699], Train Loss: 0.13996118191473214, Train Acc: 0.973271484375
2024-04-29 09:40:36,294 - Batch [3300/8699], Train Loss: 0.13751061588035415, Train Acc: 0.9735416666666666
2024-04-29 09:40:41,077 - Batch [3400/8699], Train Loss: 0.13530627983995466, Train Acc: 0.9737545955882353
2024-04-29 09:40:45,866 - Batch [3500/8699], Train Loss: 0.1327139632320364, Train Acc: 0.9740848214285714
2024-04-29 09:40:50,686 - Batch [3600/8699], Train Loss: 0.13050601088354596, Train Acc: 0.9743446180555555
2024-04-29 09:40:55,498 - Batch [3700/8699], Train Loss: 0.1282911486444504, Train Acc: 0.9745988175675676
2024-04-29 09:41:00,318 - Batch [3800/8699], Train Loss: 0.12613297358476924, Train Acc: 0.9749177631578947
2024-04-29 09:41:05,139 - Batch [3900/8699], Train Loss: 0.12396180006953028, Train Acc: 0.9752283653846154
2024-04-29 09:41:09,962 - Batch [4000/8699], Train Loss: 0.17965159719382062, Train Acc: 0.97165625
2024-04-29 09:41:14,788 - Batch [4100/8699], Train Loss: 0.18038584302148283, Train Acc: 0.9708498475609756
2024-04-29 09:41:19,613 - Batch [4200/8699], Train Loss: 0.1796873840067946, Train Acc: 0.9703422619047619
2024-04-29 09:41:24,448 - Batch [4300/8699], Train Loss: 0.17849946357431648, Train Acc: 0.9700908430232558
2024-04-29 09:41:29,284 - Batch [4400/8699], Train Loss: 0.17744428680312757, Train Acc: 0.9699928977272727
2024-04-29 09:41:34,122 - Batch [4500/8699], Train Loss: 0.17598305671426676, Train Acc: 0.9698263888888888
2024-04-29 09:41:38,959 - Batch [4600/8699], Train Loss: 0.17417105888818776, Train Acc: 0.9698505434782608
2024-04-29 09:41:43,801 - Batch [4700/8699], Train Loss: 0.17245418806899676, Train Acc: 0.9698304521276596
2024-04-29 09:41:48,642 - Batch [4800/8699], Train Loss: 0.17032395047118673, Train Acc: 0.9700032552083333
2024-04-29 09:41:53,479 - Batch [4900/8699], Train Loss: 0.16910451761468276, Train Acc: 0.9699776785714286
2024-04-29 09:41:58,317 - Batch [5000/8699], Train Loss: 0.16689097441027406, Train Acc: 0.97019375
2024-04-29 09:42:03,147 - Batch [5100/8699], Train Loss: 0.1649397306193771, Train Acc: 0.970327818627451
2024-04-29 09:42:07,982 - Batch [5200/8699], Train Loss: 0.1629596957682784, Train Acc: 0.9704897836538462
2024-04-29 09:42:12,815 - Batch [5300/8699], Train Loss: 0.1609537138017817, Train Acc: 0.9707016509433962
2024-04-29 09:42:17,634 - Batch [5400/8699], Train Loss: 0.15899385265223423, Train Acc: 0.9709085648148148
2024-04-29 09:42:22,453 - Batch [5500/8699], Train Loss: 0.15704248203034513, Train Acc: 0.9711363636363637
2024-04-29 09:42:27,275 - Batch [5600/8699], Train Loss: 0.15523691516421553, Train Acc: 0.9713113839285714
2024-04-29 09:42:32,098 - Batch [5700/8699], Train Loss: 0.15348731888786954, Train Acc: 0.9715515350877193
2024-04-29 09:42:36,909 - Batch [5800/8699], Train Loss: 0.15181987482663004, Train Acc: 0.9717780172413794
2024-04-29 09:42:41,714 - Batch [5900/8699], Train Loss: 0.15010095800961748, Train Acc: 0.9719623940677966
2024-04-29 09:42:46,514 - Batch [6000/8699], Train Loss: 0.14825945831716913, Train Acc: 0.9722395833333334
2024-04-29 09:42:51,343 - Batch [6100/8699], Train Loss: 0.14652403242922327, Train Acc: 0.9725
2024-04-29 09:42:56,175 - Batch [6200/8699], Train Loss: 0.14490376300597188, Train Acc: 0.9727242943548388
2024-04-29 09:43:01,020 - Batch [6300/8699], Train Loss: 0.14318884987511582, Train Acc: 0.9729885912698413
2024-04-29 09:43:05,872 - Batch [6400/8699], Train Loss: 0.1421133835004548, Train Acc: 0.97305908203125
2024-04-29 09:43:10,710 - Batch [6500/8699], Train Loss: 0.14086950007516247, Train Acc: 0.9731682692307693
2024-04-29 09:43:15,548 - Batch [6600/8699], Train Loss: 0.1393189939025218, Train Acc: 0.9734019886363636
2024-04-29 09:43:20,388 - Batch [6700/8699], Train Loss: 0.1378266697795888, Train Acc: 0.9736194029850747
2024-04-29 09:43:25,243 - Batch [6800/8699], Train Loss: 0.1362820002072155, Train Acc: 0.9738419117647059
2024-04-29 09:43:30,095 - Batch [6900/8699], Train Loss: 0.13510593806654958, Train Acc: 0.973978713768116
2024-04-29 09:43:34,952 - Batch [7000/8699], Train Loss: 0.13379198332302206, Train Acc: 0.9741473214285714
2024-04-29 09:43:39,806 - Batch [7100/8699], Train Loss: 0.1325719679293098, Train Acc: 0.9743177816901408
2024-04-29 09:43:44,663 - Batch [7200/8699], Train Loss: 0.1312080981508512, Train Acc: 0.9745399305555555
2024-04-29 09:43:49,513 - Batch [7300/8699], Train Loss: 0.12993188448736687, Train Acc: 0.9747217465753425
2024-04-29 09:43:54,367 - Batch [7400/8699], Train Loss: 0.12862613884588966, Train Acc: 0.9749282094594595
2024-04-29 09:43:59,218 - Batch [7500/8699], Train Loss: 0.12729790891841986, Train Acc: 0.9751208333333333
2024-04-29 09:44:04,074 - Batch [7600/8699], Train Loss: 0.12630180666641344, Train Acc: 0.9752405427631579
2024-04-29 09:44:08,930 - Batch [7700/8699], Train Loss: 0.12526075477108614, Train Acc: 0.975367288961039
2024-04-29 09:44:14,147 - Batch [7800/8699], Train Loss: 0.12405419608522864, Train Acc: 0.9755689102564102
2024-04-29 09:44:19,057 - Batch [7900/8699], Train Loss: 0.12299490453598762, Train Acc: 0.9757575158227848
2024-04-29 09:44:23,879 - Batch [8000/8699], Train Loss: 0.12343486372608459, Train Acc: 0.975515625
2024-04-29 09:44:28,706 - Batch [8100/8699], Train Loss: 0.12356887597185387, Train Acc: 0.9754591049382716
2024-04-29 09:44:33,535 - Batch [8200/8699], Train Loss: 0.1225471274127116, Train Acc: 0.9756288109756097
2024-04-29 09:44:38,363 - Batch [8300/8699], Train Loss: 0.12143930656257568, Train Acc: 0.9758207831325301
2024-04-29 09:44:43,190 - Batch [8400/8699], Train Loss: 0.12033760664635337, Train Acc: 0.976000744047619
2024-04-29 09:44:48,050 - Batch [8500/8699], Train Loss: 0.11935273997365113, Train Acc: 0.9761507352941177
2024-04-29 09:44:52,910 - Batch [8600/8699], Train Loss: 0.11832546656393597, Train Acc: 0.9763063226744186
2024-04-29 09:44:58,327 - Train Loss: 0.11811197176291949, Train Acc: 0.9762844003736437
2024-04-29 09:46:37,700 - Test Acc: 0.9385360455842093
2024-04-29 09:46:37,754 - Confusion Matrix:
 [[67493    63]
 [ 8491 63124]]
2024-04-29 09:46:37,758 - Epoch time: 532.0896158218384 seconds.
2024-04-29 09:46:37,758 - Epoch 5/5
2024-04-29 09:46:57,983 - Batch [100/8699], Train Loss: 0.06503216722980142, Train Acc: 0.9778125
2024-04-29 09:47:02,533 - Batch [200/8699], Train Loss: 0.06258708686567843, Train Acc: 0.979296875
2024-04-29 09:47:07,113 - Batch [300/8699], Train Loss: 0.0566161600779742, Train Acc: 0.9816666666666667
2024-04-29 09:47:11,714 - Batch [400/8699], Train Loss: 0.05214702403114643, Train Acc: 0.9836328125
2024-04-29 09:47:16,325 - Batch [500/8699], Train Loss: 0.05148751094099134, Train Acc: 0.9835
2024-04-29 09:47:20,951 - Batch [600/8699], Train Loss: 0.0694461955029207, Train Acc: 0.9793229166666667
2024-04-29 09:47:25,596 - Batch [700/8699], Train Loss: 0.08116855942843748, Train Acc: 0.9767410714285715
2024-04-29 09:47:30,251 - Batch [800/8699], Train Loss: 0.07758412415743805, Train Acc: 0.97744140625
2024-04-29 09:47:34,916 - Batch [900/8699], Train Loss: 0.07505076901107613, Train Acc: 0.9782118055555555
2024-04-29 09:47:39,600 - Batch [1000/8699], Train Loss: 0.07170305194612593, Train Acc: 0.979109375
2024-04-29 09:47:44,285 - Batch [1100/8699], Train Loss: 0.0681304997804744, Train Acc: 0.9799431818181819
2024-04-29 09:47:48,975 - Batch [1200/8699], Train Loss: 0.06603259046853055, Train Acc: 0.9803385416666667
2024-04-29 09:47:53,674 - Batch [1300/8699], Train Loss: 0.06485956854598883, Train Acc: 0.9807572115384615
2024-04-29 09:47:58,373 - Batch [1400/8699], Train Loss: 0.06314509934213544, Train Acc: 0.9811830357142857
2024-04-29 09:48:03,073 - Batch [1500/8699], Train Loss: 0.061915527135599405, Train Acc: 0.98159375
2024-04-29 09:48:07,766 - Batch [1600/8699], Train Loss: 0.060027100973238705, Train Acc: 0.982197265625
2024-04-29 09:48:12,529 - Batch [1700/8699], Train Loss: 0.05929048981065588, Train Acc: 0.982454044117647
2024-04-29 09:48:17,268 - Batch [1800/8699], Train Loss: 0.05863715340616182, Train Acc: 0.9826996527777778
2024-04-29 09:48:22,050 - Batch [1900/8699], Train Loss: 0.05751252457340199, Train Acc: 0.982952302631579
2024-04-29 09:48:26,818 - Batch [2000/8699], Train Loss: 0.06061942757142242, Train Acc: 0.982125
2024-04-29 09:48:31,704 - Batch [2100/8699], Train Loss: 0.07209720594575629, Train Acc: 0.9799627976190476
2024-04-29 09:48:36,485 - Batch [2200/8699], Train Loss: 0.07367666992983272, Train Acc: 0.9794389204545455
2024-04-29 09:48:41,268 - Batch [2300/8699], Train Loss: 0.07418812602991239, Train Acc: 0.9791372282608696
2024-04-29 09:48:46,052 - Batch [2400/8699], Train Loss: 0.07443455124691051, Train Acc: 0.97892578125
2024-04-29 09:48:50,834 - Batch [2500/8699], Train Loss: 0.07340456844633444, Train Acc: 0.979075
2024-04-29 09:48:55,613 - Batch [2600/8699], Train Loss: 0.07243012404427505, Train Acc: 0.9792908653846154
2024-04-29 09:49:00,391 - Batch [2700/8699], Train Loss: 0.07163299106854808, Train Acc: 0.9794444444444445
2024-04-29 09:49:05,168 - Batch [2800/8699], Train Loss: 0.07106380229982148, Train Acc: 0.9795703125
2024-04-29 09:49:09,952 - Batch [2900/8699], Train Loss: 0.0696421424988336, Train Acc: 0.9798922413793103
2024-04-29 09:49:14,731 - Batch [3000/8699], Train Loss: 0.0686596214491874, Train Acc: 0.9801927083333334
2024-04-29 09:49:19,508 - Batch [3100/8699], Train Loss: 0.06800615592953568, Train Acc: 0.9803931451612903
2024-04-29 09:49:24,298 - Batch [3200/8699], Train Loss: 0.06798418490539916, Train Acc: 0.9805615234375
2024-04-29 09:49:29,075 - Batch [3300/8699], Train Loss: 0.06739659192876636, Train Acc: 0.9806534090909091
2024-04-29 09:49:33,853 - Batch [3400/8699], Train Loss: 0.06759427731695777, Train Acc: 0.9806939338235294
2024-04-29 09:49:38,631 - Batch [3500/8699], Train Loss: 0.06734194044559262, Train Acc: 0.9807410714285715
2024-04-29 09:49:43,448 - Batch [3600/8699], Train Loss: 0.06673260882189627, Train Acc: 0.9808767361111111
2024-04-29 09:49:48,255 - Batch [3700/8699], Train Loss: 0.06583382706651841, Train Acc: 0.9811486486486487
2024-04-29 09:49:53,041 - Batch [3800/8699], Train Loss: 0.06488092854576136, Train Acc: 0.9814268092105263
2024-04-29 09:49:57,853 - Batch [3900/8699], Train Loss: 0.06410764450120787, Train Acc: 0.9816346153846154
2024-04-29 09:50:02,674 - Batch [4000/8699], Train Loss: 0.06347675012768013, Train Acc: 0.9817734375
2024-04-29 09:50:07,458 - Batch [4100/8699], Train Loss: 0.06274457141595166, Train Acc: 0.9819626524390244
2024-04-29 09:50:12,278 - Batch [4200/8699], Train Loss: 0.062085974973133055, Train Acc: 0.9821875
2024-04-29 09:50:17,095 - Batch [4300/8699], Train Loss: 0.06132842012603908, Train Acc: 0.9823728197674418
2024-04-29 09:50:21,894 - Batch [4400/8699], Train Loss: 0.060607124615172245, Train Acc: 0.9825532670454545
2024-04-29 09:50:26,681 - Batch [4500/8699], Train Loss: 0.059983387260814196, Train Acc: 0.9827118055555556
2024-04-29 09:50:31,511 - Batch [4600/8699], Train Loss: 0.0594875356533347, Train Acc: 0.9828600543478261
2024-04-29 09:50:36,406 - Batch [4700/8699], Train Loss: 0.05897430840633225, Train Acc: 0.9829787234042553
2024-04-29 09:50:41,209 - Batch [4800/8699], Train Loss: 0.05856173801508703, Train Acc: 0.9830794270833333
2024-04-29 09:50:46,040 - Batch [4900/8699], Train Loss: 0.05798715922849643, Train Acc: 0.9832302295918367
2024-04-29 09:50:50,847 - Batch [5000/8699], Train Loss: 0.05741371146797901, Train Acc: 0.983378125
2024-04-29 09:50:55,690 - Batch [5100/8699], Train Loss: 0.05693778524285995, Train Acc: 0.9835110294117647
2024-04-29 09:51:00,476 - Batch [5200/8699], Train Loss: 0.057126928372051154, Train Acc: 0.9834284855769231
2024-04-29 09:51:05,283 - Batch [5300/8699], Train Loss: 0.05719411649970768, Train Acc: 0.9834817216981132
2024-04-29 09:51:10,097 - Batch [5400/8699], Train Loss: 0.05716769517081385, Train Acc: 0.983509837962963
2024-04-29 09:51:14,933 - Batch [5500/8699], Train Loss: 0.05710879884927999, Train Acc: 0.9835482954545455
2024-04-29 09:51:19,768 - Batch [5600/8699], Train Loss: 0.0568550488708362, Train Acc: 0.9835993303571429
2024-04-29 09:51:24,576 - Batch [5700/8699], Train Loss: 0.056718708211443744, Train Acc: 0.9836595394736842
2024-04-29 09:51:29,399 - Batch [5800/8699], Train Loss: 0.056275883713618705, Train Acc: 0.9837742456896552
2024-04-29 09:51:34,354 - Batch [5900/8699], Train Loss: 0.05603011422862607, Train Acc: 0.983885063559322
2024-04-29 09:51:39,309 - Batch [6000/8699], Train Loss: 0.055648027658937886, Train Acc: 0.9840052083333334
2024-04-29 09:51:44,159 - Batch [6100/8699], Train Loss: 0.05568972846551332, Train Acc: 0.9840701844262295
2024-04-29 09:51:48,994 - Batch [6200/8699], Train Loss: 0.05571892426299464, Train Acc: 0.9840725806451613
2024-04-29 09:51:53,811 - Batch [6300/8699], Train Loss: 0.0555915642578602, Train Acc: 0.9841170634920635
2024-04-29 09:51:58,692 - Batch [6400/8699], Train Loss: 0.05525254055993173, Train Acc: 0.98421630859375
2024-04-29 09:52:03,529 - Batch [6500/8699], Train Loss: 0.055047341685715276, Train Acc: 0.9843028846153846
2024-04-29 09:52:08,364 - Batch [6600/8699], Train Loss: 0.05459614029376429, Train Acc: 0.9844223484848484
2024-04-29 09:52:13,176 - Batch [6700/8699], Train Loss: 0.05449952201240126, Train Acc: 0.9844682835820896
2024-04-29 09:52:18,027 - Batch [6800/8699], Train Loss: 0.05417690960932626, Train Acc: 0.9845473345588235
2024-04-29 09:52:22,879 - Batch [6900/8699], Train Loss: 0.054001219443060744, Train Acc: 0.9845946557971015
2024-04-29 09:52:27,726 - Batch [7000/8699], Train Loss: 0.054112384470853224, Train Acc: 0.9845089285714286
2024-04-29 09:52:32,586 - Batch [7100/8699], Train Loss: 0.05426909352296104, Train Acc: 0.9844432218309859
2024-04-29 09:52:37,468 - Batch [7200/8699], Train Loss: 0.054031517678821625, Train Acc: 0.9844791666666667
2024-04-29 09:52:42,325 - Batch [7300/8699], Train Loss: 0.053900076490659456, Train Acc: 0.9845505136986301
2024-04-29 09:52:47,264 - Batch [7400/8699], Train Loss: 0.05390958461893968, Train Acc: 0.9845164695945946
2024-04-29 09:52:52,118 - Batch [7500/8699], Train Loss: 0.05376549626265187, Train Acc: 0.9845354166666667
2024-04-29 09:52:56,985 - Batch [7600/8699], Train Loss: 0.053600540057821874, Train Acc: 0.9845908717105263
2024-04-29 09:53:01,869 - Batch [7700/8699], Train Loss: 0.05334872453921027, Train Acc: 0.9846469155844156
2024-04-29 09:53:06,759 - Batch [7800/8699], Train Loss: 0.05308039089148411, Train Acc: 0.984707532051282
2024-04-29 09:53:11,663 - Batch [7900/8699], Train Loss: 0.05277129678314263, Train Acc: 0.9847903481012659
2024-04-29 09:53:16,519 - Batch [8000/8699], Train Loss: 0.05394589527522476, Train Acc: 0.98458203125
2024-04-29 09:53:21,399 - Batch [8100/8699], Train Loss: 0.0541373420835625, Train Acc: 0.9844965277777777
2024-04-29 09:53:26,310 - Batch [8200/8699], Train Loss: 0.05395866421054873, Train Acc: 0.9845407774390244
2024-04-29 09:53:31,256 - Batch [8300/8699], Train Loss: 0.05366174127615522, Train Acc: 0.9846065512048193
2024-04-29 09:53:36,639 - Batch [8400/8699], Train Loss: 0.053592887186685055, Train Acc: 0.9846279761904762
2024-04-29 09:53:41,733 - Batch [8500/8699], Train Loss: 0.05333449200749644, Train Acc: 0.9847003676470588
2024-04-29 09:53:47,054 - Batch [8600/8699], Train Loss: 0.05313093247390921, Train Acc: 0.9847529069767442
2024-04-29 09:53:53,996 - Train Loss: 0.052828533744061504, Train Acc: 0.984838686498527
2024-04-29 09:56:08,922 - Test Acc: 0.9941870073506693
2024-04-29 09:56:08,981 - Confusion Matrix:
 [[67407   149]
 [  660 70955]]
2024-04-29 09:56:08,984 - Epoch time: 571.2261455059052 seconds.
2024-04-29 09:56:08,984 - Best Train Acc: 0.9880954947186894
2024-04-29 09:56:08,985 - Total training time: 2693.05934882164 seconds.
