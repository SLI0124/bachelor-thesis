2024-04-29 14:24:07,245 - Training the model...
2024-04-29 14:24:07,245 - Epoch 1/5
2024-04-29 14:24:37,559 - Batch [100/8699], Train Loss: 0.7895485401898622, Train Acc: 0.691875
2024-04-29 14:24:50,122 - Batch [200/8699], Train Loss: 0.4713092495687306, Train Acc: 0.815078125
2024-04-29 14:25:03,549 - Batch [300/8699], Train Loss: 0.3517758896822731, Train Acc: 0.8639583333333334
2024-04-29 14:25:16,865 - Batch [400/8699], Train Loss: 0.2859287748672068, Train Acc: 0.890859375
2024-04-29 14:25:30,498 - Batch [500/8699], Train Loss: 0.24764757366664708, Train Acc: 0.90615625
2024-04-29 14:25:43,853 - Batch [600/8699], Train Loss: 0.2160561231818671, Train Acc: 0.918828125
2024-04-29 14:25:58,097 - Batch [700/8699], Train Loss: 0.19589065139314957, Train Acc: 0.9269866071428572
2024-04-29 14:26:11,694 - Batch [800/8699], Train Loss: 0.1774087296728976, Train Acc: 0.934296875
2024-04-29 14:26:26,068 - Batch [900/8699], Train Loss: 0.1638680889536368, Train Acc: 0.9395486111111111
2024-04-29 14:26:39,736 - Batch [1000/8699], Train Loss: 0.15298207652347628, Train Acc: 0.943921875
2024-04-29 14:26:54,230 - Batch [1100/8699], Train Loss: 0.14272590901205232, Train Acc: 0.9480255681818182
2024-04-29 14:27:08,050 - Batch [1200/8699], Train Loss: 0.1348282569925262, Train Acc: 0.9509375
2024-04-29 14:27:22,299 - Batch [1300/8699], Train Loss: 0.12726054745394952, Train Acc: 0.95390625
2024-04-29 14:27:36,363 - Batch [1400/8699], Train Loss: 0.12115409614759431, Train Acc: 0.9561941964285714
2024-04-29 14:27:50,124 - Batch [1500/8699], Train Loss: 0.1153883119020611, Train Acc: 0.9583854166666667
2024-04-29 14:28:04,413 - Batch [1600/8699], Train Loss: 0.11052275162802289, Train Acc: 0.9602734375
2024-04-29 14:28:18,023 - Batch [1700/8699], Train Loss: 0.10654920282829314, Train Acc: 0.9619117647058824
2024-04-29 14:28:31,648 - Batch [1800/8699], Train Loss: 0.10265650295239337, Train Acc: 0.9635069444444444
2024-04-29 14:28:45,394 - Batch [1900/8699], Train Loss: 0.09925250893226659, Train Acc: 0.9647532894736842
2024-04-29 14:28:59,891 - Batch [2000/8699], Train Loss: 0.09558312850524817, Train Acc: 0.96615625
2024-04-29 14:29:13,744 - Batch [2100/8699], Train Loss: 0.09262468615462283, Train Acc: 0.9671800595238095
2024-04-29 14:29:28,320 - Batch [2200/8699], Train Loss: 0.08954826911502592, Train Acc: 0.9682883522727272
2024-04-29 14:29:42,237 - Batch [2300/8699], Train Loss: 0.08717692733584123, Train Acc: 0.96921875
2024-04-29 14:29:56,841 - Batch [2400/8699], Train Loss: 0.08541240328492374, Train Acc: 0.9698307291666667
2024-04-29 14:30:10,749 - Batch [2500/8699], Train Loss: 0.08405902111238102, Train Acc: 0.9703625
2024-04-29 14:30:24,585 - Batch [2600/8699], Train Loss: 0.0824333768568445, Train Acc: 0.971015625
2024-04-29 14:30:38,474 - Batch [2700/8699], Train Loss: 0.08062718417578489, Train Acc: 0.9717418981481482
2024-04-29 14:30:52,322 - Batch [2800/8699], Train Loss: 0.07891939937705632, Train Acc: 0.9724330357142857
2024-04-29 14:31:06,207 - Batch [2900/8699], Train Loss: 0.07727341983739311, Train Acc: 0.9730765086206896
2024-04-29 14:31:20,130 - Batch [3000/8699], Train Loss: 0.07561783004946968, Train Acc: 0.973703125
2024-04-29 14:31:34,594 - Batch [3100/8699], Train Loss: 0.07396372854493694, Train Acc: 0.9742741935483871
2024-04-29 14:31:48,448 - Batch [3200/8699], Train Loss: 0.07252607096918837, Train Acc: 0.9748095703125
2024-04-29 14:32:02,973 - Batch [3300/8699], Train Loss: 0.07163775053453829, Train Acc: 0.9752225378787879
2024-04-29 14:32:16,807 - Batch [3400/8699], Train Loss: 0.07031175899659609, Train Acc: 0.9757077205882353
2024-04-29 14:32:30,608 - Batch [3500/8699], Train Loss: 0.06909904057866412, Train Acc: 0.9761383928571429
2024-04-29 14:32:44,405 - Batch [3600/8699], Train Loss: 0.06778023613242921, Train Acc: 0.9766059027777778
2024-04-29 14:32:58,090 - Batch [3700/8699], Train Loss: 0.06663780258417859, Train Acc: 0.977043918918919
2024-04-29 14:33:11,754 - Batch [3800/8699], Train Loss: 0.06580377801869824, Train Acc: 0.9773972039473684
2024-04-29 14:33:26,251 - Batch [3900/8699], Train Loss: 0.06485074717517889, Train Acc: 0.9777644230769231
2024-04-29 14:33:40,031 - Batch [4000/8699], Train Loss: 0.06380078086880167, Train Acc: 0.97818359375
2024-04-29 14:33:54,486 - Batch [4100/8699], Train Loss: 0.0633841075283999, Train Acc: 0.9784146341463414
2024-04-29 14:34:08,270 - Batch [4200/8699], Train Loss: 0.06262574394347514, Train Acc: 0.9787165178571429
2024-04-29 14:34:22,011 - Batch [4300/8699], Train Loss: 0.06175123402391702, Train Acc: 0.9790552325581395
2024-04-29 14:34:35,832 - Batch [4400/8699], Train Loss: 0.06114376740404189, Train Acc: 0.9793004261363636
2024-04-29 14:34:49,694 - Batch [4500/8699], Train Loss: 0.06041264633265604, Train Acc: 0.9795833333333334
2024-04-29 14:35:04,184 - Batch [4600/8699], Train Loss: 0.059711265577406976, Train Acc: 0.9798471467391304
2024-04-29 14:35:18,007 - Batch [4700/8699], Train Loss: 0.059050286828086954, Train Acc: 0.9800864361702127
2024-04-29 14:35:31,750 - Batch [4800/8699], Train Loss: 0.05842266253356437, Train Acc: 0.9803450520833333
2024-04-29 14:35:45,501 - Batch [4900/8699], Train Loss: 0.057921637529822635, Train Acc: 0.9805133928571429
2024-04-29 14:35:59,936 - Batch [5000/8699], Train Loss: 0.06720049837411553, Train Acc: 0.97929375
2024-04-29 14:36:13,649 - Batch [5100/8699], Train Loss: 0.06727109266100985, Train Acc: 0.979249387254902
2024-04-29 14:36:28,004 - Batch [5200/8699], Train Loss: 0.06697421545608921, Train Acc: 0.9793569711538461
2024-04-29 14:36:41,671 - Batch [5300/8699], Train Loss: 0.0666497089084131, Train Acc: 0.9794634433962264
2024-04-29 14:36:56,108 - Batch [5400/8699], Train Loss: 0.06646610856175374, Train Acc: 0.9795052083333333
2024-04-29 14:37:09,835 - Batch [5500/8699], Train Loss: 0.0659659695714897, Train Acc: 0.9796647727272727
2024-04-29 14:37:23,981 - Batch [5600/8699], Train Loss: 0.06548235780620335, Train Acc: 0.9798214285714286
2024-04-29 14:37:38,686 - Batch [5700/8699], Train Loss: 0.0648700789318439, Train Acc: 0.9800109649122807
2024-04-29 14:37:53,590 - Batch [5800/8699], Train Loss: 0.06432575457435899, Train Acc: 0.9801697198275862
2024-04-29 14:38:07,986 - Batch [5900/8699], Train Loss: 0.06384752950642474, Train Acc: 0.9803151483050847
2024-04-29 14:38:22,436 - Batch [6000/8699], Train Loss: 0.06329303783402959, Train Acc: 0.9804765625
2024-04-29 14:38:37,861 - Batch [6100/8699], Train Loss: 0.06277542250098793, Train Acc: 0.9806685450819672
2024-04-29 14:38:52,372 - Batch [6200/8699], Train Loss: 0.062242435705064554, Train Acc: 0.9808492943548387
2024-04-29 14:39:06,139 - Batch [6300/8699], Train Loss: 0.061633494555874836, Train Acc: 0.9810292658730159
2024-04-29 14:39:20,560 - Batch [6400/8699], Train Loss: 0.06115454085607823, Train Acc: 0.981142578125
2024-04-29 14:39:34,472 - Batch [6500/8699], Train Loss: 0.06063027478915753, Train Acc: 0.9813052884615384
2024-04-29 14:39:49,317 - Batch [6600/8699], Train Loss: 0.060056850714799055, Train Acc: 0.981484375
2024-04-29 14:40:02,427 - Batch [6700/8699], Train Loss: 0.05956003265625251, Train Acc: 0.9816487873134329
2024-04-29 14:40:16,924 - Batch [6800/8699], Train Loss: 0.0590565816306912, Train Acc: 0.9818106617647059
2024-04-29 14:40:31,845 - Batch [6900/8699], Train Loss: 0.05860464167391054, Train Acc: 0.9819474637681159
2024-04-29 14:40:45,502 - Batch [7000/8699], Train Loss: 0.058237267909975216, Train Acc: 0.9820803571428571
2024-04-29 14:40:59,762 - Batch [7100/8699], Train Loss: 0.05781144223814216, Train Acc: 0.982231514084507
2024-04-29 14:41:12,965 - Batch [7200/8699], Train Loss: 0.05731404158772661, Train Acc: 0.9823676215277778
2024-04-29 14:41:27,739 - Batch [7300/8699], Train Loss: 0.05691362707570315, Train Acc: 0.9824828767123288
2024-04-29 14:41:40,571 - Batch [7400/8699], Train Loss: 0.05651655786939598, Train Acc: 0.9826161317567568
2024-04-29 14:41:53,621 - Batch [7500/8699], Train Loss: 0.056150473292399326, Train Acc: 0.9827541666666667
2024-04-29 14:42:06,425 - Batch [7600/8699], Train Loss: 0.055801065006781204, Train Acc: 0.9828474506578947
2024-04-29 14:42:19,195 - Batch [7700/8699], Train Loss: 0.055415091687145125, Train Acc: 0.9829565746753247
2024-04-29 14:42:32,057 - Batch [7800/8699], Train Loss: 0.05501750192810773, Train Acc: 0.9830969551282052
2024-04-29 14:42:45,014 - Batch [7900/8699], Train Loss: 0.05460144557850175, Train Acc: 0.9832377373417721
2024-04-29 14:42:58,643 - Batch [8000/8699], Train Loss: 0.05426238481849884, Train Acc: 0.983333984375
2024-04-29 14:43:11,478 - Batch [8100/8699], Train Loss: 0.053807748193684245, Train Acc: 0.9834837962962963
2024-04-29 14:43:24,309 - Batch [8200/8699], Train Loss: 0.053516172991162424, Train Acc: 0.9835823170731708
2024-04-29 14:43:37,078 - Batch [8300/8699], Train Loss: 0.0531095056894145, Train Acc: 0.9836935240963856
2024-04-29 14:43:49,904 - Batch [8400/8699], Train Loss: 0.05272424256833877, Train Acc: 0.9838188244047619
2024-04-29 14:44:03,573 - Batch [8500/8699], Train Loss: 0.052361570888463736, Train Acc: 0.9839393382352941
2024-04-29 14:44:16,418 - Batch [8600/8699], Train Loss: 0.052200498077941755, Train Acc: 0.9839789244186047
2024-04-29 14:44:29,836 - Train Loss: 0.05198671313327603, Train Acc: 0.9840321189911619
2024-04-29 14:46:31,702 - Test Acc: 0.9947618397510976
2024-04-29 14:46:31,757 - Confusion Matrix:
 [[67250   306]
 [  423 71192]]
2024-04-29 14:46:31,775 - Saved the new best model to ../data/models/pklot/all/80_20/squeezenet.pth
2024-04-29 14:46:31,775 - Epoch time: 1344.529854297638 seconds.
2024-04-29 14:46:31,775 - Epoch 2/5
2024-04-29 14:47:01,181 - Batch [100/8699], Train Loss: 0.02514709296694491, Train Acc: 0.9928125
2024-04-29 14:47:13,472 - Batch [200/8699], Train Loss: 0.022194801558944165, Train Acc: 0.993203125
2024-04-29 14:47:26,811 - Batch [300/8699], Train Loss: 0.02489059282660795, Train Acc: 0.9920833333333333
2024-04-29 14:47:39,447 - Batch [400/8699], Train Loss: 0.02597721551542236, Train Acc: 0.9922265625
2024-04-29 14:47:52,842 - Batch [500/8699], Train Loss: 0.02803387151312927, Train Acc: 0.99196875
2024-04-29 14:48:05,861 - Batch [600/8699], Train Loss: 0.027658685401286978, Train Acc: 0.9920052083333334
2024-04-29 14:48:18,784 - Batch [700/8699], Train Loss: 0.026620629990050344, Train Acc: 0.9922767857142857
2024-04-29 14:48:31,672 - Batch [800/8699], Train Loss: 0.027742394415276976, Train Acc: 0.99212890625
2024-04-29 14:48:44,686 - Batch [900/8699], Train Loss: 0.027414585089512306, Train Acc: 0.9922916666666667
2024-04-29 14:48:58,567 - Batch [1000/8699], Train Loss: 0.027070532001500395, Train Acc: 0.99234375
2024-04-29 14:49:13,452 - Batch [1100/8699], Train Loss: 0.02590772106741166, Train Acc: 0.9925994318181818
2024-04-29 14:49:28,895 - Batch [1200/8699], Train Loss: 0.025201057627821988, Train Acc: 0.992734375
2024-04-29 14:49:44,130 - Batch [1300/8699], Train Loss: 0.02506204029314876, Train Acc: 0.9927884615384616
2024-04-29 14:49:59,479 - Batch [1400/8699], Train Loss: 0.02508546773334144, Train Acc: 0.9928013392857142
2024-04-29 14:50:14,567 - Batch [1500/8699], Train Loss: 0.025166646618422724, Train Acc: 0.9927291666666667
2024-04-29 14:50:30,296 - Batch [1600/8699], Train Loss: 0.025112707976220464, Train Acc: 0.992724609375
2024-04-29 14:50:45,748 - Batch [1700/8699], Train Loss: 0.025160021556167683, Train Acc: 0.9926930147058823
2024-04-29 14:51:01,338 - Batch [1800/8699], Train Loss: 0.025365906004240563, Train Acc: 0.992578125
2024-04-29 14:51:16,334 - Batch [1900/8699], Train Loss: 0.025387883018263797, Train Acc: 0.9925082236842105
2024-04-29 14:51:31,631 - Batch [2000/8699], Train Loss: 0.025417011061703305, Train Acc: 0.992609375
2024-04-29 14:51:46,611 - Batch [2100/8699], Train Loss: 0.025126650568156383, Train Acc: 0.992641369047619
2024-04-29 14:52:01,809 - Batch [2200/8699], Train Loss: 0.024866904855065184, Train Acc: 0.9926988636363636
2024-04-29 14:52:16,370 - Batch [2300/8699], Train Loss: 0.02452926690931275, Train Acc: 0.9928125
2024-04-29 14:52:31,485 - Batch [2400/8699], Train Loss: 0.02450979439253994, Train Acc: 0.99283203125
2024-04-29 14:52:46,321 - Batch [2500/8699], Train Loss: 0.024430422112191444, Train Acc: 0.9928625
2024-04-29 14:53:01,710 - Batch [2600/8699], Train Loss: 0.024073751421979418, Train Acc: 0.9929507211538462
2024-04-29 14:53:16,753 - Batch [2700/8699], Train Loss: 0.023996528418394048, Train Acc: 0.9930150462962963
2024-04-29 14:53:32,215 - Batch [2800/8699], Train Loss: 0.024144937934818568, Train Acc: 0.9929185267857142
2024-04-29 14:53:47,342 - Batch [2900/8699], Train Loss: 0.02410082560494253, Train Acc: 0.9929741379310345
2024-04-29 14:54:02,751 - Batch [3000/8699], Train Loss: 0.024049344971300644, Train Acc: 0.993015625
2024-04-29 14:54:17,574 - Batch [3100/8699], Train Loss: 0.024056414315958636, Train Acc: 0.9929989919354839
2024-04-29 14:54:32,832 - Batch [3200/8699], Train Loss: 0.023912271691660863, Train Acc: 0.9930322265625
2024-04-29 14:54:47,868 - Batch [3300/8699], Train Loss: 0.023742996581281522, Train Acc: 0.993091856060606
2024-04-29 14:55:03,308 - Batch [3400/8699], Train Loss: 0.023710323910079965, Train Acc: 0.9930836397058823
2024-04-29 14:55:18,482 - Batch [3500/8699], Train Loss: 0.023543039205530865, Train Acc: 0.993125
2024-04-29 14:55:33,864 - Batch [3600/8699], Train Loss: 0.023374502504667462, Train Acc: 0.9931727430555556
2024-04-29 14:55:48,665 - Batch [3700/8699], Train Loss: 0.02335685810377539, Train Acc: 0.9931798986486486
2024-04-29 14:56:03,908 - Batch [3800/8699], Train Loss: 0.023244418080992448, Train Acc: 0.9932195723684211
2024-04-29 14:56:19,003 - Batch [3900/8699], Train Loss: 0.02308199636746278, Train Acc: 0.9932371794871795
2024-04-29 14:56:34,481 - Batch [4000/8699], Train Loss: 0.023137440282748684, Train Acc: 0.9931953125
2024-04-29 14:56:49,673 - Batch [4100/8699], Train Loss: 0.023046610917364176, Train Acc: 0.9932202743902439
2024-04-29 14:57:05,413 - Batch [4200/8699], Train Loss: 0.022917287319598384, Train Acc: 0.9932775297619048
2024-04-29 14:57:21,234 - Batch [4300/8699], Train Loss: 0.02322163409397712, Train Acc: 0.9931468023255814
2024-04-29 14:57:37,022 - Batch [4400/8699], Train Loss: 0.023218526906579096, Train Acc: 0.9931463068181818
2024-04-29 14:57:52,752 - Batch [4500/8699], Train Loss: 0.023154753050059502, Train Acc: 0.9931354166666667
2024-04-29 14:58:08,285 - Batch [4600/8699], Train Loss: 0.023213199258219033, Train Acc: 0.9931419836956522
2024-04-29 14:58:23,712 - Batch [4700/8699], Train Loss: 0.02318725945076678, Train Acc: 0.9931482712765958
2024-04-29 14:58:38,778 - Batch [4800/8699], Train Loss: 0.02327835889632979, Train Acc: 0.9931217447916667
2024-04-29 14:58:53,937 - Batch [4900/8699], Train Loss: 0.023323477754931113, Train Acc: 0.9931154336734694
2024-04-29 14:59:09,046 - Batch [5000/8699], Train Loss: 0.02321504069065486, Train Acc: 0.993134375
2024-04-29 14:59:24,441 - Batch [5100/8699], Train Loss: 0.02311295606808177, Train Acc: 0.9931678921568627
2024-04-29 14:59:39,514 - Batch [5200/8699], Train Loss: 0.02315263389333565, Train Acc: 0.9931520432692308
2024-04-29 14:59:54,905 - Batch [5300/8699], Train Loss: 0.023127990712668318, Train Acc: 0.9931662735849056
2024-04-29 15:00:09,950 - Batch [5400/8699], Train Loss: 0.023002343864008658, Train Acc: 0.9931828703703703
2024-04-29 15:00:25,284 - Batch [5500/8699], Train Loss: 0.0230430971944365, Train Acc: 0.9931732954545455
2024-04-29 15:00:40,125 - Batch [5600/8699], Train Loss: 0.022958396924080943, Train Acc: 0.9932114955357143
2024-04-29 15:00:55,148 - Batch [5700/8699], Train Loss: 0.022874384195470075, Train Acc: 0.9932373903508772
2024-04-29 15:01:09,598 - Batch [5800/8699], Train Loss: 0.02270550531819983, Train Acc: 0.9933081896551724
2024-04-29 15:01:24,553 - Batch [5900/8699], Train Loss: 0.022608710746206392, Train Acc: 0.9933474576271186
2024-04-29 15:01:39,005 - Batch [6000/8699], Train Loss: 0.022697881410780763, Train Acc: 0.9933333333333333
2024-04-29 15:01:54,172 - Batch [6100/8699], Train Loss: 0.022718268210245862, Train Acc: 0.9933401639344263
2024-04-29 15:02:09,049 - Batch [6200/8699], Train Loss: 0.022820297810482126, Train Acc: 0.9933140120967742
2024-04-29 15:02:24,327 - Batch [6300/8699], Train Loss: 0.022855438649075806, Train Acc: 0.9933209325396826
2024-04-29 15:02:39,172 - Batch [6400/8699], Train Loss: 0.022878462900283267, Train Acc: 0.9933203125
2024-04-29 15:02:54,313 - Batch [6500/8699], Train Loss: 0.02283262536750254, Train Acc: 0.9933485576923077
2024-04-29 15:03:09,201 - Batch [6600/8699], Train Loss: 0.022663570521403376, Train Acc: 0.9933877840909091
2024-04-29 15:03:24,632 - Batch [6700/8699], Train Loss: 0.022665174459326178, Train Acc: 0.9933931902985075
2024-04-29 15:03:39,912 - Batch [6800/8699], Train Loss: 0.022603222262060386, Train Acc: 0.9934214154411765
2024-04-29 15:03:55,336 - Batch [6900/8699], Train Loss: 0.022515164286120732, Train Acc: 0.9934510869565217
2024-04-29 15:04:10,100 - Batch [7000/8699], Train Loss: 0.02245567129833697, Train Acc: 0.9934642857142857
2024-04-29 15:04:25,467 - Batch [7100/8699], Train Loss: 0.022482237926937876, Train Acc: 0.993474911971831
2024-04-29 15:04:40,829 - Batch [7200/8699], Train Loss: 0.022401321924085223, Train Acc: 0.993515625
2024-04-29 15:04:56,491 - Batch [7300/8699], Train Loss: 0.022315359823218986, Train Acc: 0.9935466609589041
2024-04-29 15:05:11,728 - Batch [7400/8699], Train Loss: 0.022218126628849, Train Acc: 0.9935620777027027
2024-04-29 15:05:27,276 - Batch [7500/8699], Train Loss: 0.022180750497704745, Train Acc: 0.9935895833333334
2024-04-29 15:05:42,468 - Batch [7600/8699], Train Loss: 0.02212797222873501, Train Acc: 0.9936163651315789
2024-04-29 15:05:57,866 - Batch [7700/8699], Train Loss: 0.02204168906894854, Train Acc: 0.9936363636363637
2024-04-29 15:06:12,534 - Batch [7800/8699], Train Loss: 0.022126769867419543, Train Acc: 0.993623798076923
2024-04-29 15:06:27,674 - Batch [7900/8699], Train Loss: 0.0220727125486686, Train Acc: 0.9936471518987342
2024-04-29 15:06:42,331 - Batch [8000/8699], Train Loss: 0.02198181032738796, Train Acc: 0.993673828125
2024-04-29 15:06:57,347 - Batch [8100/8699], Train Loss: 0.02203659853116643, Train Acc: 0.9936747685185185
2024-04-29 15:07:11,970 - Batch [8200/8699], Train Loss: 0.021952712037848692, Train Acc: 0.9936909298780487
2024-04-29 15:07:26,850 - Batch [8300/8699], Train Loss: 0.021901121437442314, Train Acc: 0.9936841114457832
2024-04-29 15:07:41,465 - Batch [8400/8699], Train Loss: 0.021897870791169463, Train Acc: 0.9936793154761905
2024-04-29 15:07:56,535 - Batch [8500/8699], Train Loss: 0.021820351748730364, Train Acc: 0.993704044117647
2024-04-29 15:08:11,194 - Batch [8600/8699], Train Loss: 0.021777954049059804, Train Acc: 0.9937191133720931
2024-04-29 15:08:26,726 - Train Loss: 0.021679731405842173, Train Acc: 0.993743263634404
2024-04-29 15:10:47,605 - Test Acc: 0.9962061061571735
2024-04-29 15:10:47,660 - Confusion Matrix:
 [[67098   458]
 [   70 71545]]
2024-04-29 15:10:47,675 - Saved the new best model to ../data/models/pklot/all/80_20/squeezenet.pth
2024-04-29 15:10:47,675 - Epoch time: 1455.899808883667 seconds.
2024-04-29 15:10:47,675 - Epoch 3/5
2024-04-29 15:11:18,917 - Batch [100/8699], Train Loss: 0.015905087288301728, Train Acc: 0.9959375
2024-04-29 15:11:33,380 - Batch [200/8699], Train Loss: 0.014408835451631604, Train Acc: 0.995625
2024-04-29 15:11:47,745 - Batch [300/8699], Train Loss: 0.01498491841935902, Train Acc: 0.99578125
2024-04-29 15:12:02,655 - Batch [400/8699], Train Loss: 0.014912271476423484, Train Acc: 0.9959765625
2024-04-29 15:12:17,350 - Batch [500/8699], Train Loss: 0.01653282221604604, Train Acc: 0.995375
2024-04-29 15:12:32,597 - Batch [600/8699], Train Loss: 0.016931763774846332, Train Acc: 0.995234375
2024-04-29 15:12:48,101 - Batch [700/8699], Train Loss: 0.016661476094076144, Train Acc: 0.9953571428571428
2024-04-29 15:13:03,426 - Batch [800/8699], Train Loss: 0.016505670699189068, Train Acc: 0.9954296875
2024-04-29 15:13:17,868 - Batch [900/8699], Train Loss: 0.01708275550473546, Train Acc: 0.9952430555555556
2024-04-29 15:13:32,500 - Batch [1000/8699], Train Loss: 0.01712191726432502, Train Acc: 0.9951875
2024-04-29 15:13:46,288 - Batch [1100/8699], Train Loss: 0.017912290074541076, Train Acc: 0.9948863636363636
2024-04-29 15:14:00,801 - Batch [1200/8699], Train Loss: 0.01796412374490198, Train Acc: 0.9948567708333333
2024-04-29 15:14:14,463 - Batch [1300/8699], Train Loss: 0.01802779522720532, Train Acc: 0.9947475961538461
2024-04-29 15:14:29,174 - Batch [1400/8699], Train Loss: 0.018158976257883687, Train Acc: 0.9946651785714286
2024-04-29 15:14:43,747 - Batch [1500/8699], Train Loss: 0.018091656131771744, Train Acc: 0.9947291666666667
2024-04-29 15:14:58,791 - Batch [1600/8699], Train Loss: 0.018195568485477907, Train Acc: 0.994697265625
2024-04-29 15:15:13,390 - Batch [1700/8699], Train Loss: 0.018176347206135687, Train Acc: 0.9947702205882353
2024-04-29 15:15:28,072 - Batch [1800/8699], Train Loss: 0.018087103411346308, Train Acc: 0.994765625
2024-04-29 15:15:42,759 - Batch [1900/8699], Train Loss: 0.018238519186773997, Train Acc: 0.9947203947368422
2024-04-29 15:15:58,041 - Batch [2000/8699], Train Loss: 0.01844391990804979, Train Acc: 0.994671875
2024-04-29 15:16:13,021 - Batch [2100/8699], Train Loss: 0.018314380131636252, Train Acc: 0.9947470238095238
2024-04-29 15:16:28,481 - Batch [2200/8699], Train Loss: 0.018259016693846206, Train Acc: 0.994765625
2024-04-29 15:16:43,498 - Batch [2300/8699], Train Loss: 0.0180383393258434, Train Acc: 0.9948301630434783
2024-04-29 15:16:58,669 - Batch [2400/8699], Train Loss: 0.01807984830990487, Train Acc: 0.9947981770833333
2024-04-29 15:17:13,303 - Batch [2500/8699], Train Loss: 0.01795117314842573, Train Acc: 0.994825
2024-04-29 15:17:28,489 - Batch [2600/8699], Train Loss: 0.017812555025318665, Train Acc: 0.9948858173076923
2024-04-29 15:17:43,014 - Batch [2700/8699], Train Loss: 0.01755248314746428, Train Acc: 0.9949421296296296
2024-04-29 15:17:58,160 - Batch [2800/8699], Train Loss: 0.017774826076452623, Train Acc: 0.9949665178571429
2024-04-29 15:18:13,015 - Batch [2900/8699], Train Loss: 0.017649284624039238, Train Acc: 0.995010775862069
2024-04-29 15:18:27,948 - Batch [3000/8699], Train Loss: 0.017725512723122543, Train Acc: 0.9950052083333333
2024-04-29 15:18:42,184 - Batch [3100/8699], Train Loss: 0.01789400703957595, Train Acc: 0.9949546370967742
2024-04-29 15:18:57,071 - Batch [3200/8699], Train Loss: 0.017907157989138226, Train Acc: 0.9949267578125
2024-04-29 15:19:11,999 - Batch [3300/8699], Train Loss: 0.01789411380914537, Train Acc: 0.994938446969697
2024-04-29 15:19:27,291 - Batch [3400/8699], Train Loss: 0.017971235239376576, Train Acc: 0.994921875
2024-04-29 15:19:42,249 - Batch [3500/8699], Train Loss: 0.017972820294681568, Train Acc: 0.9949196428571428
2024-04-29 15:19:57,431 - Batch [3600/8699], Train Loss: 0.017874939520904465, Train Acc: 0.9949479166666667
2024-04-29 15:20:12,180 - Batch [3700/8699], Train Loss: 0.017892694797558492, Train Acc: 0.9949324324324325
2024-04-29 15:20:27,405 - Batch [3800/8699], Train Loss: 0.0178228585547803, Train Acc: 0.9949547697368422
2024-04-29 15:20:42,096 - Batch [3900/8699], Train Loss: 0.01766853458729458, Train Acc: 0.995
2024-04-29 15:20:56,783 - Batch [4000/8699], Train Loss: 0.01755524442914657, Train Acc: 0.9950234375
2024-04-29 15:21:10,919 - Batch [4100/8699], Train Loss: 0.017555490747572327, Train Acc: 0.9950381097560975
2024-04-29 15:21:25,782 - Batch [4200/8699], Train Loss: 0.01751047908216259, Train Acc: 0.9950446428571429
2024-04-29 15:21:40,661 - Batch [4300/8699], Train Loss: 0.01742415776607781, Train Acc: 0.9950654069767442
2024-04-29 15:21:55,910 - Batch [4400/8699], Train Loss: 0.017456115349006145, Train Acc: 0.9950674715909091
2024-04-29 15:22:10,631 - Batch [4500/8699], Train Loss: 0.01738743454683289, Train Acc: 0.9951041666666667
2024-04-29 15:22:25,796 - Batch [4600/8699], Train Loss: 0.01739952137366068, Train Acc: 0.9951188858695652
2024-04-29 15:22:40,096 - Batch [4700/8699], Train Loss: 0.01729769385438092, Train Acc: 0.9951429521276596
2024-04-29 15:22:54,803 - Batch [4800/8699], Train Loss: 0.01722217667212931, Train Acc: 0.9951497395833333
2024-04-29 15:23:09,520 - Batch [4900/8699], Train Loss: 0.017144794265672576, Train Acc: 0.9951849489795919
2024-04-29 15:23:24,657 - Batch [5000/8699], Train Loss: 0.017269993576105116, Train Acc: 0.99516875
2024-04-29 15:23:39,157 - Batch [5100/8699], Train Loss: 0.017309037517547147, Train Acc: 0.9951776960784313
2024-04-29 15:23:54,009 - Batch [5200/8699], Train Loss: 0.017263061966556543, Train Acc: 0.9951923076923077
2024-04-29 15:24:08,629 - Batch [5300/8699], Train Loss: 0.017305389886707486, Train Acc: 0.9951857311320754
2024-04-29 15:24:23,130 - Batch [5400/8699], Train Loss: 0.017273613941064872, Train Acc: 0.9952256944444444
2024-04-29 15:24:37,437 - Batch [5500/8699], Train Loss: 0.017269182061431573, Train Acc: 0.9952414772727273
2024-04-29 15:24:51,708 - Batch [5600/8699], Train Loss: 0.01732969846654831, Train Acc: 0.9952232142857143
2024-04-29 15:25:06,794 - Batch [5700/8699], Train Loss: 0.017268418491791015, Train Acc: 0.9952412280701755
2024-04-29 15:25:21,807 - Batch [5800/8699], Train Loss: 0.01733648420513387, Train Acc: 0.9952182112068966
2024-04-29 15:25:36,283 - Batch [5900/8699], Train Loss: 0.017323453313962647, Train Acc: 0.9952251059322034
2024-04-29 15:25:51,562 - Batch [6000/8699], Train Loss: 0.01738319535568644, Train Acc: 0.9952057291666667
2024-04-29 15:26:06,954 - Batch [6100/8699], Train Loss: 0.017323988880725068, Train Acc: 0.9952074795081968
2024-04-29 15:26:22,259 - Batch [6200/8699], Train Loss: 0.017333822933404068, Train Acc: 0.9952091733870968
2024-04-29 15:26:37,309 - Batch [6300/8699], Train Loss: 0.017230889400046485, Train Acc: 0.9952356150793651
2024-04-29 15:26:52,407 - Batch [6400/8699], Train Loss: 0.01726158200286733, Train Acc: 0.99524658203125
2024-04-29 15:27:07,823 - Batch [6500/8699], Train Loss: 0.017242611950253586, Train Acc: 0.9952644230769231
2024-04-29 15:27:22,875 - Batch [6600/8699], Train Loss: 0.017248599952280886, Train Acc: 0.9952746212121212
2024-04-29 15:27:37,654 - Batch [6700/8699], Train Loss: 0.017376630400622026, Train Acc: 0.9952355410447761
2024-04-29 15:27:52,547 - Batch [6800/8699], Train Loss: 0.017297126283638938, Train Acc: 0.9952504595588235
2024-04-29 15:28:07,223 - Batch [6900/8699], Train Loss: 0.017204282844132134, Train Acc: 0.9952853260869565
2024-04-29 15:28:21,942 - Batch [7000/8699], Train Loss: 0.01722267990204195, Train Acc: 0.9952901785714285
2024-04-29 15:28:36,424 - Batch [7100/8699], Train Loss: 0.017172109232401006, Train Acc: 0.9953058978873239
2024-04-29 15:28:50,707 - Batch [7200/8699], Train Loss: 0.01714334593880494, Train Acc: 0.9953146701388889
2024-04-29 15:29:05,108 - Batch [7300/8699], Train Loss: 0.01717428986595136, Train Acc: 0.9953103595890411
2024-04-29 15:29:19,620 - Batch [7400/8699], Train Loss: 0.017165986498368903, Train Acc: 0.9953125
2024-04-29 15:29:34,777 - Batch [7500/8699], Train Loss: 0.017104999461650006, Train Acc: 0.9953375
2024-04-29 15:29:49,589 - Batch [7600/8699], Train Loss: 0.017103589800562747, Train Acc: 0.9953433388157895
2024-04-29 15:30:04,780 - Batch [7700/8699], Train Loss: 0.01712227914316449, Train Acc: 0.9953409090909091
2024-04-29 15:30:19,719 - Batch [7800/8699], Train Loss: 0.01711437114206978, Train Acc: 0.9953465544871795
2024-04-29 15:30:34,594 - Batch [7900/8699], Train Loss: 0.01711629527202857, Train Acc: 0.9953461234177216
2024-04-29 15:30:49,055 - Batch [8000/8699], Train Loss: 0.017093587604415234, Train Acc: 0.995345703125
2024-04-29 15:31:03,940 - Batch [8100/8699], Train Loss: 0.017000627063748934, Train Acc: 0.9953568672839506
2024-04-29 15:31:18,769 - Batch [8200/8699], Train Loss: 0.01700247926536177, Train Acc: 0.995360137195122
2024-04-29 15:31:33,648 - Batch [8300/8699], Train Loss: 0.01693553249180016, Train Acc: 0.9953520331325301
2024-04-29 15:31:48,601 - Batch [8400/8699], Train Loss: 0.017014124787970538, Train Acc: 0.9953515625
2024-04-29 15:32:03,803 - Batch [8500/8699], Train Loss: 0.01691925367211768, Train Acc: 0.9953713235294117
2024-04-29 15:32:18,574 - Batch [8600/8699], Train Loss: 0.01694553006996483, Train Acc: 0.9953651889534884
2024-04-29 15:32:34,219 - Train Loss: 0.016998078273806432, Train Acc: 0.9953510095566573
2024-04-29 15:34:51,389 - Test Acc: 0.9968168655826286
2024-04-29 15:34:51,450 - Confusion Matrix:
 [[67245   311]
 [  132 71483]]
2024-04-29 15:34:51,465 - Saved the new best model to ../data/models/pklot/all/80_20/squeezenet.pth
2024-04-29 15:34:51,465 - Epoch time: 1443.7909512519836 seconds.
2024-04-29 15:34:51,465 - Epoch 4/5
2024-04-29 15:35:23,197 - Batch [100/8699], Train Loss: 0.019482976393628632, Train Acc: 0.994375
2024-04-29 15:35:37,904 - Batch [200/8699], Train Loss: 0.017289466556321714, Train Acc: 0.995234375
2024-04-29 15:35:52,744 - Batch [300/8699], Train Loss: 0.01704124461160973, Train Acc: 0.99546875
2024-04-29 15:36:07,640 - Batch [400/8699], Train Loss: 0.01731891168979928, Train Acc: 0.995390625
2024-04-29 15:36:22,545 - Batch [500/8699], Train Loss: 0.019334464508574456, Train Acc: 0.99484375
2024-04-29 15:36:37,192 - Batch [600/8699], Train Loss: 0.018714164129620865, Train Acc: 0.994921875
2024-04-29 15:36:51,183 - Batch [700/8699], Train Loss: 0.01890358939624483, Train Acc: 0.9947991071428571
2024-04-29 15:37:05,390 - Batch [800/8699], Train Loss: 0.0186521291344161, Train Acc: 0.99490234375
2024-04-29 15:37:19,215 - Batch [900/8699], Train Loss: 0.018111116967492208, Train Acc: 0.9950173611111112
2024-04-29 15:37:33,887 - Batch [1000/8699], Train Loss: 0.01772518209543341, Train Acc: 0.995109375
2024-04-29 15:37:48,565 - Batch [1100/8699], Train Loss: 0.017165778841901392, Train Acc: 0.9952414772727273
2024-04-29 15:38:03,685 - Batch [1200/8699], Train Loss: 0.01675584631832559, Train Acc: 0.9953515625
2024-04-29 15:38:18,544 - Batch [1300/8699], Train Loss: 0.016457802063836985, Train Acc: 0.9955048076923076
2024-04-29 15:38:33,782 - Batch [1400/8699], Train Loss: 0.01616921547543825, Train Acc: 0.995625
2024-04-29 15:38:48,456 - Batch [1500/8699], Train Loss: 0.01586807062241375, Train Acc: 0.99571875
2024-04-29 15:39:03,638 - Batch [1600/8699], Train Loss: 0.015807924798166367, Train Acc: 0.99578125
2024-04-29 15:39:18,812 - Batch [1700/8699], Train Loss: 0.015756349782461578, Train Acc: 0.9957996323529412
2024-04-29 15:39:34,069 - Batch [1800/8699], Train Loss: 0.015867752732788683, Train Acc: 0.9958246527777778
2024-04-29 15:39:48,926 - Batch [1900/8699], Train Loss: 0.01570774644273881, Train Acc: 0.9957894736842106
2024-04-29 15:40:04,228 - Batch [2000/8699], Train Loss: 0.01567932622909484, Train Acc: 0.995734375
2024-04-29 15:40:19,099 - Batch [2100/8699], Train Loss: 0.015619082822064402, Train Acc: 0.9957217261904762
2024-04-29 15:40:34,358 - Batch [2200/8699], Train Loss: 0.015727961805478943, Train Acc: 0.9956960227272728
2024-04-29 15:40:49,357 - Batch [2300/8699], Train Loss: 0.01570916118855324, Train Acc: 0.9957133152173913
2024-04-29 15:41:04,540 - Batch [2400/8699], Train Loss: 0.015951694932599972, Train Acc: 0.9956315104166666
2024-04-29 15:41:19,393 - Batch [2500/8699], Train Loss: 0.01590885514705078, Train Acc: 0.9956625
2024-04-29 15:41:34,643 - Batch [2600/8699], Train Loss: 0.01608286957764344, Train Acc: 0.9956430288461539
2024-04-29 15:41:49,574 - Batch [2700/8699], Train Loss: 0.016082989888254816, Train Acc: 0.995625
2024-04-29 15:42:04,769 - Batch [2800/8699], Train Loss: 0.01608001680604697, Train Acc: 0.9956082589285714
2024-04-29 15:42:19,565 - Batch [2900/8699], Train Loss: 0.016171660927348997, Train Acc: 0.9955657327586207
2024-04-29 15:42:35,101 - Batch [3000/8699], Train Loss: 0.015985154242566448, Train Acc: 0.9955989583333333
2024-04-29 15:42:50,455 - Batch [3100/8699], Train Loss: 0.01608423392864713, Train Acc: 0.9955594758064517
2024-04-29 15:43:05,451 - Batch [3200/8699], Train Loss: 0.016098460952997586, Train Acc: 0.99556640625
2024-04-29 15:43:20,047 - Batch [3300/8699], Train Loss: 0.015906101919327655, Train Acc: 0.9956013257575758
2024-04-29 15:43:33,963 - Batch [3400/8699], Train Loss: 0.015732160332437857, Train Acc: 0.9956479779411764
2024-04-29 15:43:47,750 - Batch [3500/8699], Train Loss: 0.01571794531805686, Train Acc: 0.9956741071428571
2024-04-29 15:44:02,328 - Batch [3600/8699], Train Loss: 0.015537947990963707, Train Acc: 0.9957204861111111
2024-04-29 15:44:16,073 - Batch [3700/8699], Train Loss: 0.015396986304525902, Train Acc: 0.9957643581081081
2024-04-29 15:44:30,431 - Batch [3800/8699], Train Loss: 0.015417741261993988, Train Acc: 0.9957606907894737
2024-04-29 15:44:44,082 - Batch [3900/8699], Train Loss: 0.015578656237481388, Train Acc: 0.995713141025641
2024-04-29 15:44:58,507 - Batch [4000/8699], Train Loss: 0.015476645549444584, Train Acc: 0.99574609375
2024-04-29 15:45:12,137 - Batch [4100/8699], Train Loss: 0.015323191180348925, Train Acc: 0.99578125
2024-04-29 15:45:26,475 - Batch [4200/8699], Train Loss: 0.015187220785261335, Train Acc: 0.9957998511904762
2024-04-29 15:45:40,202 - Batch [4300/8699], Train Loss: 0.015272127446043542, Train Acc: 0.9958139534883721
2024-04-29 15:45:54,649 - Batch [4400/8699], Train Loss: 0.015162749978762803, Train Acc: 0.9958522727272727
2024-04-29 15:46:08,416 - Batch [4500/8699], Train Loss: 0.015109236390755136, Train Acc: 0.9958541666666667
2024-04-29 15:46:22,669 - Batch [4600/8699], Train Loss: 0.01530817976676585, Train Acc: 0.9957982336956521
2024-04-29 15:46:36,656 - Batch [4700/8699], Train Loss: 0.015247824324224177, Train Acc: 0.9958045212765958
2024-04-29 15:46:50,589 - Batch [4800/8699], Train Loss: 0.015275543210099538, Train Acc: 0.9957942708333334
2024-04-29 15:47:04,908 - Batch [4900/8699], Train Loss: 0.015270242492491778, Train Acc: 0.99578125
2024-04-29 15:47:18,657 - Batch [5000/8699], Train Loss: 0.01517162738482075, Train Acc: 0.9958125
2024-04-29 15:47:33,167 - Batch [5100/8699], Train Loss: 0.015152389283694171, Train Acc: 0.9958394607843137
2024-04-29 15:47:46,919 - Batch [5200/8699], Train Loss: 0.015108264451768823, Train Acc: 0.9958653846153847
2024-04-29 15:48:01,369 - Batch [5300/8699], Train Loss: 0.015162323496920437, Train Acc: 0.9958520047169811
2024-04-29 15:48:15,118 - Batch [5400/8699], Train Loss: 0.01521781914987851, Train Acc: 0.9958246527777778
2024-04-29 15:48:28,809 - Batch [5500/8699], Train Loss: 0.01518793326713322, Train Acc: 0.9958295454545455
2024-04-29 15:48:42,589 - Batch [5600/8699], Train Loss: 0.015132309281057132, Train Acc: 0.99583984375
2024-04-29 15:48:57,215 - Batch [5700/8699], Train Loss: 0.015139413858434732, Train Acc: 0.9958470394736842
2024-04-29 15:49:11,209 - Batch [5800/8699], Train Loss: 0.015042249222260266, Train Acc: 0.9958728448275862
2024-04-29 15:49:25,510 - Batch [5900/8699], Train Loss: 0.014994292241004525, Train Acc: 0.995895127118644
2024-04-29 15:49:39,138 - Batch [6000/8699], Train Loss: 0.01492973598428489, Train Acc: 0.9959114583333334
2024-04-29 15:49:53,454 - Batch [6100/8699], Train Loss: 0.014957945455311138, Train Acc: 0.9959118852459017
2024-04-29 15:50:07,339 - Batch [6200/8699], Train Loss: 0.014952731134800718, Train Acc: 0.9959122983870968
2024-04-29 15:50:21,127 - Batch [6300/8699], Train Loss: 0.014932448799745977, Train Acc: 0.9959474206349206
2024-04-29 15:50:35,211 - Batch [6400/8699], Train Loss: 0.01482692986125727, Train Acc: 0.9959619140625
2024-04-29 15:50:48,732 - Batch [6500/8699], Train Loss: 0.014906941755988485, Train Acc: 0.9959471153846153
2024-04-29 15:51:03,066 - Batch [6600/8699], Train Loss: 0.014947592407155697, Train Acc: 0.9959256628787879
2024-04-29 15:51:16,769 - Batch [6700/8699], Train Loss: 0.014934789225704364, Train Acc: 0.9959258395522388
2024-04-29 15:51:31,182 - Batch [6800/8699], Train Loss: 0.014994688721122282, Train Acc: 0.9959214154411765
2024-04-29 15:51:44,893 - Batch [6900/8699], Train Loss: 0.014890654060152197, Train Acc: 0.9959533514492753
2024-04-29 15:51:59,285 - Batch [7000/8699], Train Loss: 0.014851598238254675, Train Acc: 0.9959553571428571
2024-04-29 15:52:12,914 - Batch [7100/8699], Train Loss: 0.014844352780775654, Train Acc: 0.9959419014084507
2024-04-29 15:52:26,491 - Batch [7200/8699], Train Loss: 0.014847112951761372, Train Acc: 0.9959461805555555
2024-04-29 15:52:40,187 - Batch [7300/8699], Train Loss: 0.014876927376102784, Train Acc: 0.9959482020547945
2024-04-29 15:52:54,595 - Batch [7400/8699], Train Loss: 0.014827615100649947, Train Acc: 0.9959670608108108
2024-04-29 15:53:08,319 - Batch [7500/8699], Train Loss: 0.014783519659668915, Train Acc: 0.9959833333333333
2024-04-29 15:53:22,367 - Batch [7600/8699], Train Loss: 0.014806520225684164, Train Acc: 0.9959909539473685
2024-04-29 15:53:36,247 - Batch [7700/8699], Train Loss: 0.014758061660848327, Train Acc: 0.9960166396103897
2024-04-29 15:53:49,967 - Batch [7800/8699], Train Loss: 0.014804217869953227, Train Acc: 0.996005608974359
2024-04-29 15:54:04,298 - Batch [7900/8699], Train Loss: 0.014823956812849672, Train Acc: 0.9960106803797468
2024-04-29 15:54:17,833 - Batch [8000/8699], Train Loss: 0.014863143596250893, Train Acc: 0.996009765625
2024-04-29 15:54:32,141 - Batch [8100/8699], Train Loss: 0.014817480540640207, Train Acc: 0.9960165895061729
2024-04-29 15:54:45,752 - Batch [8200/8699], Train Loss: 0.014845483028395792, Train Acc: 0.9960080030487805
2024-04-29 15:55:00,050 - Batch [8300/8699], Train Loss: 0.014790525011303762, Train Acc: 0.9960203313253012
2024-04-29 15:55:13,601 - Batch [8400/8699], Train Loss: 0.014770079385163757, Train Acc: 0.9960267857142857
2024-04-29 15:55:28,036 - Batch [8500/8699], Train Loss: 0.014701970543046627, Train Acc: 0.9960422794117647
2024-04-29 15:55:41,753 - Batch [8600/8699], Train Loss: 0.014723826031937533, Train Acc: 0.9960247093023256
2024-04-29 15:55:56,651 - Train Loss: 0.014748337920144173, Train Acc: 0.9960210533879428
2024-04-29 15:58:03,610 - Test Acc: 0.9953941553915686
2024-04-29 15:58:03,669 - Confusion Matrix:
 [[67224   332]
 [  309 71306]]
2024-04-29 15:58:03,682 - Saved the new best model to ../data/models/pklot/all/80_20/squeezenet.pth
2024-04-29 15:58:03,682 - Epoch time: 1392.2160575389862 seconds.
2024-04-29 15:58:03,682 - Epoch 5/5
2024-04-29 15:58:33,387 - Batch [100/8699], Train Loss: 0.015676834496553056, Train Acc: 0.995
2024-04-29 15:58:46,479 - Batch [200/8699], Train Loss: 0.018593513719570184, Train Acc: 0.99515625
2024-04-29 15:59:00,481 - Batch [300/8699], Train Loss: 0.017889532604143218, Train Acc: 0.99515625
2024-04-29 15:59:13,890 - Batch [400/8699], Train Loss: 0.017407921730064117, Train Acc: 0.995078125
2024-04-29 15:59:28,154 - Batch [500/8699], Train Loss: 0.017276224563393044, Train Acc: 0.995125
2024-04-29 15:59:41,659 - Batch [600/8699], Train Loss: 0.01669057683068483, Train Acc: 0.9952604166666666
2024-04-29 15:59:55,967 - Batch [700/8699], Train Loss: 0.015970708199227895, Train Acc: 0.9955580357142857
2024-04-29 16:00:09,635 - Batch [800/8699], Train Loss: 0.014878176371030349, Train Acc: 0.99583984375
2024-04-29 16:00:23,940 - Batch [900/8699], Train Loss: 0.014931757541328099, Train Acc: 0.9959201388888889
2024-04-29 16:00:37,711 - Batch [1000/8699], Train Loss: 0.014915893627257901, Train Acc: 0.9959375
2024-04-29 16:00:51,689 - Batch [1100/8699], Train Loss: 0.014336773182724508, Train Acc: 0.9961505681818181
2024-04-29 16:01:05,755 - Batch [1200/8699], Train Loss: 0.014109575424693805, Train Acc: 0.9962239583333333
2024-04-29 16:01:19,441 - Batch [1300/8699], Train Loss: 0.013683959803479062, Train Acc: 0.9963701923076923
2024-04-29 16:01:33,809 - Batch [1400/8699], Train Loss: 0.013391373460342169, Train Acc: 0.996484375
2024-04-29 16:01:47,477 - Batch [1500/8699], Train Loss: 0.013661426986548273, Train Acc: 0.9962708333333333
2024-04-29 16:02:01,876 - Batch [1600/8699], Train Loss: 0.013714117088411512, Train Acc: 0.996328125
2024-04-29 16:02:15,417 - Batch [1700/8699], Train Loss: 0.013395736558591392, Train Acc: 0.9963970588235294
2024-04-29 16:02:29,067 - Batch [1800/8699], Train Loss: 0.013415303269525287, Train Acc: 0.9964496527777778
2024-04-29 16:02:42,745 - Batch [1900/8699], Train Loss: 0.013351902267192935, Train Acc: 0.9964473684210526
2024-04-29 16:02:56,299 - Batch [2000/8699], Train Loss: 0.013126216507977006, Train Acc: 0.996453125
2024-04-29 16:03:09,810 - Batch [2100/8699], Train Loss: 0.013581945344438802, Train Acc: 0.9963690476190477
2024-04-29 16:03:24,174 - Batch [2200/8699], Train Loss: 0.013736285328719863, Train Acc: 0.9963494318181818
2024-04-29 16:03:37,789 - Batch [2300/8699], Train Loss: 0.013864126340354825, Train Acc: 0.9963383152173914
2024-04-29 16:03:51,718 - Batch [2400/8699], Train Loss: 0.013599617590415013, Train Acc: 0.99638671875
2024-04-29 16:04:05,655 - Batch [2500/8699], Train Loss: 0.013655577774213452, Train Acc: 0.9963625
2024-04-29 16:04:19,210 - Batch [2600/8699], Train Loss: 0.013574895846136664, Train Acc: 0.996376201923077
2024-04-29 16:04:32,921 - Batch [2700/8699], Train Loss: 0.013528500650959526, Train Acc: 0.9963657407407407
2024-04-29 16:04:46,573 - Batch [2800/8699], Train Loss: 0.013647828772709545, Train Acc: 0.996328125
2024-04-29 16:05:00,178 - Batch [2900/8699], Train Loss: 0.013565137975261866, Train Acc: 0.9963631465517241
2024-04-29 16:05:13,727 - Batch [3000/8699], Train Loss: 0.013492802427949452, Train Acc: 0.996359375
2024-04-29 16:05:27,252 - Batch [3100/8699], Train Loss: 0.013777657499889639, Train Acc: 0.9963104838709678
2024-04-29 16:05:40,852 - Batch [3200/8699], Train Loss: 0.01394177170814487, Train Acc: 0.9962841796875
2024-04-29 16:05:54,553 - Batch [3300/8699], Train Loss: 0.013973274590214054, Train Acc: 0.9962547348484848
2024-04-29 16:06:08,127 - Batch [3400/8699], Train Loss: 0.013937171624064135, Train Acc: 0.9962683823529411
2024-04-29 16:06:22,088 - Batch [3500/8699], Train Loss: 0.013993645016472978, Train Acc: 0.9962589285714286
2024-04-29 16:06:36,031 - Batch [3600/8699], Train Loss: 0.01393610770518535, Train Acc: 0.9962760416666666
2024-04-29 16:06:49,743 - Batch [3700/8699], Train Loss: 0.013871164357778734, Train Acc: 0.9962880067567568
2024-04-29 16:07:03,476 - Batch [3800/8699], Train Loss: 0.014025887872243115, Train Acc: 0.9962253289473684
2024-04-29 16:07:17,185 - Batch [3900/8699], Train Loss: 0.01397080808613212, Train Acc: 0.996229967948718
2024-04-29 16:07:30,795 - Batch [4000/8699], Train Loss: 0.013918489534462196, Train Acc: 0.9962421875
2024-04-29 16:07:44,325 - Batch [4100/8699], Train Loss: 0.01402855343218706, Train Acc: 0.9961928353658537
2024-04-29 16:07:58,590 - Batch [4200/8699], Train Loss: 0.014089472600129781, Train Acc: 0.9961904761904762
2024-04-29 16:08:12,189 - Batch [4300/8699], Train Loss: 0.014162489713574169, Train Acc: 0.9961809593023255
2024-04-29 16:08:25,728 - Batch [4400/8699], Train Loss: 0.01415732092517725, Train Acc: 0.9961789772727273
2024-04-29 16:08:39,347 - Batch [4500/8699], Train Loss: 0.014184337730907323, Train Acc: 0.9961736111111111
2024-04-29 16:08:53,464 - Batch [4600/8699], Train Loss: 0.014123105686625935, Train Acc: 0.9961922554347826
2024-04-29 16:09:07,268 - Batch [4700/8699], Train Loss: 0.0141375079892058, Train Acc: 0.9962067819148936
2024-04-29 16:09:20,924 - Batch [4800/8699], Train Loss: 0.014025367185475375, Train Acc: 0.99623046875
2024-04-29 16:09:35,071 - Batch [4900/8699], Train Loss: 0.014039403160881453, Train Acc: 0.9962213010204082
2024-04-29 16:09:48,639 - Batch [5000/8699], Train Loss: 0.014072080544214804, Train Acc: 0.99620625
2024-04-29 16:10:02,931 - Batch [5100/8699], Train Loss: 0.01406486349465512, Train Acc: 0.9962254901960784
2024-04-29 16:10:16,561 - Batch [5200/8699], Train Loss: 0.013971551494601919, Train Acc: 0.9962530048076923
2024-04-29 16:10:30,883 - Batch [5300/8699], Train Loss: 0.014062649535655064, Train Acc: 0.9962529481132075
2024-04-29 16:10:44,564 - Batch [5400/8699], Train Loss: 0.013974808559482544, Train Acc: 0.9962847222222222
2024-04-29 16:10:58,859 - Batch [5500/8699], Train Loss: 0.013906950726369442, Train Acc: 0.9963039772727272
2024-04-29 16:11:12,473 - Batch [5600/8699], Train Loss: 0.013936629584261645, Train Acc: 0.9963197544642857
2024-04-29 16:11:26,716 - Batch [5700/8699], Train Loss: 0.013984022577813353, Train Acc: 0.9963212719298246
2024-04-29 16:11:40,287 - Batch [5800/8699], Train Loss: 0.013882225826438305, Train Acc: 0.9963469827586207
2024-04-29 16:11:54,552 - Batch [5900/8699], Train Loss: 0.013892282379803441, Train Acc: 0.9963268008474576
2024-04-29 16:12:08,038 - Batch [6000/8699], Train Loss: 0.01387790013822132, Train Acc: 0.9963567708333333
2024-04-29 16:12:21,689 - Batch [6100/8699], Train Loss: 0.013911281571138075, Train Acc: 0.9963498975409836
2024-04-29 16:12:35,303 - Batch [6200/8699], Train Loss: 0.01386357563678684, Train Acc: 0.9963558467741935
2024-04-29 16:12:49,108 - Batch [6300/8699], Train Loss: 0.013883822254950405, Train Acc: 0.9963492063492063
2024-04-29 16:13:03,420 - Batch [6400/8699], Train Loss: 0.013782874001799854, Train Acc: 0.9963525390625
2024-04-29 16:13:17,082 - Batch [6500/8699], Train Loss: 0.013728295959021124, Train Acc: 0.9963629807692308
2024-04-29 16:13:30,760 - Batch [6600/8699], Train Loss: 0.013707899107137591, Train Acc: 0.9963707386363636
2024-04-29 16:13:44,413 - Batch [6700/8699], Train Loss: 0.013692024162287385, Train Acc: 0.9963782649253732
2024-04-29 16:13:58,005 - Batch [6800/8699], Train Loss: 0.013837243938830316, Train Acc: 0.996328125
2024-04-29 16:14:11,634 - Batch [6900/8699], Train Loss: 0.013848709114082088, Train Acc: 0.9963292572463768
2024-04-29 16:14:25,992 - Batch [7000/8699], Train Loss: 0.013815713160329713, Train Acc: 0.9963392857142858
2024-04-29 16:14:39,594 - Batch [7100/8699], Train Loss: 0.013811885720403334, Train Acc: 0.9963358274647888
2024-04-29 16:14:53,915 - Batch [7200/8699], Train Loss: 0.013895811369349581, Train Acc: 0.9963129340277778
2024-04-29 16:15:07,600 - Batch [7300/8699], Train Loss: 0.013961201324422266, Train Acc: 0.9963163527397261
2024-04-29 16:15:21,442 - Batch [7400/8699], Train Loss: 0.013963140466901407, Train Acc: 0.996328125
2024-04-29 16:15:35,449 - Batch [7500/8699], Train Loss: 0.01395232642947, Train Acc: 0.9963479166666667
2024-04-29 16:15:49,126 - Batch [7600/8699], Train Loss: 0.013932167261899442, Train Acc: 0.9963548519736842
2024-04-29 16:16:02,783 - Batch [7700/8699], Train Loss: 0.013862527881341544, Train Acc: 0.9963737824675325
2024-04-29 16:16:16,379 - Batch [7800/8699], Train Loss: 0.01385299711068199, Train Acc: 0.9963842147435897
2024-04-29 16:16:29,981 - Batch [7900/8699], Train Loss: 0.013808916939790177, Train Acc: 0.9963924050632912
2024-04-29 16:16:43,681 - Batch [8000/8699], Train Loss: 0.013882406739912426, Train Acc: 0.996373046875
2024-04-29 16:16:58,067 - Batch [8100/8699], Train Loss: 0.013901354381733419, Train Acc: 0.9963618827160494
2024-04-29 16:17:11,663 - Batch [8200/8699], Train Loss: 0.013911219261085534, Train Acc: 0.996358612804878
2024-04-29 16:17:25,214 - Batch [8300/8699], Train Loss: 0.013864215135935882, Train Acc: 0.9963629518072289
2024-04-29 16:17:38,756 - Batch [8400/8699], Train Loss: 0.013876223402866495, Train Acc: 0.9963616071428572
2024-04-29 16:17:53,393 - Batch [8500/8699], Train Loss: 0.013967482797296992, Train Acc: 0.9963400735294118
2024-04-29 16:18:08,942 - Batch [8600/8699], Train Loss: 0.014049069712151894, Train Acc: 0.9963099563953488
2024-04-29 16:18:24,769 - Train Loss: 0.01406735124802454, Train Acc: 0.9963012861967379
2024-04-29 16:20:45,066 - Test Acc: 0.9953941553915686
2024-04-29 16:20:45,128 - Confusion Matrix:
 [[67258   298]
 [  343 71272]]
2024-04-29 16:20:45,144 - Saved the new best model to ../data/models/pklot/all/80_20/squeezenet.pth
2024-04-29 16:20:45,144 - Epoch time: 1361.4620099067688 seconds.
2024-04-29 16:20:45,144 - Best Train Acc: 0.9963012861967379
2024-04-29 16:20:45,145 - Total training time: 6997.898681879044 seconds.
